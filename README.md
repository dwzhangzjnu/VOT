# Visual Object Tracking

## Paper List

### :star2: Recommendations :star2:

- **VOTBook:**  Xin Zhao, Shiyu Hu, Xu-Cheng Yin.<br />
  "Visual Object Tracking: An Evaluation Perspective." Springer (2025).
  [[paper](https://link.springer.com/book/10.1007/978-981-96-4558-9)]

- **VOTSurvey:** Sajid Javed, Martin Danelljan, Fahad Shahbaz Khan, Muhammad Haris Khan, Michael Felsberg, Jiri Matas.<br />
  "Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook." TAPMI (2023).
  [[paper](https://arxiv.org/abs/2112.02838)] 
  
- **DL4VT:** Seyed Mojtaba Marvasti-Zadeh, Li Cheng, Senior Member, Hossein Ghanei-Yakhdan, Shohreh Kasaei, Senior Member.<br />
  "Deep Learning for Visual Tracking: A Comprehensive Survey." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/1912.00535.pdf)] 
  [[code](https://github.com/MMarvasti/Deep-Learning-for-Visual-Tracking-Survey)]
   
- **SAM3:** Nicolas Carion, Laura Gustafson, Yuan-Ting Hu, Shoubhik Debnath, Ronghang Hu, Didac Suris, Chaitanya Ryali, Kalyan Vasudev Alwala, Haitham Khedr, Andrew Huang, Jie Lei, Tengyu Ma, Baishan Guo, Arpit Kalla, Markus Marks, Joseph Greer, Meng Wang, Peize Sun, Roman Rädle, Triantafyllos Afouras, Effrosyni Mavroudi, Katherine Xu, Tsung-Han Wu, Yu Zhou, Liliane Momeni, Rishi Hazra, Shuangrui Ding, Sagar Vaze, Francois Porcher, Feng Li, Siyuan Li, Aishwarya Kamath, Ho Kei Cheng, Piotr Dollár, Nikhila Ravi, Kate Saenko, Pengchuan Zhang, Christoph Feichtenhofer.<br />
  "SAM 3: Segment Anything with Concepts." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2511.16719)] 
  [[code](https://github.com/facebookresearch/sam3)]

- **SAMURAI:** Cheng-Yen Yang, Hsiang-Wei Huang, Wenhao Chai, Zhongyu Jiang, Jenq-Neng Hwang.<br />
  "SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memory." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.11922)] 
  [[code](https://github.com/yangchris11/samurai)]

- **DAMv2:** Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, Hengshuang Zhao.<br />
  "Depth Anything V2." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2406.09414)] 
  [[code](https://depth-anything-v2.github.io/)]

- **4M-21:** Roman Bachmann, Oğuzhan Fatih Kar, David Mizrahi, Ali Garjani, Mingfei Gao, David Griffiths, Jiaming Hu, Afshin Dehghan, Amir Zamir.<br />
  "4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2406.09406)] 
  [[code](https://4m.epfl.ch/)]
      
- **SAM:** Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick.<br />
  "Segment Anything." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.02643v1.pdf)] 
  [[homepage](https://segment-anything.com/)] 
  [[code](https://github.com/facebookresearch/segment-anything)]
  
- **TAM:** Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, Feng Zheng.<br />
  "Track Anything: Segment Anything Meets Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.11968)] 
  [[code](https://github.com/gaomingqi/Track-Anything)]
  
- **SAM-Track:** Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, Yi Yang.<br />
  "Segment-and-Track Anything." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.06558)] 
  [[code](https://github.com/z-x-yang/Segment-and-Track-Anything)]
  
- **SEEM:** Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Gao, Yong Jae Lee.<br />
  "Segment Everything Everywhere All at Once." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.06718v1.pdf)] 
  [[code](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)]
  
- **ReviewLLM:** Jiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu, Chong Ma, Sigang Yu, Haixing Dai.<br />
  "Review of Large Vision Models and Visual Prompt Engineering." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.00855)]
  [[code](https://github.com/xxx)]
  
- **ChatVideo:** Junke Wang, Dongdong Chen, Chong Luo, Xiyang Dai, Lu Yuan, Zuxuan Wu, Yu-Gang Jiang.<br />
  "ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.14407)] 
  [[code](https://www.wangjunke.info/ChatVideo/)]
  
- **Video-ChatGPT:** Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan.<br />
  "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05424)] 
  [[code](https://github.com/mbzuai-oryx/Video-ChatGPT)]
  
- **SegGPT:** Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang.<br />
  "SegGPT: Segmenting Everything In Context." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.03284)] 
  [[code](https://github.com/baaivision/Painter)]


### AAAI 2026

- **SATA:** Tianlu Zhang, Qiang Zhang, Guiguang Ding, Jungong Han.<br />
  "Tracking and Segmenting Anything in Any Modality." AAAI (2026).
  [[paper](https://arxiv.org/abs/2511.19475)]
  [[code]( )]

- **LUART:** Yun Xiao, Yuhang Wang, Jiandong Jin, Wangkang Zhang, Chenglong Li.<br />
  "Unaligned UAV RGBT Tracking: A Largescale Benchmark and A Novel Approach." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **CADTrack:** Hao Li, Yuhao Wang, Xiantao Hu, Wenning Hao, Pingping Zhang, Dong Wang, Huchuan Lu.<br />
  "CADTrack: Learning Contextual Aggregation with Deformable Alignment for Robust RGBT Tracking." AAAI (2026).
  [[paper](https://arxiv.org/abs/2511.17967)] 
  [[code](https://github.com/IdolLab/CADTrack)]

- **AlignTrack:** Chuanyu Sun, Jiqing Zhang, Yang Wang, Yuanchen Wang, Yutong Jiang, Baocai Yin, Xin Yang.<br />
  "AlignTrack: Top-Down Spatiotemporal Resolution Alignment for RGB-Event Visual Tracking." AAAI (2026).
  [[paper]( )] 
  [[code](https://github.com/scy0712/AlignTrack)]

- **MoDTrack:** Hongtao Yang, Bineng Zhong, Qihua Liang, Xiantao Hu, Yufei Tan, Haiying Xia, Shuxiang Song.<br />
  "Motion-Aware Object Tracking via Motion and Geometry-Aware Cues." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **MUTrack:** Weijing Wu, Qihua Liang, Bineng Zhong, Xiaohu Tang, Yufei Tan, Ning Li, Yuanliang Xue.<br />
  "MUTrack: A Memory-Aware Unified Representation Framework for Visual Trackings." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **ADTrack:** Guangtong Zhang, Bineng Zhong, Shirui Yang, Yang Wang, Tian Bai.<br />
  "Aware Distillation for Robust Vision-Language Tracking Under Linguistic Sparsity." AAAI (2026).
  [[paper]( )] 
  [[code]( )]
  
- **MFDP:** Shilei Wang, Pujian Lai, Dong Gao, Jifeng Ning, Gong Cheng.<br />
  "Exploring Modality-Aware Fusion and Decoupled Temporal Propagation for Multi-Modal Object Tracking." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **SDTrack:** Junze Shi, Yang Yu, Jian Shi, Haibo Luo.<br />
  "Exploring Reliable Spatiotemporal Dependencies for Efficient Visual Tracking." AAAI (2026).
  [[paper]( )] 
  [[code]( )]  

- **AMTrack:** Ge Ying, Dawei Zhang, Chengzhuan Yang, Wei Liu, Sang-Woon Jeon, Hua Wang, Changqin Huang, Zhonglong Zheng.<br />
  "Exploiting All Mamba Fusion for Efficient RGB-D Tracking." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **GOLA:** Zekai Shao, Yufan Hu, Jingyuan Liu, Bin Fan, Hongmin Liu.<br />
  "Group Orthogonal Low-Rank Adaptation for RGB-T Tracking." AAAI (2026).
  [[paper](https://arxiv.org/abs/2512.05359)] 
  [[code](https://github.com/MelanTech/GOLA)]

- **SFPT:** Jiahao Wang, Fang Liu, Hao Wang, Shuo Li, Xiyi Wang, Puhua Chen.<br />
  "Semantic Feature Purification for Adversarially-Aware RGB-T Tracking." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **HTTrack:** Jiahao Wang, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Xiyi Wang, Lingling Li, Puhua Chen, Xu Liu.<br />
  "HTTrack: Learning to Perceive Targets via Historical Trajectories in Satellite Video Tracking." AAAI (2026).
  [[paper]( )] 
  [[code]( )]
  
- **CompTrack:** Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu, Shuo Wang.<br />
  "CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking." AAAI (2026).
  [[paper](https://arxiv.org/abs/2511.15580)] 
  [[code]( )]

- **AerialMind:** Chenglizhao Chen, Shaofeng Liang, Runwei Guan, Xiaolou Sun, Haocheng Zhao, Haiyun Jiang, Tao Huang, Henghui Ding, Qing-Long Han.<br />
  "AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios." AAAI (2026).
  [[paper](https://arxiv.org/abs/2511.21053)] 
  [[code](https://github.com/shawnliang420/AerialMind)]

- **SAM2-OV:** Yangkai Chen, Qiangqiang Wu, Guangyao Li, Junlong Gao, Guanglin Niu, Hanzi Wang.<br />
  "SAM2-OV: A Novel Detection-Only Tuning Paradigm for Open-Vocabulary Multi-Object Tracking." AAAI (2026).
  [[paper]( )] 
  [[code]( )]

- **SAM2MOT:** Junjie Jiang, Zelin Wang, Manqi Zhao, Yin Li, DongSheng Jiang.<br />
  "SAM2MOT: A Novel Paradigm of Multi-Object Tracking by Segmentation." AAAI (2026).
  [[paper](https://arxiv.org/abs/2504.04519)] 
  [[code](https://github.com/TripleJoy/SAM2MOT)]
  
- **SAM-DAQ:** Jia Lin, Xiaofei Zhou, Jiyuan Liu, Runmin Cong, Guodao Zhang, Zhi Liu, Jiyong Zhang.<br />
  "SAM-DAQ: Segment Anything Model with Depth-guided Adaptive Queries for RGB-D Video Salient Object Detection." AAAI (2026).
  [[paper](https://arxiv.org/abs/2511.09870)] 
  [[code](https://github.com/LinJ0866/SAM-DAQ)]

- **SM3Det:** Yuxuan Li, Xiang Li, Yunheng Li, Yicheng Zhang, Yimian Dai, Qibin Hou, Ming-Ming Cheng, Jian Yang.<br />
  "SM3Det: A Unified Model for Multi-Modal Remote Sensing Object Detection." AAAI (2026).
  [[paper](https://arxiv.org/abs/2412.20665)] 
  [[code](https://github.com/zcablii/SM3Det)]
  


### NeurIPS 2025

- **RGBDT500:** Xue-Feng Zhu, Tianyang Xu, Yifan Pan, Jinjie Gu, Xi Li, Jiwen Lu, Xiao-Jun Wu, Josef Kittler.<br />
  "Collaborating Vision, Depth, and Thermal Signals for Multi-Modal Tracking." NeurIPS (2025).
  [[paper](https://arxiv.org/abs/2509.24741)] 
  [[code](https://xuefeng-zhu5.github.io/RGBDT500/)]

- **MMOT:** Tianhao Li, Tingfa Xu, Ying Wang, Haolin Qin, Xu Lin, Jianan Li.<br />
  "MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking." NeurIPS (2025).
  [[paper](https://arxiv.org/abs/2510.12565)] 
  [[code](https://github.com/Annzstbl/MMOT)]
  
- **SpikeFET:** Jingjun Yang, Liangwei Fan, Jinpu Zhang, Xiangkai Lian, Hui Shen, Dewen Hu.<br />
  "Fully Spiking Neural Networks for Unified Frame-Event Object Tracking." NeurIPS (2025).
  [[paper](https://openreview.net/forum?id=FooiwsnEH9)] 
  [[code](https://github.com/Noctis-A/SpikeFET)]

- **BSA:** Shuai Wang, Malu Zhang, Jingya Wang, Dehao Zhang, Yimeng Shan, Jieyuan Zhang, Yichen Xiao, Honglin Cao, Haonan Zhang, Zeyu Ma, Yang Yang, Haizhou Li.<br />
  "Bipolar Self-attention for Spiking Transformers." NeurIPS (2025).
  [[paper](https://openreview.net/forum?id=nG45z7lJ7D)] 
  [[code]( )]

- **OmniSegmentor:** Bo-Wen Yin, Jiao-Long Cao, Xuying Zhang, Yuming Chen, Ming-Ming Cheng, Qibin Hou .<br />
  "OmniSegmentor: A Flexible Multi-Modal Learning Framework for Semantic Segmentation." NeurIPS (2025).
  [[paper](https://openreview.net/forum?id=Kdqzbx8YGU)] 
  [[code](https://github.com/VCIP-RGBD/DFormer)]

- **TubeletGraph:** Yihong Sun, Xinyu Yang, Jennifer J. Sun, Bharath Hariharan.<br />
  "Tracking and Understanding Object Transformations." NeurIPS (2025).
  [[paper](https://arxiv.org/abs/2511.04678)] 
  [[code](https://tubelet-graph.github.io/)]

- **DAT:** Haowei Sun, Jinwu Hu, Zhirui Zhang, Haoyuan Tian, Xinze Xie, Yufeng Wang, Xiaohua Xie, Yun Lin, Zhuliang Yu, Mingkui Tan.<br />
  "Open-World Drone Active Tracking with Goal-Centered Rewards." NeurIPS (2025).
  [[paper](https://openreview.net/forum?id=Ly2wXKIByI)] 
  [[code](https://github.com/SHWplus/DAT_Benchmark)]

- **LoRATv2:** Liting Lin, Heng Fan, Zhipeng Zhang, Yuqing Huang, Yaowei Wang, Yong Xu, Haibin Ling.<br />
  "LoRATv2: Enabling Low-Cost Temporal Modeling in One-Stream Trackers." NeurIPS (2025).
  [[paper](https://openreview.net/forum?id=q06YjUj0FB)] 
  [[code](https://github.com/LitingLin/LoRATv2)]

- **DSATrack:** Xinyu Zhou, Tongxin Pan, Lingyi Hong, Pinxue Guo, Haijing Guo, Zhaoyu Chen, Kaixun Jiang, Wenqiang Zhang.<br />
  "Dynamic Semantic-Aware Correlation Modeling for UAV Tracking." NeurIPS (2025).
  [[paper](https://arxiv.org/abs/2510.21351)] 
  [[code](https://github.com/zxyyxzz/DSATrack)]
  
- **DOVTrack:** Zekun Qian, Ruize Han, Zhixiang Wang, Junhui Hou, Wei Feng.<br />
  "DOVTrack: Data-Efficient Open-Vocabulary Tracking." NeurIPS (2025).
  [[paper](https://openreview.net/forum?id=DIVHwy7wfh)] 
  [[code](https://github.com/zekunqian/DOVTrack)]
  


### ICCV 2025

- **UMDATrack:** Siyuan Yao, Rui Zhu, Ziqi Wang, Wenqi Ren, Yanyang Yan, Xiaochun Cao.<br />
  "UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.00648)] 
  [[code](https://github.com/Z-Z188/UMDATrack)]

- **XTrack:** Yuedong Tan, Zongwei Wu, Yuqian Fu, Zhuyun Zhou, Guolei Sun, Eduard Zamfi, Chao Ma, Danda Pani Paudel, Luc Van Gool, Radu Timofte.<br />
  "XTrack: Multimodal Training Boosts RGB-X Video Object Trackers." ICCV (2025).
  [[paper](https://arxiv.org/abs/2405.17773)] 
  [[code](https://github.com/supertyd/XTrack)]

- **FlexTrack:** Yuedong Tan, Jiawei Shao, Eduard Zamfir, Ruanjun Li, Zhaochong An, Chao Ma, Danda Paudel, Luc Van Gool, Radu Timofte, Zongwei Wu.<br />
  "What You Have is What You Track: Adaptive and Robust Multimodal Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.05899)] 
  [[code](https://github.com/supertyd/FlexTrack)]

- **TUEs:** Qiangqiang Wu, Yi Yu, Chenqi Kong, Ziquan Liu, Jia Wan, Haoliang Li, Alex C. Kot, Antoni B. Chan.<br />
  "Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.07483)] 
  [[code]( )]

- **ATCTrack:** Xiaokun Feng, Shiyu Hu, Xuchen Li, Dailing Zhang, Meiqi Wu, Jing Zhang, Xiaotang Chen, Kaiqi Huang.<br />
  "ATCTrack: Aligning Target-Context Cues with Dynamic Target States for Robust Vision-Language Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.19875)] 
  [[code](https://github.com/XiaokunFeng/ATCTrack)]

- **CAT:** Yongsheng Yuan, Jie Zhao, Dong Wang, Huchuan Lu.<br />
  "CAT: A Unified Click-and-Track Framework for Realistic Tracking." ICCV (2025).
  [[paper](https://openaccess.thecvf.com/content/ICCV2025/html/Yuan_CAT_A_Unified_Click-and-Track_Framework_for_Realistic_Tracking_ICCV_2025_paper.html)] 
  [[code](https://github.com/ysyuann/CAT)]

- **CompressTracker:** Lingyi Hong, Jinglun Li, Xinyu Zhou, Shilin Yan, Pinxue Guo, Kaixun Jiang, Zhaoyu Chen, Shuyong Gao, Wei Zhang, Hong Lu, Wenqiang Zhang.<br />
  "General Compression Framework for Efficient Transformer Object Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2409.17564)] 
  [[code](https://github.com/LingyiHongfd/CompressTracker)]

- **SMSTracker:** Sixian Chan, Zedong Li, Wenhao Li, Shijian Lyu, Chunhua Shen, Xiaoqin Zhang.<br />
  "SMSTracker: Tri-path Score Mask Sigma Fusion for Multi-Modal Tracking." ICCV (2025).
  [[paper](https://openaccess.thecvf.com/content/ICCV2025/html/Chan_SMSTracker_Tri-path_Score_Mask_Sigma_Fusion_for_Multi-Modal_Tracking_ICCV_2025_paper.html)] 
  [[code](https://github.com/Leezed525/SMSTracker)]

- **VISTA:** Matteo Dunnhofer, Zaira Manigrasso, Christian Micheloni.<br />
  "Is Tracking really more challenging in First Person Egocentric Vision?" ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.16015)] 
  [[code](https://machinelearning.uniud.it/datasets/vista)]
  
- **TrackAny3D:** Mengmeng Wang, Haonan Wang, Yulong Li, Xiangjie Kong, Jiaxin Du, Guojiang Shen, Feng Xia.<br />
  "TrackAny3D: Transferring Pretrained 3D Models for Category-unified 3D Point Cloud Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.19908)] 
  [[code](https://github.com/sallymmx/TrackAny3D)]

- **GSOT3D:** Yifan Jiao, Yunhao Li, Junhua Ding, Qing Yang, Song Fu, Heng Fan, Libo Zhang.<br />
  "GSOT3D: Towards Generic 3D Single Object Tracking in the Wild." ICCV (2025).
  [[paper](https://arxiv.org/abs/2412.02129)] 
  [[code](https://github.com/ailovejinx/GSOT3D)]

 - **TRACT:** Yunhao Li, Yifan Jiao, Dan Meng, Heng Fan, Libo Zhang.<br />
  "Attention to Trajectory: Trajectory-Aware Open-Vocabulary Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2503.08145)] 
  [[code](https://github.com/Nathan-Li123/TRACT)]

- **VOVTrack:** Zekun Qian, Ruize Han, Junhui Hou, Linqi Song, Wei Feng.<br />
  "VOVTrack: Exploring the Potentiality in Raw Videos for Open-Vocabulary Multi-Object Tracking." ICCV (2025).
  [[paper](https://openaccess.thecvf.com/content/ICCV2025/html/Qian_VOVTrack_Exploring_the_Potentiality_in_Raw_Videos_for_Open-Vocabulary_Multi-Object_ICCV_2025_paper.html)] 
  [[code](https://github.com/zekunqian/VOVTrack)]

- **COVTrack:** Zekun Qian, Ruize Han, Zhixiang Wang, Junhui Hou, Wei Feng.<br />
  "COVTrack: Continuous Open-Vocabulary Multi-Object Tracking via Adaptive Multi-Cue Fusion." ICCV (2025).
  [[paper](https://openaccess.thecvf.com/content/ICCV2025/html/Qian_COVTrack_Continuous_Open-Vocabulary_Tracking_via_Adaptive_Multi-Cue_Fusion_ICCV_2025_paper.html)] 
  [[code](https://github.com/zekunqian/COVTrack)]
  
- **MCATrack:** Jiahao Zhang, Zongli Jiang, Jinli Zhang, Yixin Wei, Liang Li, Yizheng Wang, Gang Wang.<br />
  "Tracking Tiny Drones against Clutter: Large-Scale Infrared Benchmark with Motion-Centric Adaptive Algorithm." ICCV (2025).
  [[paper](https://openaccess.thecvf.com/content/ICCV2025/html/Zhang_Tracking_Tiny_Drones_against_Clutter_Large-Scale_Infrared_Benchmark_with_Motion-Centric_ICCV_2025_paper.html)] 
  [[code](https://github.com/zhangjiahao02/MCATrack)]

- **CST Anti-UAV:** Bin Xie, Congxuan Zhang, Fagan Wang, Peng Liu, Feng Lu, Zhen Chen, Weiming Hu.<br />
  "CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes." ICCVW (2025).
  [[paper](https://arxiv.org/abs/2507.23473)] 
  [[code]( )]

- **GUSEM:** Oussama Abdul Hay, Sara Alansari, Mohamad Alansari, Yahya Zweiri.<br />
  "Comparing Representations for Event Camera-based Visual Object Tracking." ICCVW (2025).
  [[paper](https://openaccess.thecvf.com/content/ICCV2025W/NeVi/html/Hay_Comparing_Representations_for_Event_Camera-based_Visual_Object_Tracking_ICCVW_2025_paper.html)] 
  [[code]( )]
  
  
### CVPR 2025

- **ARPTrack:** Shiyi Liang, Yifan Bai, Yihong Gong, Xing Wei.<br />
  "Autoregressive Sequential Pretraining for Visual Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Autoregressive_Sequential_Pretraining_for_Visual_Tracking_CVPR_2025_paper.html)] 
  [[code](https://arptrack.github.io/)]

- **DreamTrack:** Mingzhe Guo, Weiping Tan, Wenyu Ran, Liping Jing, Zhipeng Zhang.<br />
  "DreamTrack: Dreaming the Future for Multimodal Visual Object Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Guo_DreamTrack_Dreaming_the_Future_for_Multimodal_Visual_Object_Tracking_CVPR_2025_paper.html)] 
  [[code]( )]

- **MamTrack:** Chuanyu Sun, Jiqing Zhang, Yang Wang, Huilin Ge, Qianchen Xia, Baocai Yin, Xin Yang.<br />
  "Exploring Historical Information for RGBE Visual Tracking with Mamba." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Exploring_Historical_Information_for_RGBE_Visual_Tracking_with_Mamba_CVPR_2025_paper.html)] 
  [[code](https://github.com/scy0712/MamTrack)]
  
- **PURA:** Zekai Shao, Yufan Hu, Bin Fan, Hongmin Liu.<br />
  "PURA: Parameter Update-Recovery Test-Time Adaption for RGB-T Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Shao_PURA_Parameter_Update-Recovery_Test-Time_Adaption_for_RGB-T_Tracking_CVPR_2025_paper.html)] 
  [[code](https://melantech.github.io/PURA)]

- **ACAttack:** Xinyu Xiang, Qinglong Yan, Hao Zhang, Jiayi Ma.<br />
  "ACAttack: Adaptive Cross Attacking RGB-T Tracker via Multi-Modal Response Decoupling." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Xiang_ACAttack_Adaptive_Cross_Attacking_RGB-T_Tracker_via_Multi-Modal_Response_Decoupling_CVPR_2025_paper.html)] 
  [[code](https://github.com/Xinyu-Xiang/ACAttack)]
  
- **MITracker:** Mengjie Xu, Yitao Zhu, Haotian Jiang, Jiaming Li, Zhenrong Shen, Sheng Wang, Haolin Huang, Xinyu Wang, Qing Yang, Han Zhang, Qian Wang.<br />
  "MITracker: Multi-View Integration for Visual Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2502.20111)] 
  [[code](https://mii-laboratory.github.io/MITracker/)]

- **SPMTrack:** Wenrui Cai, Qingjie Liu, Yunhong Wang.<br />
  "SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.18338)] 
  [[code](https://github.com/WenRuiCai/SPMTrack)]
  
- **ORTrack :** You Wu, Xucheng Wang, Xiangyang Yang, Mengyuan Liu, Dan Zeng, Hengzhou Ye, Shuiwang Li.<br />
  "Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2504.09228)] 
  [[code](https://github.com/wuyou3474/ORTrack)]

- **SGLATrack:** Chaocan Xue, Bineng Zhong, Qihua Liang, Yaozong Zheng, Ning Li, Yuanliang Xue, Shuxiang Song.<br />
  "Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.06625)] 
  [[code](https://github.com/GXNU-ZhongLab/SGLATrack)]

- **DUTrack:** Xiaohai Li, Bineng Zhong, Qihua Liang, Zhiyi Mo, Jian Nong, Shuxiang Song.<br />
  "Dynamic Updates for Language Adaptation in Visual-Language Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.06621)] 
  [[code](https://github.com/GXNU-ZhongLab/DUTrack)]

- **MambaVLT:** Xinqi Liu, Li Zhou, Zikun Zhou, Jianqiu Chen, Zhenyu He.<br />
  "MambaVLT: Time-Evolving Multimodal State Space Model for Vision-Language Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2411.15459)] 
  [[code]( )]

- **Mono3DVLT:** Hongkai Wei, Yang Yang, Shijie Sun, Mingtao Feng, Xiangyu Song, Qi Lei, Hongli Hu, Rong Wang, Huansheng Song, Naveed Akhtar, Ajmal Saeed Mian.<br />
  "Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Wei_Mono3DVLT_Monocular-Video-Based_3D_Visual_Language_Tracking_CVPR_2025_paper.html)] 
  [[code](https://github.com/hongkai-wei/Mono3DVLT)]
  
- **EdgeTAM:** Chong Zhou, Chenchen Zhu, Yunyang Xiong, Saksham Suri, Fanyi Xiao, Lemeng Wu, Raghuraman Krishnamoorthi, Bo Dai, Chen Change Loy, Vikas Chandra, Bilge Soran.<br />
  "EdgeTAM: On-Device Track Anything Model." CVPR (2025).
  [[paper](https://arxiv.org/abs/2501.07256)] 
  [[code](https://github.com/facebookresearch/EdgeTAM)]

- **DAM4SAM:** Jovana Videnovic, Alan Lukezic, Matej Kristan.<br />
  "A Distractor-Aware Memory for Visual Object Tracking with SAM2." CVPR (2025).
  [[paper](https://arxiv.org/abs/2411.17576)] 
  [[code](https://github.com/jovanavidenovic/DAM4SAM)]

- **MUST:** Haolin Qin, Tingfa Xu, Tianhao Li, Zhenxiang Chen, Tao Feng, Jianan Li.<br />
  "MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.17699)] 
  [[code](https://github.com/q2479036243/MUST-Multispectral-UAV-Single-Object-Tracking)]

- **ETAP:** Friedhelm Hamann, Daniel Gehrig, Filbert Febryanto, Kostas Daniilidis, Guillermo Gallego.<br />
  "ETAP: Event-based Tracking of Any Point." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Hamann_ETAP_Event-based_Tracking_of_Any_Point_CVPR_2025_paper.html)] 
  [[code](https://github.com/tub-rip/ETAP)]

- **Chrono:** Inès Hyeonsu Kim, Seokju Cho, Jiahui Huang, Jung Yi, Joon-Young Lee, Seungryong Kim.<br />
  "Exploring Temporally-Aware Features for Point Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Exploring_Temporally-Aware_Features_for_Point_Tracking_CVPR_2025_paper.html)] 
  [[code](https://cvlab-kaist.github.io/Chrono/)]

- **Tracktention:** Zihang Lai, Andrea Vedaldi.<br />
  "Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Tracktention_Leveraging_Point_Tracking_to_Attend_Videos_Faster_and_Better_CVPR_2025_paper.html)] 
  [[code](https://zlai0.github.io/TrackTention/)]

- **TimeTracker:** Haoyue Liu, Jinghan Xu, Yi Chang, Hanyu Zhou, Haozhi Zhao, Lin Wang, Luxin Yan.<br />
  "TimeTracker: Event-based Continuous Point Tracking for Video Frame Interpolation with Non-linear Motion." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_TimeTracker_Event-based_Continuous_Point_Tracking_for_Video_Frame_Interpolation_with_CVPR_2025_paper.html)] 
  [[code]( )]
  
- **ADMCMT:** Huijie Fan, Yu Qiao, Yihao Zhen, Tinghui Zhao, Baojie Fan, Qiang Wang.<br />
  "All-Day Multi-Camera Multi-Target Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Fan_All-Day_Multi-Camera_Multi-Target_Tracking_CVPR_2025_paper.html)] 
  [[code](https://github.com/QTRACKY/ADMCMT)]

- **OmniTrack:** Kai Luo, Hao Shi, Sheng Wu, Fei Teng, Mengfei Duan, Chang Huang, Yuhang Wang, Kaiwei Wang, Kailun Yang.<br />
  "Omnidirectional Multi-Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.04565)] 
  [[code](https://github.com/xifen523/OmniTrack)]

- **DFormerv2:** Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, Qibin Hou.<br />
  "DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation." CVPR (2025).
  [[paper](https://arxiv.org/abs/2504.04701)] 
  [[code](https://github.com/VCIP-RGBD/DFormer)]
  
- **JTD-UAV:** Yifan Wang, Jian Zhao, Zhaoxin Fan, Xin Zhang, Xuecheng Wu, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li.<br />
  "JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems ." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html)] 
  [[code]( )]

- **Anti-UAV:** Yifei Dong, Fengyi Wu, Sanjian Zhang, Guangyu Chen, Yuzhi Hu, Masumi Yano, Jingdong Sun, Siyu Huang, Feng Liu, Qi Dai, Zhi-Qi Cheng.<br />
  "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions." CVPRW (2025).
  [[paper](https://arxiv.org/abs/2504.11967)] 
  [[code]( )]

- **StrongSiamTracker:** Xiaolong Cui, Liu Wan, Lingqi Kong, Jimin Li, Chaojie Zhang, Ruohan Zhao, Panlong Wu, Shan He.<br />
  "StrongSiamTracker: A Siamese Tracker with Dynamic Global Detection for Robust Anti-UAV Tracking." CVPRW (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025W/Anti-UAV/html/Cui_StrongSiamTracker_A_Siamese_Tracker_with_Dynamic_Global_Detection_for_Robust_CVPRW_2025_paper.html)] 
  [[code]( )]

- **DLST:** Jiahao Zhang, Yixin Wei, Jinli Zhang, Zongli Jiang, Peiwen Yu, Yufei Ma, Runan Jin.<br />
  "DLST: Dual-Template Co-Evolution Learning for Robust Long-Term Drone Tracking in Dynamic Environments." CVPRW (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025W/Anti-UAV/html/Zhang_DLST_Dual-Template_Co-Evolution_Learning_for_Robust_Long-Term_Drone_Tracking_in_CVPRW_2025_paper.html)] 
  [[code]( )]
  
- **FDTrack:** Chenxu Peng, Chenxu Wang, Minrui Zou, Danyang Li, Zhengpeng Yang, Yimian Dai, Ming-Ming Cheng, Xiang Li.<br />
  "A Simple Detector with Frame Dynamics is a Strong Tracker." CVPRW (2025).
  [[paper](https://arxiv.org/abs/2505.04917)] 
  [[code](https://github.com/facias914/A-Simple-Detector-is-a-Strong-Tracker)]
  

### ICML 2025

- **MPT:** Jie Zhao, Xin Chen, Yongsheng Yuan, Michael Felsberg, Dong Wang, Huchuan Lu.<br />
  "Efficient Motion Prompt Learning for Robust Visual Tracking." ICML (2025).
  [[paper](https://arxiv.org/abs/2505.16321)] 
  [[code](https://github.com/zj5559/Motion-Prompt-Tracking)]

- **CSTrack:** Xiaokun Feng, Dailing Zhang, Shiyu Hu, Xuchen Li, Meiqi Wu, Jing Zhang, Xiaotang Chen, Kaiqi Huang.<br />
  "CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features." ICML (2025).
  [[paper](https://arxiv.org/abs/2505.19434)] 
  [[code](https://github.com/XiaokunFeng/CSTrack)]
  

### ACM MM 2025

- **RSTrack:** Fansheng Zeng, Bineng Zhong, Haiying Xia, Yufei Tan, Xiantao Hu, Liangtao Shi, Shuxiang Song.<br />
  "Explicit Context Reasoning with Supervision for Visual Tracking." ACM MM (2025).
  [[paper](https://arxiv.org/abs/2507.16191)] 
  [[code](https://github.com/GXNU-ZhongLab/RSTrack)]

- **UniBench300:** Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Chunyang Cheng, Tao Zhou, Xiaojun Wu, Josef Kittler.<br />
  "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking." ACM MM (2025).
  [[paper](https://arxiv.org/abs/2508.10655)] 
  [[code](https://github.com/Zhangyong-Tang/UniBench300)]

- **Gen4Track:** Jiawei Ge, Xinyu Zhang, Jiuxin Cao, Xuelin Zhu, Weijia Liu, Qingqing Gao, Biwei Cao, Kun Wang, Chang Liu, Bo Liu, Chen Feng, Ioannis Patras.<br />
  "Gen4Track: A Tuning-free Data Augmentation Framework via Self-correcting Diffusion Model for Vision-Language Tracking." ACM MM (2025).
  [[paper](https://dl.acm.org/doi/10.1145/3746027.3754956)] 
  [[code]( )]

- **FA3T:** Jiahao Wang, Fang Liu, Licheng Jiao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu, Xinyi Wang.<br />
  "FA3T: Feature-Aware Adversarial Attacks for Multi-modal Tracking." ACM MM (2025).
  [[paper](https://dl.acm.org/doi/10.1145/3746027.3755155)] 
  [[code]( )]

- **MST:** Shilei Wang, Gong Cheng, Pujian Lai, Dong Gao, Junwei Han.<br />
  "Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction." ACM MM (2025).
  [[paper](https://arxiv.org/abs/2508.11531)] 
  [[code](https://github.com/wsumel/MST)]

- **CM3AE:** Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu.<br />
  "CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework." ACM MM (2025).
  [[paper](https://arxiv.org/abs/2504.12576)] 
  [[code](https://github.com/Event-AHU/CM3AE)]

  
  
### IJCAI 2025

- **FastSeqTrack:** Dongdong Li, Zhinan Gao, Yangliu Kuai, Rui Chen.<br />
  "Exploring Effcient and Effective Sequence Learning for Visual Object Tracking." IJCAI (2025).
  [[paper](https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/3672.pdf)] 
  [[code](https://github.com/vision4drones/FastSeqTrack)]

- **SSTrack:** Yutong Kou, Shubo Lin, Liang Li, Bing Li, Weiming Hu, Jin Gao.<br />
  "SSTrack: Sample-interval Scheduling for Lightweight Visual Object Tracking." IJCAI (2025).
  [[paper](https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/3314.pdf)] 
  [[code](https://github.com/Kou-99/SSTrack)]

- **TUMFNet:** Zhaodong Ding, Chenglong Li, Shengqing Miao, Jin Tang.<br />
  "Template-based Uncertainty Multimodal Fusion Network for RGBT Tracking." IJCAI (2025).
  [[paper](https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/2815.pdf)] 
  [[code](https://github.com/dongdong2061/IJCAI25-TUMFNet)]
  
- **GDSTrack:** Shenglan Li, Rui Yao, Yong Zhou, Hancheng Zhu, Kunyang Sun, Bing Liu, Zhiwen Shao, Jiaqi Zhao.<br />
  "Modality-Guided Dynamic Graph Fusion and Temporal Diffusion for Self-Supervised RGB-T Tracking." IJCAI (2025).
  [[paper](https://arxiv.org/abs/2505.03507)] 
  [[code](https://github.com/LiShenglana/GDSTrack)]


### AAAI 2025

- **STTrack:** Xiantao Hu, Ying Tai, Xu Zhao, Chen Zhao, Zhenyu Zhang, Jun Li, Bineng Zhong, Jian Yang.<br />
  "Exploiting Multimodal Spatial-temporal Patterns for Video Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.15691)] 
  [[code](https://github.com/NJU-PCALab/STTrack)]

- **SUTrack:** Xin Chen, Ben Kang, Wanting Geng, Jiawen Zhu, Yi Liu, Dong Wang, Huchuan Lu.<br />
  "SUTrack: Towards Simple and Unified Single Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.19138)] 
  [[code](https://github.com/chenxin-dlut/SUTrack)]

- **MIMTrack:** Xingmei Wang, Guohao Nie, Jiaxiang Meng, Zining Yan.<br />
  "MIMTrack: In-Context Tracking via Masked Image Modeling." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32860)] 
  [[code](https://github.com/chenxin-dlut/SUTrack)]
  
- **AINet:** Andong Lu, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "RGBT Tracking via All-layer Multimodal Interactions with Progressive Fusion Mamba." AAAI (2025).
  [[paper](https://arxiv.org/abs/2408.08827)] 
  [[code]( )]

- **CMS:** Xinyu Xiang, Qinglong Yan, Hao Zhang, Jianfeng Ding, Han Xu, Zhongyuan Wang, Jiayi Ma.<br />
  "Cross-Modal Stealth: A Coarse-to-Fine Attack Framework for RGB-T Tracker ." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32931)] 
  [[code](https://github.com/Xinyu-Xiang/CMS)]
  
- **CAFormer:** Yun Xiao, Jiacong Zhao, Andong Lu, Chenglong Li, Yin Lin, Bing Yin, Cong Liu.<br />
  "Cross-modulated Attention Transformer for RGBT Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2408.02222)] 
  [[code]( )]
  
- **TemTrack:** Jinxia Xie, Bineng Zhong, Qihua Liang, Ning Li, Zhiyi Mo, Shuxiang Song.<br />
  "Robust Tracking via Mamba-based Context-aware Token Learning." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.13611)] 
  [[code](https://github.com/GXNU-ZhongLab/TemTrack)]

- **LMTrack:** Chenlong Xu, Bineng Zhong, Qihua Liang, Yaozong Zheng, Guorong Li, Shuxiang Song.<br />
  "Less is More: Token Context-aware Learning for Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2501.00758)] 
  [[code](https://github.com/XuChenLong/LMTrack)]
  
- **MambaLCT:** Xiaohai Li, Bineng Zhong, Qihua Liang, Guorong Li, Zhiyi Mo, Shuxiang Song.<br />
  "MambaLCT: Boosting Tracking via Long-term Context State Space Model." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.13615)] 
  [[code](https://github.com/GXNU-ZhongLab/MambaLCT)]

- **SSTrack:** Yaozong Zheng , Bineng Zhong, Qihua Liang, Ning Li, Shuxiang Song.<br />
  "Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33155)] 
  [[code](https://github.com/GXNU-ZhongLab/SSTrack)]
  
- **MCITrack:** Ben Kang, Xin Chen, Simiao Lai, Yang Liu, Yi Liu, Dong Wang.<br />
  "Exploring Enhanced Contextual Information for Video-Level Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.11023)] 
  [[code](https://github.com/kangben258/MCITrack/)]
  
- **AsymTrack:** Jiawen Zhu, Huayi Tang, Xin Chen, Xinying Wang, Dong Wang, Huchuan Lu.<br />
  "Two-stream Beats One-stream: Asymmetric Siamese Network for Efficient Visual Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2503.00516)] 
  [[code](https://github.com/jiawen-zhu/AsymTrack)]

- **LVPTrack:** Hongjing Wu, Siyuan Yao, Feng Huang, Shu Wang, Linchao Zhang, Zhuoran Zheng, Wenqi Ren.<br />
  "LVPTrack: High Performance Domain Adaptive UAV Tracking with Label Aligned Visual Prompt Tuning." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32906)] 
  [[code]( )]

- **MM-Tracker:** Mufeng Yao, Jinlong Peng, Qingdong He, Bo Peng, Hao Chen, Mingmin Chi, Chao Liu.<br />
  "MM-Tracker: Motion Mamba for UAV-platform Multiple Object Tracking." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33019)] 
  [[code](https://github.com/YaoMufeng/MMTracker)]
  
- **PSOT:** Zhangbin Li, Jinxing Zhou, Jing Zhang, Shengeng Tang, Kun Li, Dan Guo.<br />
  "Patch-level Sounding Object Tracking for Audio-Visual Question Answering." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.10749)] 
  [[code](https://github.com/jiawen-zhu/AsymTrack)]
  

### Others 2025

- **HFTrack:** Yuheng Jiang, Hebei Li, Dachun Kai, Yansong Peng, Jiahui Yuan, Peilin Xiao, Yueyi Zhang, Xiaoyan Sun.<br />
  "Enhancing Visual Tracking by Leveraging High-frequency Information within Event Signals." BMVC (2025).
  [[paper](https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_265/paper.pdf)] 
  [[code]( )]

- **MFDA:** Zhiheng Li, Weng Zhimin, Yuehuan Wang.<br />
  "Multi-view Feature Discrepancy Attack for Single Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10889698)] 
  [[code]( )]

- **CGTrack:** Weihong Li, Xiaoqiong Liu, Heng Fan, Libo Zhang.<br />
  "CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking." ICRA (2025).
  [[paper](https://arxiv.org/abs/2505.05936)] 
  [[code](https://github.com/Nightwatch-Fox11/CGTrack)]

- **LoReTrack:** Shaohua Dong, Yunhe Feng, Qing Yang, Yuewei Lin, Heng Fan.<br />
  "LoReTrack: Efficient and Accurate Low-Resolution Transformer Tracking." IROS (2025).
  [[paper](https://arxiv.org/abs/2405.17660)] 
  [[code](https://github.com/ShaohuaDong2021/LoReTrack)]

- **BTTrack:** Biao Wang, Wenling Li.<br />
  "BTTrack: Bridge Token Learning for Efficient Visual Object Tracking." IROS (2025).
  [[paper]( )] 
  [[code](https://github.com/Wangbiao2/BTTrack)]
  
- **CLTrack:** Bin Chen, Shenglong Hu, Gang Dong, Lingyan Liang, Dongchao Wen, Kaihua Zhang.<br />
  "Continuously Learning Video-level Object Tokens for Robust UAV tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10887950)] 
  [[code]( )]
  
- **LunarTracking:** Mohammed Leo, Ding Zhang, Hai-Tao Zheng, Haiye Lin.<br />
  "Lunar Tracking: A New Benchmark For Nighttime Tiny Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10890681)] 
  [[code](https://github.com/kk123321x/LunarTracking)]

- **EHDA:** Qiao Li, Kanlun Tan, Qiao Liu, Di Yuan, Xin Li, Yunpeng Liu.<br />
  "Efficient Hierarchical Domain Adaptive Thermal Infrared Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10890354)] 
  [[code]( )]

- **PDTrack:** Yeqiang Liu, Weiran Li, Yanhao Ding, Zhenbo Li.<br />
  "PDTrack: Progressive Distance Association for Multiple Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10888323)] 
  [[code]( )]
  
- **RSM:** Riran Cheng, Xupeng Wang, Ferdous Sohel, Hang Lei.<br />
  "RSM: Refined Saliency Map For Explainable 3D Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10887798)] 
  [[code]( )]

- **MPTrack:** Xueqi Li, Yongjun Zhang, Jianqiang Xia, Fang Dong, Yuanyuan Wang, Yushe Cao, Junze Zhang, Dianxi Shi.<br />
  "Memory Prompt for Multi-Modal Visual Object Tracking." ECAI (2025).
  [[paper](https://ebooks.iospress.nl/doi/10.3233/FAIA250829)] 
  [[code]( )]

- **LRPD:** Qingkuo Hu, Yichen Li, Wenbin Yu.<br />
  "Exploiting Multimodal Prompt Learning and Distillation for RGB-T Tracking." ICMR (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3731715.3733332)] 
  [[code]( )]

- **UMMSOD:** Chaojun Cen, Fei Li, Zhenbo Li.<br />
  "Unified Multi-modal Salient Object Detection via Frequency Prompt and Adapter Tuning." ICMR (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3731715.3733459)] 
  [[code]( )]
  
- **VSS:** Pengfei Wei, Liu Qiao, Zhenyu He, Di Yuan.<br />
  "A Multi-Stream Visual-Spectral-Spatial Adaptive Hyperspectral Object Tracking." ICMR (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3731715.3733262)] 
  [[code]( )]
  
- **DARTer:** Xuzhao Li, Xuchen Li, Shiyu Hu.<br />
  "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking." ICMR (2025).
  [[paper](https://arxiv.org/abs/2505.00752)] 
  [[code]( )]
  


### ArXiv 2025

- **MMVOTSurvey:** Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Hui Li, Shaochuan Zhao, Tao Zhou, Chunyang Cheng, Xiaojun Wu, Josef Kittler.<br />
  "Omni Survey for Multimodality Analysis in Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2508.13000)]
  [[code](https://github.com/Zhangyong-Tang/Awesome-MultiModal-Visual-Object-Tracking)]

- **GOTSurvey:** Fereshteh Aghaee Meibodi, Shadi Alijani, Homayoun Najjaran.<br />
  "A Deep Dive into Generic Object Tracking: A Survey." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.23251)]

- **HIEVT:** Kui Wu, Hao Chen, Churan Wang, Fakhri Karray, Zhoujun Li, Yizhou Wang, Fangwei Zhong.<br />
  "Hierarchical Instruction-aware Embodied Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12606)] 
  [[code](https://sites.google.com/view/hievt)]

- **EVTRA:** Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong.<br />
  "VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.20718)] 
  [[code](https://sites.google.com/view/evt-recovery-assistant)]

- **TrackVLA++:** Jiahang Liu, Yunpeng Qi, Jiazhao Zhang, Minghan Li, Shaoan Wang, Kui Wu, Hanjing Ye, Hong Zhang, Zhibo Chen, Fangwei Zhong, Zhizheng Zhang, He Wang.<br />
  "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2510.07134)] 
  [[code](https://pku-epic.github.io/TrackVLA-plus-plus-Web/)]

- **TrackVLA:** Shaoan Wang, Jiazhao Zhang, Minghan Li, Jiahang Liu, Anqi Li, Kui Wu, Fangwei Zhong, Junzhi Yu, Zhizheng Zhang, He Wang.<br />
  "TrackVLA: Embodied Visual Tracking in the Wild." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.23189)] 
  [[code](https://pku-epic.github.io/TrackVLA-web)]

- **SAM2++:** Jiaming Zhang, Cheng Liang, Yichun Yang, Chenkai Zeng, Yutao Cui, Xinwen Zhang, Xin Zhou, Kai Ma, Gangshan Wu, Limin Wang.<br />
  "SAM 2++: Tracking Anything at Any Granularity." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2510.18822)] 
  [[code](https://tracking-any-granularity.github.io/)]

- **SAMITE:** Qianxiong Xu, Lanyun Zhu, Chenxi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao.<br />
  "SAMITE: Position Prompted SAM2 with Calibrated Memory for Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.21732)] 
  [[code](https://github.com/Sam1224/SAMITE)]
  
- **HiM2SAM:** Ruixiang Chen, Guolei Sun, Yawei Li, Jie Qin, Luca Benini.<br />
  "HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.07603)] 
  [[code](https://github.com/LouisFinner/HiM2SAM)]

- **SOIBench:** Yipei Wang, Shiyu Hu, Shukun Jia, Panxi Xu, Hongfei Ma, Yiping Ma, Jing Zhang, Xiaobo Lu, Xin Zhao.<br />
  "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2508.09524)] 
  [[code]( )]
  
- **TPDOT:** Zhongping Dong, Liming Chen, Mohand Tahar Kechadi.<br />
  "Trajectory Prediction in Dynamic Object Tracking: A Critical Study." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.19341)] 
  [[code]( )]

- **R1-Track:** Biao Wang, Wenwen Li.<br />
  "R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.21980)] 
  [[code](https://github.com/Wangbiao2/R1-Track)]
  
- **MVTD:** Ahsan Baidar Bakht, Muhayy Ud Din, Sajid Javed, Irfan Hussain.<br />
  "MVTD: A Benchmark Dataset for Maritime Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.02866)] 
  [[code](https://github.com/AhsanBaidar/MVTD)]

- **Diff-MM:** Shiyu Xuan, Zechao Li, Jinhui Tang.<br />
  "Diff-MM: Exploring Pre-trained Text-to-Image Generation Model for Unified Multi-modal Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12606)] 
  [[code]( )]

- **UniSOT:** Yinchao Ma, Yuyang Tang, Wenfei Yang, Tianzhu Zhang, Xu Zhou, Feng Wu.<br />
  "UniSOT: a Unified Framework for Multi-Modality Single Object Tracking." TPAMI (2025).
  [[paper](https://ieeexplore.ieee.org/document/11202681)] 
  [[code]( )]

- **UM-ODTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Shengping Zhang, Guorong Li, Xianxian Li, Rongrong Ji.<br />
  "Towards Universal Modal Tracking with Online Dense Temporal Token Learning." TPAMI (2025).
  [[paper](https://arxiv.org/abs/2507.20177)] 
  [[code](https://github.com/GXNU-ZhongLab/ODTrack)]
  
- **MAGTrack:** Anonymous authors.<br />
  "MAGTrack: MLLM-Augmented Grounding and Text Refinement for Language-Guided Tracking." ArXiv (2025).
  [[paper](https://openreview.net/forum?id=IW8S0qIjTG)] 
  [[code]( )]

- **OneTrackerV2:** Anonymous authors.<br />
  "OneTrackerV2: Unified Multimodal Visual Object Tracking with Mixture of Experts." ArXiv (2025).
  [[paper](https://openreview.net/forum?id=sTXCoxide9)] 
  [[code]( )]

- **Uni-MDTrack:** Anonymous authors.<br />
  "Uni-MDTrack: Prompt Unified Single Object Tracking with Deep Fusion of Memory and Dynamic State." ArXiv (2025).
  [[paper](https://openreview.net/forum?id=FMOn4cjJKG)] 
  [[code]( )]

- **VCoT:** Anonymous authors.<br />
  "VCoT: Visual Chain-of-Thought for Continual Learning in Day-Night Object Tracking." ArXiv (2025).
  [[paper](https://openreview.net/forum?id=9T9cxAK7ac)] 
  [[code]( )]
  
- **VPTT:** Jiaming Liu, Yue Wu, Qiguang Miao, Maoguo Gong, Linghe Kong.<br />
  "Revisiting Siamese-based 3D Single Object Tracking with a Versatile Transformer." TPAMI (2025).
  [[paper](https://ieeexplore.ieee.org/document/11045222)] 
  [[code]( )]

- **DyHiT:** Ben Kang, Xin Chen, Jie Zhao, Chunjuan Bo, Dong Wang, Huchuan Lu.<br />
  "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking." IJCV (2025).
  [[paper](https://arxiv.org/abs/2506.20381)] 
  [[code](https://github.com/kangben258/HiT)]

- **VMDA:** Xiantao Hu, Bineng Zhong, Qihua Liang, Zhiyi Mo, Liangtao Shi, Ying Tai, Jian Yang.<br />
  "Visual and Memory Dual Adapter for Multi-Modal Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.23972)] 
  [[code](https://github.com/xuboyue1999/mmtrack)]

- **DMTrack:** Weihong Li, Shaohua Dong, Haonan Lu, Yanhao Zhang, Heng Fan, Libo Zhang.<br />
  "DMTrack: Spatio-Temporal Multimodal Tracking via Dual-Adapter." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2508.01592)] 
  [[code]( )]
  
- **APTrack:** Xiantao Hu, Bineng Zhong, Qihua Liang, Zhiyi Mo, Liangtao Shi, Ying Tai, Jian Yang.<br />
  "Adaptive Perception for Unified Visual Multi-modal Object Tracking." TAI (2025).
  [[paper](https://arxiv.org/abs/2502.06583)] 
  [[code]( )]

- **BR-MoE:** Qingguo Meng, Andong Lu, Zhe Jin.<br />
  "BR-MoE: Blind Multi-Modal Tracking with Route-Dynamic Mixture of Experts." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11077417)] 
  [[code]( )]

- **SRTrack:** Zhiwen Chen, Jinjian Wu, Zhiyu Zhu, Yifan Zhang, Guangming Shi, Junhui Hou.<br />
  "Optimizing Multi-Modal Trackers via Sensitivity-aware Regularized Tuning." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2508.17488)] 
  [[code](https://github.com/zhiwen-xdu/SRTrack)]

- **MSITrack:** Tao Feng, Tingfa Xu, Haolin Qin, Tianhao Li, Shuaihao Han, Xuyang Zou, Zhan Lv, Jianan Li.<br />
  "MSITrack: A Challenging Benchmark for Multispectral Single Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2510.06619)] 
  [[code](https://github.com/Fengtao191/MSITrack)]

- **QuadFusion:** Andong Lu, Mai Wen, Jinhu Wang, Yuanzhi Guo, Chenglong Li, Jin Tang, Bin Luo.<br />
  "Towards General Multimodal Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.11218)] 
  [[code]( )]

- **PFA:** Andong Lu, Yuanzhi Guo, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "Breaking Shallow Limits: Task-Driven Pixel Fusion for Gap-free RGBT Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.11247)] 
  [[code]( )]

- **mmMobileViT:** Mahdi Falaki, Maria A. Amer.<br />
  "Lightweight RGB-T Tracking with Mobile Vision Transformers." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.19154)] 
  [[code]( )]

- **DT-Training:** Jack Hong, Shilin Yan, Zehao Xiao, Jiayin Cai, Xiaolong Jiang, Yao Hu, Henghui Ding.<br />
  "Progressive Scaling Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.19990)] 
  [[code]( )]

- **HyMamba:** Long Gao, Yunhe Zhang, Yan Jiang, Weiying Xie, Yunsong Li.<br />
  "Hyperspectral Mamba for Hyperspectral Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2509.08265)] 
  [[code](https://github.com/lgao001/HyMamba)]

- **SMMT:** Shang Zhang, Huanbin Zhang, Dali Feng, Yujie Cui, Ruoyan Xiong, Cen He.<br />
  "SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.04088)] 
  [[code]( )]
  
- **MATrack:** Xuzhao Li, Xuchen Li, Shiyu Hu.<br />
  "MATrack: Efficient Multiscale Adaptive Tracker for Real-Time Nighttime UAV Operations." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2510.21586)] 
  [[code](https://github.com/zzq-vipsl/DPTrack)]

- **DPTrack:** Zhiqiang Zhu, Xinbo Gao, Wen Lu, Jie Li, Zhaoyang Wang, Mingqian Ge.<br />
  "DPTrack: Directional Kernel-Guided Prompt Learning for Robust Nighttime Aerial Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2510.15449)] 
  [[code](https://github.com/zzq-vipsl/DPTrack)]
  
- **TrackingMiM:** Bingxi Liu, Calvin Chen, Junhao Li, Guyang Yu, Haoqian Song, Xuchen Liu, Jinqiang Cui, Hong Zhang.<br />
  "TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.01535)] 
  [[code]( )]

- **T-SiamTPN:** Hojat Ardi, Amir Jahanshahi, Ali Diba.<br />
  "T-SiamTPN: Temporal Siamese Transformer Pyramid Networks for Robust and Efficient UAV Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.01535)] 
  [[code]( )]

- **MM-UAV:** Tianyang Xu, Jinjie Gu, Xuefeng Zhu, XiaoJun Wu, Josef Kittler.<br />
  "A Tri-Modal Dataset and a Baseline System for Tracking Unmanned Aerial Vehicles." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2511.18344)] 
  [[code](https://xuefeng-zhu5.github.io/MM-UAV/)]

- **VAUAT:** Guanghai Ding, Yihua Ren, Yuting Liu, Qijun Zhao, Shuiwang Li.<br />
  "Vision-Based Anti Unmanned Aerial Technology: Opportunities and Challenges." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.10006)] 
  [[code]( )]

- **FocusTrack:** Ying Wang, Tingfa Xu, Jianan Li.<br />
  "FocusTrack: A Self-Adaptive Local Sampling Algorithm for Efficient Anti-UAV Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.13604)] 
  [[code](https://github.com/vero1925/FocusTrack)]

- **SwiTrack:** Boyue Xu, Ruichao Hou, Tongwei Ren, Dongming Zhou, Gangshan Wu, Jinde Cao.<br />
  "SwiTrack: Tri-State Switch for Cross-Modal Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2511.16227)] 
  [[code](https://github.com/xuboyue1999/SwiTrack)]
  
- **SonarT165:** Yunfeng Li, Bo Wang, Jiahao Wan, Xueyi Wu, Ye Li.<br />
  "SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.15609)] 
  [[code](https://github.com/LiYunfengLYF/SonarT165)]

- **LightFC-X:** Yunfeng Li, Bo Wang, Ye Li.<br />
  "LightFC-X: Lightweight Convolutional Tracker for RGB-X Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.18143)] 
  [[code](https://github.com/LiYunfengLYF/LightFC-X)]

- **UASTrack:** He Wang, Tianyang Xu, Zhangyong Tang, Xiao-Jun Wu, Josef Kittler.<br />
  "UASTrack: A Unified Adaptive Selection Framework with Modality-Customization in Single Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.18220)] 
  [[code](https://github.com/wanghe/UASTrack)]

- **ProTracker:** Tingyang Zhang, Chen Wang, Zhiyang Dou, Qingzhe Gao, Jiahui Lei, Baoquan Chen, Lingjie Liu.<br />
  "ProTracker: Probabilistic Integration for Robust and Accurate Point Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2501.03220)] 
  [[code](https://michaelszj.github.io/protracker)]

- **HMAD:** Boyue Xu, Yi Xu, Ruichao Hou, Jia Bei, Tongwei Ren, Gangshan Wu.<br />
  "RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.17595)] 
  [[code]( )]

- **BTMTrack:** Zhongxuan Zhang, Bi Zeng, Xinyu Ni, Yimin Du.<br />
  "BTMTrack: Robust RGB-T Tracking via Dual-template Bridging and Temporal-Modal Candidate Elimination." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2501.03616)] 
  [[code]( )]

- **ReasoningTrack:** Xiao Wang, Liye Jin, Xufeng Lou, Shiao Wang, Lan Chen, Bo Jiang, Zhipeng Zhang.<br />
  "ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2508.05221)] 
  [[code](https://github.com/Event-AHU/Open_VLTrack)]

- **CRSOT:** Yabin Zhu, Xiao Wang, Chenglong Li, Bo Jiang, Lin Zhu, Zhixiang Huang.<br />
  "CRSOT: Cross-Resolution Object Tracking Using Unaligned Frame and Event Cameras." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11119086)] 
  [[code](https://github.com/Event-AHU/Cross_Resolution_SOT)]

- **FELT:** Xiao Wang, Xufeng Lou, Shiao Wang, Ju Huang, Lan Chen, Bo Jiang.<br />
  "Long-Term Visual Object Tracking with Event Cameras: An Associative Memory Augmented Tracker and A Benchmark Dataset." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2403.05839)] 
  [[code](https://github.com/Event-AHU/FELT_SOT_Benchmark)]

- **Mamba-FETrack V2:** Shiao Wang, Ju Huang, Qingchuan Ma, Jinfeng Gao, Chunyi Xu, Xiao Wang, Lan Chen, Bo Jiang.<br />
  "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.23783)] 
  [[code](https://github.com/Event-AHU/Mamba_FETrack)]

- **ISTASTrack:** Siying Liu, Zikai Wang, Hanle Zheng, Yifan Hu, Xilin Wang, Qingkai Yang, Jibin Wu, Hao Guo, Lei Deng.<br />
  "ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2509.09977)] 
  [[code](https://github.com/lsying009/ISTASTrack)]

- **SDTrack:** Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao, Jieyuan Zhang, Kexin Shi, Jingzhinan Wang, Jason K. Eshraghian, Haicheng Qu, Jiqing Zhang, Malu Zhang, Yang Yang.<br />
  "SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.08703)] 
  [[code]( )]

- **HAD:** Yao Deng, Xian Zhong, Wenxuan Liu, Zhaofei Yu, Jingling Yuan, Tiejun Huang.<br />
  "HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2510.19560)] 
  [[code]( )]

- **TrackSSD-FENet:** Keqi Liu, Rong Xiao, Deng Xiong, Yongsheng Sang, Jiancheng Lv.<br />
  "Joint Frame and Event Object Tracking via Non-causal State Space Duality." ICIC (2025).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-96-9964-3_32)] 
  [[code]( )]

- **DiffDf:** Long Xu, Peng Gao, Wen-Jia Tang, Fei Wang, Ru-Yue Yuan.<br />
  "Towards Effective and Efficient Adversarial Defense with Diffusion Models for Robust Visual Tracking." INFFUS (2025).
  [[paper](https://arxiv.org/abs/2506.00325)] 
  [[code](https://github.com/pgao-lab/DiffDf)]

- **AMGA:** Wei-Long Tian, Peng Gao, Xiao Liu, Long Xu, Hamido Fujita, Hanan Aljuai, Mao-Li Wang.<br />
  "Toward Adaptive Meta-Gradient Adversarial Examples for Visual Tracking." TR (2025).
  [[paper](https://arxiv.org/abs/2505.08999)] 
  [[code](https://github.com/pgao-lab/AMGA)]

- **SFTrack:** Shiao Wang, Xiao Wang, Liye Jin, Bo Jiang, Lin Zhu, Lan Chen, Yonghong Tian, Bin Luo.<br />
  "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12903)] 
  [[code](https://github.com/Event-AHU/SlowFast_Event_Track)]

- **Attack4RGBE:** Qiang Chen, Xiao Wang, Haowen Wang, Bo Jiang, Lin Zhu, Dawei Zhang, Yonghong Tian, Jin Tang.<br />
  "Adversarial Attack for RGB-Event based Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.08703)] 
  [[code](https://github.com/Event-AHU/Adversarial_Attack_Defense)]

- **ATINet:** Mianzhao Wang, Fan Shi, Xu Cheng, Feifei Zhang, Shengyong Chen.<br />
  "An Angular-Temporal Interaction Network for Light Field Object Tracking in Low-Light Scenes." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.21460)] 
  [[code]( )]
  
- **DMP:** Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang.<br />
  "Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.21692)] 
  [[code]( )]

- **DRCT:** Xiantong Zhao, Xiuping Liu, Shengjing Tian, Yinan Han.<br />
  "Robust Single Object Tracking in LiDAR Point Clouds under Adverse Weather Conditions." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2501.07133)] 
  [[code]( )]
  
- **CMDTrack:** Tianlu Zhang, Qiang Zhang, Kurt Debattista, Jungong Han.<br />
  "Cross-Modality Distillation for Multi-modal Tracking." TPAMI (2025).
  [[paper](https://ieeexplore.ieee.org/document/10943265)] 
  [[code](https://github.com/Tianlu-Zhang/TransCMD)]

- **DIFTracker:** Pha Nguyen, Rishi Madhok, Bhiksha Raj, Khoa Luu.<br />
  "Autoregressive Temporal Modeling for Advanced Tracking-by-Diffusion." IJCV (2025).
  [[paper](https://link.springer.com/article/10.1007/s11263-025-02439-x)] 
  [[code]( )]

- **DMD:** Yufan Hu, Zekai Shao, Bin Fan, Hongmin Liu.<br />
  "Dual-level Modality De-biasing for RGB-T Tracking." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/10975100)] 
  [[code]( )]

- **UncTrack:** Siyuan Yao, Yang Guo, Yanyang Yan, Wenqi Ren, Xiaochun Cao.<br />
  "UncTrack: Reliable Visual Object Tracking with Uncertainty-Aware Prototype Memory Network." TIP (2025).
  [[paper](https://arxiv.org/abs/2503.12888)] 
  [[code](https://github.com/ManOfStory/UncTrack)]

- **SNNTrack:** Jiqing Zhang, Malu Zhang, Yuanchen Wang, Qianhui Liu, Baocai Yin, Haizhou Li.<br />
  "Spiking Neural Networks with Adaptive Membrane Time Constant for Event-Based Tracking." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/10857949)] 
  [[code]( )]

- **HPL:** Mianzhao Wang, Fan Shi, Xu Cheng, Shengyong Chen.<br />
  "Prior Knowledge-Driven Hybrid Prompter Learning for RGB-Event Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10962221)] 
  [[code]( )]
  
- **FMTrack:** Yuanliang Xue, Guodong Jin, Bineng Zhong, Tao Shen, Lining Tan, Chaocan Xue.<br />
  "FMTrack: Frequency-aware Interaction and Multi-Expert Fusion for RGB-T Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11134499)] 
  [[code](https://github.com/xyl-507/FMTrack)]

- **AETrack:** Zhiruo Zhu, Bineng Zhong, Qihua Liang, Hongtao Yang, Yaozong Zheng, Ning Li.<br />
  "Adaptive Expert Decision for RGB-T Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10973112)] 
  [[code]( )]

- **MFJA:** Hu Xue, Hao Zhu, Zhidan Ran, Xianlun Tang, Guanqiu Qi, Zhiqin Zhu.<br />
  "Feature Fusion and Enhancement for Lightweight Visible-Thermal Infrared Tracking via Multiple Adapters." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11112670)] 
  [[code](https://github.com/huxue/MFJA)]
  
- **LINR:** Yao Chen, Guancheng Jia, Yufei Zha, Peng Zhang, Yanning Zhang.<br />
  "LINR: A Plug-and-Play Local Implicit Neural Representation Module for Visual Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11030729)] 
  [[code](https://github.com/Xiaochen918/LINR)]

- **MPIT:** Wuwei Wang, Meibo Lv, Lin Zhu, Tuo Han, Yi Zhang, Yuanqing Li.<br />
  "Siamese Visual Tracking with Multi-Parallel Interactive Transformers." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11003183)] 
  [[code](https://github.com/wangwuwei/MPIT)]

- **VFPTrack:** Hongtao Yang, Bineng Zhong, Qihua Liang, Zhiruo Zhu, Yaozong Zheng, Ning Li.<br />
  "Robust RGB-T Tracking via Learnable Visual Fourier Prompt Fine-tuning and Modality Fusion Prompt Generation." TMM (2025).
  [[paper](https://arxiv.org/abs/2509.19733)] 
  [[code]( )]

- **MPANet:** Xiang Liu, Haiyan Li, Victor Sheng, Yujun Ma, Xiaoguo Liang, Guanbo Wang.<br />
  "Scale-Aware Attention and Multi-Modal Prompt Learning with Fusion Adapter for RGBT Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11207526)] 
  [[code]( )]
  
- **PTrMA:** Binxin Luo, Dongxu Liu, Xianrong Peng, Haorui Zuo, Jianlin Zhang, Meihui Li.<br />
  "Progressive Transformer with Multi-modality Adaptation for RGB-T Tracking." TIM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11023155)] 
  [[code]( )]
  
- **ToS:** Chengao Zong, Xin Chen, Jie Zhao, Yang Liu, Huchuan Lu, Dong Wang.<br />
  "Enhancing the Two-Stream Framework for Efficient Visual Tracking." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/11131531)] 
  [[code]( )]

- **HKDT:** Yidong Song, Shilei Wang, Zhaochuan Zeng, Jikai Zheng, Zhenhua Wang, Jifeng Ning.<br />
  "Exploring Pruning-based Efficient Object Tracking via Hybrid Knowledge Distillation." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11162677)] 
  [[code]( )]
  
- **DyTrack:** Jiawen Zhu, Xin Chen, Haiwen Diao, Shuai Li, Jun-Yan He, Chenyang Li, Bin Luo, Dong Wang, Huchuan Lu.<br />
  "Exploring Dynamic Transformer for Efficient Object Tracking." TNNLS (2025).
  [[paper](https://ieeexplore.ieee.org/document/10947615)] 
  [[code]( )]

- **TSTrack:** Jiafeng Li, Shengyao Sun, Yang Wang, Jing Zhang, Li Zhuo.<br />
  "TSTrack: A Light-weight Transformer-based Spatiotemporal Feature Refinement Tracking Algorithm." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11181116)] 
  [[code](https://github.com/BJUTsipl/TSTrack)]
  
- **FWTrack:** Xuyi Fan, Hongguang Li, Yangzhu Wang, Minghao Zhao, Li Shen.<br />
  "Hierarchical Spatial–Temporal UAV Tracking With Three-Dimensional Wavelets for Road Traffic Surveillance." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11087725)] 
  [[code](https://github.com/OrigamiSL/FWTrack)]

- **TDAT:** Yuanliang Xue, Guodong Jin, Tao Shen, Lining Tan, Nian Wang, Jing Gao.<br />
  "Target-Distractor Aware UAV Tracking via Global Agent." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11054299)] 
  [[code](https://github.com/xyl-507/TDAT)]

- **SiamDFF:** Houzhang Fang, Chenxing Wu, Kun Bai, Tianqi Chen, Xiaolin Wang, Xiyang Liu, Yi Chang, Luxin Yan.<br />
  "Infrared UAV Target Tracking with Dynamic Feature Refinement and Global Contextual Attention Knowledge Distillation." TMM (2025).
  [[paper](https://arxiv.org/abs/2512.04581)] 
  [[code]( )]

- **MHITrack:** Lei Lei, Xianxian Li.<br />
  "Multi-modal Hybrid Interaction Vision-language Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10980446)] 
  [[code]( )]

- **LGTrack:** Jianbo Song, Hong Zhang, Yachun Feng, Hanyang Liu, Yifan Yang.<br />
  "Language-guided Visual Tracking: Comprehensive and Effective Multimodal Information Fusion." TOMM (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3757322)] 
  [[code]( )]
  
- **HyperTrack:** Yuedong Tan, Wenfang Sun, Jingyuan Li, Shuwei Hou, Xiaobo Li, Zhe Wang.<br />
  "HyperTrack: A Unified Network for Hyperspectral Video Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11131287)] 
  [[code](https://github.com/supertyd/HyperTrack)]

- **HotMoE:** Wenfang Sun, Yuedong Tan, Jingyuan Li, Shuwei Hou, Xiaobo Li, Yingzhao Shao.<br />
  "HotMoE: Exploring Sparse Mixture-of-Experts for Hyperspectral Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10855488)] 
  [[code](https://github.com/supertyd/hotmoe)]

- **SatSAM2:** Ruijie Fan, Junyan Ye, Huan Chen, Zilong Huang, Xiaolei Wang, Weijia Li.<br />
  "SatSAM2: Motion-Constrained Video Object Tracking in Satellite Imagery using Promptable SAM2 and Kalman Priors." arXiv (2025).
  [[paper](https://arxiv.org/abs/2511.18264)] 
  [[code]( )]

- **TLH:** Xiaoyan Yang, Licheng Jiao, Yangyang Li, Xu Liu, Lingling Li, Puhua Chen.<br />
  "Tracking Like Human: Dynamic Scene Learning Reasoning Tracker in Satellite Videos." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11000100)] 
  [[code]( )]

- **MemTrack:** Jiawei Zhou, Yanni Dong, Yuxiang Zhang, Bo Du.<br /> 
  "Incorporating Prior Knowledge and Temporal Memory Transformer Network for Satellite Video Object Tracking." ISPRS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0924271625003028)] 
  [[code](https://github.com/jiawei-zhou/MemTrack)]

- **SiamTITP:** Jiawei Zhou, Yanni Dong, Bo Du.<br />
  "SiamTITP: Incorporating Temporal Information and Trajectory Prediction Siamese Network for Satellite Video Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11051136)] 
  [[code](https://github.com/jiawei-zhou/SiamTITP)]

- **STAR:** Yuzeng Chen, Qiangqiang Yuan, Yi Xiao, Yuqi Tang, Jiang He, Te Han.<br />
  "STAR: A Unified Spatiotemporal Fusion Framework for Satellite Video Object Tracking." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11063306)] 
  [[code](https://github.com/YZCU/STAR)]
  
- **PUTrack:** Qiuyang Zhang, Wei Song, Cong Liu, Minghua Zhang.<br />
  "PUTrack: Improved Underwater Object Tracking via Progressive Prompting." TII (2025).
  [[paper](https://ieeexplore.ieee.org/document/10892342)] 
  [[code](https://github.com/faicaiwawa/PUTrack)]

- **ASMTrack:** Shaoyang Ma, Gang Chen, Jiale Quan.<br />
  "ASMTrack: Thermal Infrared Target Tracking Network Based on Atkinson-Shiffrin Memory Model." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11184691)] 
  [[code]( )]

- **MGTrack:** Shaoyang Ma, Yao Yang, Kai Zhang, Gang Chen.<br />
  "Transformer-Based Memory Guided Thermal Infrared Target Tracking Framework for Traffic Assistance." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11005508)] 
  [[code]( )]
  
- **NOT-156:** Chen Sun, Xinyu Wang, Shenghua Fan, Xiaobing Dai, Yuting Wan, Xiao Jiang.<br />
  "NOT-156: Night Object Tracking using Low-light and Thermal Infrared: From Multi-modal Common-aperture Camera to Benchmark Datasets." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/10938642)] 
  [[code](http://rsidea.whu.edu.cn/NOT156_dataset.htm)]

- **SP-HST:** Gang He, Long Gao, Langkun Chen, Yan Jiang, Weiying Xie, Yunsong Li.<br />
  "Hyperspectral Object Tracking with Spectral Information Prompt." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11029092)] 
  [[code](https://github.com/lgao001/SP-HST)]

- **CCTrack:** Ye Wang, Shaohui Mei, Mingyang Ma, Yuheng Liu, Tao Gao, Huiyang Han.<br />
  "Hyperspectral Object Tracking With Context-Aware Learning and Category Consistency." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/10928989)] 
  [[code]( )]

- **UBSTrack:** Mohammad Aminul Islam, Jun Zhou, Wangzhi Xing, Yongsheng Gao, Kuldip K. Paliwal.<br />
  "UBSTrack: Unified Band Selection and Multi-Model Ensemble for Hyperspectral Object Tracking." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11007116)] 
  [[code](https://github.com/aamin0102/UBSTrack)]

- **ProFiT:** Yuzeng Chen, Qiangqiang Yuan, Yuqi Tang, Xin Wang, Yi Xiao, Jiang He, Ziyang Lihe, Xianyu Jin.<br />
  "ProFiT: A Prompt-guided Frequency-aware Filtering and Template-enhanced Interaction Framework for Hyperspectral Video Tracking." ISPRS, (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0924271625001893)] 
  [[code](https://github.com/YZCU/ProFiT)]
  
- **SpectralTrack:** Yuzeng Chen, Qiangqiang Yuan, Hong Xie, Yuqi Tang, Yi Xiao, Jiang He.<br />
  "Hyperspectral Video Tracking with Spectral-Spatial Fusion and Memory Enhancement." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/11007172)] 
  [[code](https://github.com/YZCU/SpectralTrack)]

- **HOPL:** Lu Zhang, Rui Yao, Yuhong Zhang, Yong Zhou, Fuyuan Hu, Jiaqi Zhao, Zhiwen Shao.<br />
  "Historical Object-Aware Prompt Learning for Universal Hyperspectral Object Tracking." TOMM (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3736581)] 
  [[code](https://github.com/rayyao/HOPL)]
  
- **HyA-T:** Long Gao, Yunhe Zhang, Langkun Chen, Yan Jiang, Weiying Xie, Yunsong Li.<br />
  "Domain Adapter for Visual Object Tracking based on Hyperspectral Video." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325009574)] 
  [[code](https://github.com/lgao001/HyA-T)]

- **COST:** Chunhui Zhang, Li Liu, Jialin Gao, Xin Sun, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang.<br />
  "COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking." INFFUS (2025).
  [[paper](https://arxiv.org/abs/2504.01321)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking/tree/main/VL-SOT500)] 

- **ATSTrack:** Yihao Zhen, Qiang Wang, Yu Qiao, Liangqiong Qu, Huijie Fan.<br />
  "ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.00454)] 
  [[code]( )]
  
- **SIEVL-Track:** Ning Li, Bineng Zhong, Qihua Liang, Zhiyi Mo, Jian Nong, Shuxiang Song.<br />
  "SIEVL-Track: Exploring Semantic Information Enhancement for Visual-Language Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10845881)] 
  [[code]( )]

- **SATrack:** Yuyang Tang, Yinchao Ma, Tianzhu Zhang.<br />
  "Semantic-aware Network for Natural Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10973162)] 
  [[code]( )]
  
- **ProVLT:** Chengao Zong, Jie Zhao; Xin Chen; Huchuan Lu; Dong Wang.<br />
  "Learning Language Prompt for Vision-Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10947500)] 
  [[code]( )]

- **MAVLT:** Liangtao Shi, Bineng Zhong, Qihua Liang, Xiantao Hu, Zhiyi Mo, Shuxiang Song.<br />
  "Mamba Adapter: Efficient Multi-Modal Fusion for Vision-Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10948517)] 
  [[code](https://github.com/GXNU-ZhongLab/MAVLT)]

- **AVLTrack:** Yuanliang Xue, Bineng Zhong, Guodong Jin, Tao Shen, Lining Tan, Ning Li.<br />
  "AVLTrack: Dynamic Sparse Learning for Aerial Vision-Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10922151)] 
  [[code](https://github.com/xyl-507/AVLTrack)]

- **FFTR:** Donghai Liao, Xiu Shu, Zhihui Li, Qiao Liu, Di Yuan, Xiaojun Chang.<br />
  "Fine-grained Feature and Template Reconstruction for TIR Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10946152)] 
  [[code]( )]

- **ATCTrack:** Xudong Luo, Di Yuan, Xiu Shu, Qiao Liu, Xiaojun Chang, Zhenyu He.<br />
  "Adaptive Trajectory Correction for Underwater Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10900462)] 
  [[code]( )]

- **IDSTT:** Kunlong Zhao, Dawei Zhao, Liang Xiao, Yiming Nie, Yulong Huang, Yonggang Zhang.<br />
  "IDSTT: Iterative Dual-Sample-Teacher for Semi-Supervised Visual Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11180070)] 
  [[code]( )]
  
- **HarNet:** Si Chen, Rui Xu, Yan Yan, Yang Hua, Da-Han Wang, Shunzhi Zhu.<br />
  "Hierarchical Attention-Enhanced Correlation Refinement for Robust Visual Tracking." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11023144)] 
  [[code]( )]

- **CorPN:** Qun Li, Haijun Zhang, Kai Yang, Wei Dai, Jianghong Ma, Yuping Liu.<br />
  "CorPN: Corner Prediction Network for Visual Tracking." TCE (2025).
  [[paper](https://ieeexplore.ieee.org/document/10891175)] 
  [[code]( )]

- **CasCenter:** Qun Li, Haijun Zhang, Kai Yang, Yong-Guo Shi, Deqiang Zeng, Wun-She Yap.<br />
  "CasCenter: A Cascaded Center Network for Visual Tracking." TCE (2025).
  [[paper](https://ieeexplore.ieee.org/document/10909718)] 
  [[code]( )]

- **AMLAA:** Sihang Ma, Yuanfang Chen, Xing Fang, Xiaohan Chen, Muhammad Alam.<br />
  "Metaverse Target-Tracking Security: A Study on Adaptive Metalearning Adversarial Attack Methods." MSMC (2025).
  [[paper](https://ieeexplore.ieee.org/document/10970385)] 
  [[code]( )]

- **ILA:** Ziyi Liu, Caiyun Xie, Wenbing Ding, Dengpan Ye, Long Tang, Qian Wang.<br />
  "Towards Invisible Decision-Based Adversarial Attacks against Visual Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11194202)] 
  [[code]( )]

- **AGA:** Rui Yao, Anqi Zhang, Yong Zhou, Jiaqi Zhao, Bing Liu, Abdulmotaleb El Saddik.<br />
  "Adversarial Geometric Attacks for 3D Point Cloud Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10948328)] 
  [[code](https://github.com/betselot/TATrack)]

- **MSTIC:** Xiaoyu Ni, Liang Yuan, Yongming Han.<br />
  "Multiscale Spatio-Temporal Information Cascade Single-Object Visual Tracker." TIM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10972015)] 
  [[code]( )]

- **TA-Track:** Betselot Yewulu Reta, Wei Xia.<br />
  "3D Single Object Tracking with Temporal-Aware and Attention Mechanism." TIM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10912766)] 
  [[code](https://github.com/betselot/TATrack)]

- **CCETrack:** Yushi Yang, Wei Li, Ying Yao, Bo Zhou, Baojie Fan.<br />
  "3D Single Object Tracking With Cross-Modal Fusion Conflict Elimination." RAL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10930556)] 
  [[code]( )]
  
- **RSTrack:** Juntao Liang, Jiaqi Zhou, Wei Li, Yong Wang, Tianjiang Hu, Qi Wu.<br />
  "Reconstructed and Simulated Dataset for Aerial RGBD Tracking." RAL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10829654)] 
  [[code](https://github.com/TonikLeung/RSTrack)]

- **MRTTrack:** Pujian Lai, Dong Gao, Shilei Wang, Gong Cheng.<br />
  "Mining Representative Tokens via Transformer-based Multi-modal Interaction for RGB-T Tracking." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325008234)] 
  [[code](https://github.com/gao5yy/MRTTrack)]

- **DSTrack:** Zhixing Wang, Kai Wang, Chuanming Tang, Xiang Li, Jianlin Zhang, Lianli Gao.<br />
  "DSTrack: Diffusion-based Sequence Learning for Visual Object Tracking." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325003541)] 
  [[code]( )]

- **VCGDD:** Shaochuan Zhao, Tianyang Xu, Hui Li, Xiao-Jun Wu, Josef Kittler.<br />
  "Visual Complexity Guided Diffusion Defender for Video Object Tracking and Recognition." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325005278)] 
  [[code](https://github.com/DjangoChaogh/VCGDD)]
  
- **GCR:** Kuiran Wang, Xuehui Yu, Wenwen Yu, Guorong Li, Xiangyuan Lan, Qixiang Ye, Jianbin Jiao, Zhenjun Han.<br />
  "ClickTrack: Towards Real-time Interactive Single Object Tracking." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320324009622)] 
  [[code]( )]

- **AUDI-T:** Bin Kang, Zongyu Wang, Dong Liang, Tianyu Ding, Songlin Du.<br />
  "Robust Unsupervised Visual Tracking Via Image-to-Video Identity Knowledge Transferring." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325007691)] 
  [[code]( )]
  
- **ATOTrack:** Sixian Chan, Xianpeng Zeng, Zhoujian Wu, Yu Wang, Xiaolong Zhou, Tinglong Tang, Jie Hu.<br />
  "Adaptive Target Oriented Tracking." TIST (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3732785)] 
  [[code]( )]
  
- **DFDT:** Zhengjun Xu, Detian Huang, Hang Liu, Huihui Wang, Mingxin Lin, Miaohua Ruan.<br />
  "Dual-Frequency Domain Transformer for Thermal Infrared Object Tracking." INFPHY (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S135044952500266X)] 
  [[code](https://github.com/faith1689/DFDT)]

- **Stable-SAM2:** Mohamad Alansari, Iyyakutti Iyappan Ganapathi, Sara Alansari, Hasan Al Marzouqi, Sajid Javed.<br />
  "Visual Tracking by Matching Points Using Diffusion Model." INFFUS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1110016825007914)] 
  [[code](https://github.com/HamadYA/Stable-SAM2)]

- **CLDTracker:** Mohamad Alansari, Sajid Javed, Iyyakutti Iyappan Ganapathi, Sara Alansari, Muzammal Naseer.<br />
  "CLDTracker: A Comprehensive Language Description for Visual Tracking." INFFUS (2025).
  [[paper](https://arxiv.org/abs/2505.23704)] 
  [[code](https://github.com/HamadYA/CLDTracker)]
  
- **MAT:** He Wang, Tianyang Xu, Zhangyong Tang, Xiao-Jun Wu, Josef Kittler.<br />
  "Multi-modal Adapter for RGB-T Tracking." INFFUS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1566253525000132)] 
  [[code](https://github.com/ouha1998/MAT)]
  
- **FPDT:** Lihua Qi, Haijun Wang, Haoyu Qu, Zihao Su.<br />
  "Learning Adaptive Frequency-Prompt Denoising Transformer for UAV Nighttime Tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125013802)] 
  [[code]( )]

- **TMTR:** Guocai Du, Peiyong Zhou, Nurbiya Yadikar, Alimjan Aysa, Kurban Ubul.<br />
  "Toward a Dynamic Tree-Mamba Encoder for UAV Tracking with Vision-Language." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125007774)] 
  [[code]( )]

- **HCSMP:** Wenhao Jiang, Dong Zhao, Chen Wang, Xin Yu, Pattathal V. Arun, Yuta Asano, Pei Xiang, Huixin Zhou.<br />
  "Hyperspectral Video Object Tracking with Cross-Modal Spectral Complementary and Memory Prompt Network." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S095070512501634X)] 
  [[code]( )]

- **TUFNet:** Yisong Liu, Zhao Gao, Yang Cao, Dongming Zhou.<br />
  "Two-stage Unidirectional Fusion Network for RGBT Tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125000310)] 
  [[code]( )]

- **VT2V:** Kaixiang Yan, Wenhua Qian, Cong Bi, Xue Wang.<br />
  "VT2V: A Benchmark of Object Tracking with Aerial & Ground Cooperation and Multi-modal Images." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125019033)] 
  [[code](https://github.com/MrShardfish94/VT2V)]

- **RDT-TEF:** Long Gao, Yuze Ke, Wanlin Zhao, Yang Zhang, Yan Jiang, Gang He, Yunsong Li.<br />
  "RGB-D Visual Object Tracking with Transformer-based Multi-modal Feature Fusion." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125005775)] 
  [[code]( )]

- **TVTracker:** Fang Gao, Wenjie Wu, Yan Jin, Jingfeng Tang, Hanbo Zheng, Shengheng Ma.<br />
  "TVTracker: Target-Adaptive Text-Guided Visual Fusion for Multi-Modal RGB-T Tracking." IOTJ (2025).
  [[paper](https://ieeexplore.ieee.org/document/10948521)] 
  [[code]( )]

- **SCFT:** Shaoyang Ma, Kai Zhang, Yao Yang, Qiyan Liu, Gang Chen.<br />
  "Vision-Inspired Transformer-Based Thermal Infrared Target Tracking Framework for Internet of Things." IOTJ (2025).
  [[paper](https://ieeexplore.ieee.org/document/11142785)] 
  [[code]( )]

- **ASTrack:** Tao Lv, Pai Peng, Jiang Long, Yinghao Ye, Xiaohuan Lu.<br />
  "Adaptive Spatio-Temporal Feature Fusion for Visual Object tracking." IOTJ (2025).
  [[paper](https://ieeexplore.ieee.org/document/11142310)] 
  [[code]( )]
  
- **IAMTrack:** Huiwei Shi, Xiaodong Mu, Hao He, Chengliang Zhong, Bo Zhang, Peng Zhao.<br />
  "IAMTrack: Interframe Appearance and Mdality Tokens Propagation with Temporal Modeling for RGBT Tracking." APIN (2025).
  [[paper](https://link.springer.com/article/10.1007/s10489-025-06438-w)] 
  [[code]( )]
  
- **RMATrack:** Xiaomei Gong, Yi Zhang, Yanli Liu.<br />
  "Visual Tracking with Unified Relation Modeling and Masked Appearance Learning." NUENET (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0893608025010780)] 
  [[code]( )]

- **TATrack:** Wenkang Zhang, Tianyang Xu, Fei Xie, Jinhui Wu, Wankou Yang.<br />
  "TATrack: Target-Oriented Adaptive Vision Transformer for UAV Tracking." NUENET (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0893608025009475)] 
  [[code]( )]

- **HFFTrack:** Sugang Ma, Zhen Wan, Licheng Zhang, Bin Hu, Jinyu Zhang, Xiangmo Zhao.<br />
  "HFFTrack: Transformer Tracking via Hybrid Frequency Features." NUENET (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0893608025001480)] 
  [[code](https://github.com/ElliottZhen/HFFTrack)]

- **DSC:** Yuanming Zhang, Hao Sun.<br />
  "Decoding Split-frequency Representation for Cross-scale Tracking." NUENET (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0893608025004678)] 
  [[code](https://github.com/pellab/DSC)]
  
- **ICSPTrack:** Xianxin Jia, Zhiqiang Hou, Yunlong Wang, Hao Yue, Shuai Hu, Sugang Ma, Xiaobao Yang, Lei Pu.<br />
  "Integrating Multi-scale Appearance and Motion Cues for Visual Tracking via Spatio-temporal Prompt." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125017988)] 
  [[code](https://github.com/jiaxianxin/ICSPTrack)]

- **AIFTrack:** Junze Shi, Jian Shi, Haibo Luo.<br />
  "Adaptive Information Flow Propagation for Visual Tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125008743)] 
  [[code]( )]

- **TBIM:** Huanlong Zhang, Weiqiang Fu, Rui Qi, Bineng Zhong, Xin Wang, Yanfeng Wang.<br />
  "Target-background Interaction Modeling Transformer for Object Tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125002771)] 
  [[code]( )]
  
- **MCTrack:** Jianbo Song, Hong Zhang, Hanyang Liu, Yachun Feng, Yang Han, Yifan Yang.<br />
  "MCTrack: Multi-Cue Spatio-Temporal Object Tracking." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425035997)] 
  [[code]( )]

- **FSTrack:** Jian Shi, Yang Yu, Bin Hui, Junze Shi, Haibo Luo.<br />
  "FSTrack: Visual Tracking with Feature Fusion and Adaptive Selection." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0957417425035109)] 
  [[code]( )]

- **ASTrack:** Zhi Chen, Lijun Liu, Yu Zhen.<br />
  "Transformer Tracking with Auxiliary Search Token." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425005329)] 
  [[code]( )]
  
- **TIPTrack:** Kaixiang Yan, Wenhua Qian.<br />
  "TIPTrack: Time-series Information Prompt Network for RGBT Tracking." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425027721)] 
  [[code]( )]

- **OTKD:** Yongqi Pan, Cheng Zhu, Lailong Luo, Hanlin Tan, Mingrui Lao, Yuxuan Liang.<br />
  "OTKD: A General Knowledge Distillation Pipeline for Object Tracking." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425041624)] 
  [[code]( )]
  
- **Anti-MUAV15:** Shihan Liu, Tianyang Xu, Xue-Feng Zhu, Xiao-Jun Wu, Josef Kittler.<br />
  "Learning Adaptive Detection and Tracking Collaborations with Augmented UAV Synthesis for Accurate Anti-UAV System." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425013016)] 
  [[code](https://github.com/Shihan0325/Anti-MUAV15)]

- **TransADT:** Feng Cheng, Gaoliang Peng, Hang Li, Benqi Zhao, Rui Li.<br />
  "Lightweight Anti-UAV Object Tracking with Visual Sensing Based on Heterogeneous Model Knowledge Distillation." JSEN (2025).
  [[paper](https://ieeexplore.ieee.org/document/11203892)] 
  [[code]( )]
  
- **LightAMAT:** Mingshu Zhang, Fangmei Chen, Fasheng Wang, Binbin Wang, Hanwei Li, Fuming Sun.<br />
  "Lightweight Adaptive Multi-scale Asymmetric Tracker." ASOC (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1568494625013353)] 
  [[code](https://github.com/zmingshu/LightAMAT)]

- **VOTReview:** Zeshi Chen, Caiping Peng, Shuai Liu, Weiping Ding.<br />
  "Visual Object Tracking: Review and Challenges." ASOC (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S156849462500451X)] 
  [[code]( )]
  
- **TransSTC:** Hong Zhang, Wanli Xing, Yifan Yang, Hanyang Liu, Ding Yuan.<br />
  "TransSTC: Transformer Tracker Meets Efficient Spatial-Temporal Cues." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325009641)] 
  [[code](https://github.com/WLCarlos/TransSTC)]

- **DDCTrack:** Guocai Du, Peiyong Zhou, Nurbiya Yadikar, Alimjan Aysa, Kurban Ubul.<br />
  "Dynamic Token Sampling for Efficient Unmanned Aerial Vehicles Transformer Tracking." EAAI (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0952197625026417)] 
  [[code]( )]

- **STPTrack:** Meng Sun, Xiaotao Liu, Yifan Li, Hongyu Wang, Dian Yuan, Jing Liu.<br />
  "Continuous Spatio Temporal Prompts for Visual Tracking." EAAI (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0952197625021918)] 
  [[code]( )]

- **A-CLIP:** Hong Zhu, Qingyang Lu, Lei Xue, Guanglin Yuan, Kaihua Zhang.<br />
  "Joint Feature Extraction and Alignment in Object Tracking with Vision-Language Model." EAAI (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0952197625007870)] 
  [[code]( )]

- **MSTGT:** Fei Pan, Lianyu Zhao, Chenglin Wang, Chunlei Du, Xiaolei Zhao.<br />
  "MSTGT: Multi-scale Spatio-temporal Guidance for Visual Tracking." NEUCOM (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0925231225022556)] 
  [[code](https://github.com/capf-2011/MSTGT)]

- **ECTTrack:** Liang Xu, Zhiqing Guo, Liejun Wang.<br />
  "Efficient hybrid linear self-attention based visual object tracking with LoRA." NEUCOM (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0925231225010070)] 
  [[code](https://github.com/mrlonely426/ECTTrack)]

- **MFNet:** Fanghua Hong, Wanyu Wang, Andong Lu, Lei Liu, Qunjing Wang.<br />
  "Efficient RGBT Tracking via Multi-Path Mamba Fusion Network." SPL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10971948)] 
  [[code]( )]

- **M3Track:** Zhangyong Tang, Tianyang Xu, Xiao-jun Wu, Josef Kittler.<br />
  "M3Track: Meta-Prompt for Multi-Modal Tracking." SPL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10949728)] 
  [[code](https://github.com/Zhangyong-Tang/M3Track)]

- **AdaMoT:** Yongjun Wang, Xiaohui Hao.<br />
  "AdaMoT: Adaptive Motion-Aware Transformer for Efficient Visual Tracking." SPL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10935672)] 
  [[code]( )]

- **EMTrack:** Xianda Xu, Shilong Jing, Zeshu Zhang, Chao Chen, Guangsha Guo, Hengyi Lv.<br />
  "EMTrack: Event-guide Multimodal Transformer for Challenging Single Object Tracking." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11026009)] 
  [[code](https://github.com/lpsg555/EMTrack)]

- **FAEFTrack:** Xilong Shang, Zhaoyuan Zeng, Xiaopeng Li, Cien Fan, Weizheng Jin.<br />
  "Improving Object Tracking Performances with Frequency Learning for Event Cameras." JSEN (2025).
  [[paper](https://ieeexplore.ieee.org/document/10994255)] 
  [[code]( )]
  
- **TGTrack:** Junze Shi, Yang Yu, Bin Hui, Jian Shi, Haibo Luo.<br />
  "Historical States Modeling for Visual Tracking." NCAA (2025).
  [[paper](https://arxiv.org/abs/2501.03616)] 
  [[code]( )]

- **TAAT:** Zhangyong Tang, Tianyang Xu, Xiao-Jun Wu, Josef Kittler.<br />
  "Temporal Aggregation for Real-time RGBT Tracking via Fast Decision-level Fusion." PRL (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0167865525001229)] 
  [[code](https://github.com/Zhangyong-Tang/TAAT-PRL)]

- **TADMT:** Guocai Du, Peiyong Zhou, Nurbiya Yadikar, Alimjan Aysa, Kurban Ubul.<br />
  "Mamba Meets Tracker: Exploiting Token Aggregation and Diffusion for Robust Unmanned Aerial Vehicles Tracking." CAIS (2025).
  [[paper](https://link.springer.com/article/10.1007/s40747-025-01821-z)] 
  [[code]( )]

- **FCSurvey:** Wenqi Zhang, Xinqiang Li, Xingyu Liu, Shiteng Lu, Huanling Tang.<br />
  "Facing Challenges: A Survey of Object Tracking." DSP (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1051200425001046)] 
  [[code]( )]
  
- **BFTrans:** Xinglong Sun, Haijiang Sun, Shan Jiang, Jiacheng Wang, Jiasong Wang.<br />
  "Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.09951)] 
  [[code]( )]

- **CFTrack:** Juntao Liang, Jun Hou, Weijun Zhang, Yong Wang.<br />
  "CFTrack: Enhancing Lightweight Visual Tracking through Contrastive Learning and Feature Matching." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.19705)] 
  [[code]( )]
  
  
  
### NeurIPS 2024

- **ChatTracker:** Yiming Sun, Fan Yu, Shaoxiang Chen, Yu Zhang, Junwei Huang, Chenhui Li, Yang Li, Changbo Wang.<br />
  "ChatTracker: Enhancing Visual Tracking Performance via Chatting with Multimodal Large Language Model." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2411.01756)] 
  [[code]( )]

- **WebUOT-1M:** Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2405.19818)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]

- **VastTrack:** Liang Peng, Junyuan Gao, Xinran Liu, Weihong Li, Shaohua Dong, Zhipeng Zhang, Heng Fan, Libo Zhang.<br />
  "VastTrack: Vast Category Visual Object Tracking." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2403.03493)] 
  [[code](https://github.com/HengLan/VastTrack)]

- **DeTrack:** Xinyu Zhou, Jinglun Li, Lingyi Hong, Kaixun Jiang, Pinxue Guo, Weifeng Ge, Wenqiang Zhang.<br />
  "DeTrack: In-model Latent Denoising Learning for Visual Object Tracking." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2501.02467)] 
  [[code]( )]

- **CSAM:** Tianlu Zhang, Kurt Debattista, Qiang Zhang, Guiguang Ding, Jungong Han.<br />
  "Revisiting Motion Information for RGB-Event Tracking with MOT Philosophy." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=bzGAELYOyL)] 
  [[code]( )]

- **DINTR:** Pha Nguyen, Ngan Le, Jackson Cothren, Alper Yilmaz, Khoa Luu.<br />
  "DINTR: Tracking via Diffusion-based Interpolation." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2410.10053)] 
  [[code]( )]

- **UAV3D:** Hui Ye, Rajshekhar Sunderraman, Shihao Ji.<br />
  "UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial  Vehicles." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2410.11125)] 
  [[code](https://huiyegit.github.io/UAV3D_Benchmark/)]
  
- **MemVLT:** Xiaokun Feng, Xuchen Li, Shiyu Hu, Dailing Zhang, Meiqi Wu, Xiaotang Chen, Kaiqi Huang.<br />
  "MemVLT: Vision-Language Tracking with Adaptive Memory-based Prompts." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=ZK1CZXKgG5)] 
  [[code](https://github.com/XiaokunFeng/MemVLT)]

- **CPDTrack:** Dailing Zhang, Shiyu Hu, Xiaokun Feng, Xuchen Li, Meiqi Wu, Kaiqi Huang.<br />
  "Beyond Accuracy: Tracking more like Human via Visual Search." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=LezAEImfoc)] 
  [[code](https://github.com/ZhangDailing8/CPDTrack)]


### ECCV 2024

- **Diff-Tracker:** Zhengbo Zhang, Li Xu, Duo Peng, Hossein Rahmani, Jun Liu.<br />
  "Diff-Tracker: Text-to-Image Diffusion Models are Unsupervised Trackers." ECCV (2024).
  [[paper](https://arxiv.org/abs/2407.08394)] 
  [[code]( )]

- **LoRAT:** Liting Lin, Heng Fan, Zhipeng Zhang, Yaowei Wang, Yong Xu, Haibin Ling.<br />
  "Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.05231)] 
  [[code](https://github.com/LitingLin/LoRAT)]

- **BenSMOT:** Yunhao Li, Hao Wang, Xue Ma, Jiali Yao, Shaohua Dong, Heng Fan, Libo Zhang.<br />
  "Beyond MOT: Semantic Multi-Object Tracking." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.05021)] 
  [[code](https://github.com/HengLan/SMOT)]

- **VideoMamba:** Kunchang Li, Xinhao Li, Yi Wang, Yinan He, Yali Wang, Limin Wang, Yu Qiao.<br />
  "VideoMamba: State Space Model for Efficient Video Understanding." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.06977)] 
  [[code](https://huggingface.co/OpenGVLab/VideoMamba)]

- **DINO-Tracker:** Narek Tumanyan, Assaf Singer, Shai Bagon, Tali Dekel.<br />
  "DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.14548v1)] 
  [[code](https://dino-tracker.github.io/)]

- **DecoMotion:** Rui Li, Dong Liu.<br />
  "Decomposition Betters Tracking Everything Everywhere." ECCV (2024).
  [[paper](https://arxiv.org/abs/2407.06531)] 
  [[code](https://github.com/qianduoduolr/DecoMotion)]

- **Elysium:** Han Wang, Yanjie Wang, Yongjie Ye, Yuxiang Nie, Can Huang.<br />
  "Elysium: Exploring Object-level Perception in Videos via MLLM." ECCV (2024).
  [[paper](https://arxiv.org/abs/2408.02049)] 
  [[code](https://github.com/Hon-Wong/Elysium)]
  
- **HVTrack:** Qiao Wu, Kun Sun, Pei An, Mathieu Salzmann, Yanning Zhang, Jiaqi Yang.<br />
  "3D Single-object Tracking in Point Clouds with High Temporal Variation." ECCV (2024).
  [[paper](https://arxiv.org/abs/2408.02049)] 
  [[code]( )]

- **AADN:** Zhewei Wu, Ruilong Yu, Qihe Liu, Shuying Cheng, Shilin Qiu, Shijie Zhou.<br />
  "Enhancing Tracking Robustness with Auxiliary Adversarial Defense Networks." ECCV (2024).
  [[paper](https://arxiv.org/abs/2402.17976)] 
  [[code](https://github.com/)]
  

### CVPR 2024

- **MASA:** Siyuan Li, Lei Ke, Martin Danelljan, Luigi Piccinelli, Mattia Segu, Luc Van Gool, Fisher Yu.<br />
  "Matching Anything by Segmenting Anything." CVPR (2024).
  [[paper](https://arxiv.org/abs/2406.04221)] 
  [[code](https://matchinganything.github.io/)]

- **OneTracker:** Lingyi Hong, Shilin Yan, Renrui Zhang, Wanyun Li, Xinyu Zhou, Pinxue Guo, Kaixun Jiang, Yiting Cheng, Jinglun Li, Zhaoyu Chen, Wenqiang Zhang.<br />
  "OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.09634)] 
  [[code](https://)]

- **ARTrackV2:** Yifan Bai, Zeyang Zhao, Yihong Gong, Xing Wei.<br />
  "ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to Describe." CVPR (2024).
  [[paper](https://arxiv.org/abs/2312.17133)] 
  [[code](https://artrackv2.github.io/)]

- **DiffusionTrack:** Fei Xie, Zhongdao Wang, Chao Ma.<br />
  "DiffusionTrack: Point Set Diffusion Model for Visual Object Tracking." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xie_DiffusionTrack_Point_Set_Diffusion_Model_for_Visual_Object_Tracking_CVPR_2024_paper.html)] 
  [[code](https://github.com/VISION-SJTU/DiffusionTrack)]

- **RTracker:** Yuqing Huang, Xin Li, Zikun Zhou, Yaowei Wang, Zhenyu He, Ming-Hsuan Yang.<br />
  "RTracker: Recoverable Tracking via PN Tree Structured Memory." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.19242)] 
  [[code](https://github.com/NorahGreen/RTracker)]

- **NetTrack:** Guangze Zheng, Shijie Lin, Haobo Zuo, Changhong Fu, Jia Pan.<br />
  "NetTrack: Tracking Highly Dynamic Objects with a Net." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.11186)] 
  [[code](https://george-zhuang.github.io/nettrack/)]

- **LMOT:** Xinzhe Wang, Kang Ma, Qiankun Liu, Yunhao Zou, Ying Fu.<br />
  "Multi-Object Tracking in the Dark." CVPR (2024).
  [[paper](https://arxiv.org/abs/2405.06600)] 
  [[code](https://github.com/ying-fu/LMOT)]

- **DeconfuseTrack:** Cheng Huang, Shoudong Han, Mengyu He, Wenbo Zheng, Yuhao Wei.<br />
  "DeconfuseTrack: Dealing with Confusion for Multi-Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.02767)] 
  [[code]( )]

- **DiffMOT:** Weiyi Lv, Yuhang Huang, Ning Zhang, Ruei-Sung Lin, Mei Han, Dan Zeng.<br />
  "DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.02075)] 
  [[code](https://diffmot.github.io/)]

- **GeneralTrack:** Zheng Qin, Le Wang, Sanping Zhou, Panpan Fu, Gang Hua, Wei Tang.<br />
  "Towards Generalizable Multi-Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2406.00429)] 
  [[code](https://github.com/qinzheng2000/GeneralTrack.git)]

- **TLTDMOT:** Sijia Chen, En Yu, Jinyang Li, Wenbing Tao.<br />
  "Delving into the Trajectory Long-tail Distribution for Muti-object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.04700)] 
  [[code](https://github.com/chen-si-jia/Trajectory-Long-tail-Distribution-for-MOT)]
  
- **Un-Track:** Zongwei Wu, Jilai Zheng, Xiangxuan Ren, Florin-Alexandru Vasluianu, Chao Ma, Danda Pani Paudel, Luc Van Gool, Radu Timofte.<br />
  "Single-Model and Any-Modality for Video Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2311.15851)] 
  [[code](https://github.com/Zongwei97/UnTrack)]

- **HIPTrack:** Wenrui Cai, Qingjie Liu, Yunhong Wang.<br />
  "HIPTrack: Visual Tracking with Historical Prompts." CVPR (2024).
  [[paper](https://arxiv.org/abs/2311.02072)] 
  [[code](https://github.com/WenRuiCai/HIPTrack)]

- **AQATrack:** Jinxia Xie, Bineng Zhong, Zhiyi Mo, Shengping Zhang, Liangtao Shi, Shuxiang Song, Rongrong Ji.<br />
  "Autoregressive Queries for Adaptive Tracking with Spatio-Temporal Transformers." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Autoregressive_Queries_for_Adaptive_Tracking_with_Spatio-Temporal_Transformers_CVPR_2024_paper.html)] 
  [[code](https://github.com/GXNU-ZhongLab/AQATrack)]

- **MMA:** Lingxiao Yang, Ru-Yuan Zhang, Yanchen Wang, Xiaohua Xie.<br />
  "MMA: Multi-Modal Adapter for Vision-Language Models." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_MMA_Multi-Modal_Adapter_for_Vision-Language_Models_CVPR_2024_paper.html)] 
  [[code](https://github.com/ZjjConan/Multi-Modal-Adapter)]

- **SDSTrack:** Xiaojun Hou, Jiazheng Xing, Yijie Qian, Yaowei Guo, Shuo Xin, Junhao Chen, Kai Tang, Mengmeng Wang, Zhengkai Jiang, Liang Liu, Yong Liu.<br />
  "SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.16002)] 
  [[code](https://github.com/hoqolo/SDSTrack)]

- **SpatialTracker:** Yuxi Xiao, Qianqian Wang, Shangzhan Zhang, Nan Xue, Sida Peng, Yujun Shen, Xiaowei Zhou.<br />
  "SpatialTracker: Tracking Any 2D Pixels in 3D Space." CVPR (2024).
  [[paper](https://arxiv.org/abs/2404.04319)] 
  [[code](https://henry123-boy.github.io/SpaTracker/)]

- **RALF:** Jooyeon Kim, Eulrang Cho, Sehyung Kim, Hyunwoo J. Kim.<br />
  "Retrieval-Augmented Open-Vocabulary Object Detection." CVPR (2024).
  [[paper](https://arxiv.org/abs/2404.05687)] 
  [[code](https://github.com/mlvlab/RALF)]

- **HDETrack:** Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang.<br />
  "Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline." CVPR (2024).
  [[paper](https://arxiv.org/abs/2309.14611)] 
  [[code](https://github.com/Event-AHU/EventVOT_Benchmark)]

- **CAI:** Yanyan Shao, Shuting He, Qi Ye, Yuchao Feng, Wenhan Luo, Jiming Chen.<br />
  "Context-Aware Integration of Language and Visual References for Natural Language Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.19975)] 
  [[code](https://github.com/twotwo2/QueryNLT)]

- **DTLLM-VLT:** Xuchen Li, Xiaokun Feng, Shiyu Hu, Meiqi Wu, Dailing Zhang, Jing Zhang, Kaiqi Huang.<br />
  "DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM." CVPRW (2024).
  [[paper](https://arxiv.org/abs/2405.12139)] 
  [[code]( )]
  
- **MTMMC:** Sanghyun Woo, Kwanyong Park, Inkyu Shin, Myungchul Kim, In So Kweon.<br />
  "MTMMC: A Large-Scale Real-World Multi-Modal Camera Tracking Benchmark." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.20225)] 
  [[code](https://sites.google.com/view/mtmmc)]

- **ResampleTrack:** Xuhong Ren, Jianlang Chen, Yue Cao, Wanli Xue, Qing Guo, Lei Ma, Jianjun Zhao, Shenyong Chen.<br />
  "ResampleTrack: Online Resampling for Adversarially Robust Visual Tracking." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Ren_ResampleTrack_Online_Resampling_for_Adversarially_Robust_Visual_Tracking_CVPRW_2024_paper.html)] 
  [[code]( )]
  

### WACV 2024

- **ContrasTR:** Pierre-François De Plaen, Nicola Marinello, Marc Proesmans, Tinne Tuytelaars, Luc Van Gool.<br />
  "Contrastive Learning for Multi-Object Tracking With Transformers." WACV (2024).
  [[paper](https://openaccess.thecvf.com/content/WACV2024/papers/De_Plaen_Contrastive_Learning_for_Multi-Object_Tracking_With_Transformers_WACV_2024_paper.pdf)] 
  [[code]()]

- **LaGOT:** Christoph Mayer, Martin Danelljan, Ming-Hsuan Yang, Vittorio Ferrari, Luc Van Gool, Alina Kuznetsova.<br />
  "Beyond SOT: It's Time to Track Multiple Generic Objects at Once." WACV (2024).
  [[paper](https://arxiv.org/abs/2212.11920)] 
  [[code](https://github.com/visionml/pytracking)]

- **SiamABC:** Ram Zaveri, Shivang Patel, Yu Gu, Gianfranco Doretto.<br />
  "Improving Accuracy and Generalization for Efficient Visual Tracking." WACV (2025).
  [[paper](https://arxiv.org/abs/2411.18855)] 
  [[code](https://wvuvl.github.io/SiamABC/)]

- **SMAT:** Goutam Yelluru Gopal, Maria A. Amer.<br />
  "Separable Self and Mixed Attention Transformers for Efficient Object Tracking." WACV (2024).
  [[paper](https://arxiv.org/abs/2309.03979)] 
  [[code](https://github.com/goutamyg/SMAT)]
  
- **DATr:** Jie Zhao, Johan Edstedt, Michael Felsberg, Dong Wang, Huchuan Lu.<br />
  "Leveraging the Power of Data Augmentation for Transformer-based Tracking." WACV (2024).
  [[paper](https://arxiv.org/abs/2309.08264)] 
  [[code](https://github.com/zj5559/DATr)]
  
### AAAI 2024

- **GMMT:** Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Xiao-Jun Wu, Josef Kittler.<br />
  "Generative-based Fusion Mechanism for Multi-Modal Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2309.01728)] 
  [[code](https://github.com/Zhangyong-Tang/GMMT)]

- **ODTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Zhiyi Mo, Shengping Zhang, Xianxian Li.<br />
  "ODTrack: Online Dense Temporal Token Learning for Visual Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.01686)] 
  [[code](https://github.com/GXNU-ZhongLab/ODTrack)]

 - **EVPTrack:** Liangtao Shi, Bineng Zhong, Qihua Liang, Ning Li, Shengping Zhang, Xianxian Li.<br />
  "Explicit Visual Prompts for Visual Object Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.03142)] 
  [[code](https://github.com/GXNU-ZhongLab/EVPTrack)] 

- **UVLTrack:** Yinchao Ma, Yuyang Tang, Wenfei Yang, Tianzhu Zhang, Jinpeng Zhang, Mengxue Kang.<br />
  "Unifying Visual and Vision-Language Tracking via Contrastive Learning." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.11228)] 
  [[code](https://github.com/OpenSpaceAI/UVLTrack)]
  
 - **STCFormer:** Kun Hu, Wenjing Yang, Wanrong Huang, Xianchen Zhou, Mingyu Cao, Jing Ren, Huibin Tan.<br />
  "Sequential Fusion Based Multi-Granularity Consistency for Space-Time Transformer Tracking." AAAI (2024).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29145)] 
  [[code]( )]

- **BAT:** Bing Cao, Junliang Guo, Pengfei Zhu, Qinghua Hu.<br />
  "Bi-directional Adapter for Multimodal Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2312.10611)] 
  [[code](https://github.com/SparkTempest/BAT)]

- **TATrack:** Hongyu Wang, Xiaotao Liu, Yifan Li, Meng Sun, Dian Yuan, Jing Liu.<br />
  "Temporal Adaptive RGBT Tracking with Modality Prompt." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.01244)] 
  [[code]()]

- **Hybrid-SORT:** Mingzhan Yang, Guangxin Han, Bin Yan, Wenhua Zhang, Jinqing Qi, Huchuan Lu, Dong Wang.<br />
  "Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2308.00783)] 
  [[code](https://github.com/ymzis69/HybirdSORT)]

- **SR-Track:** Zepeng Li, Dongxiang Zhang, Sai Wu, Mingli Song, Gang Chen.<br />
  "Sampling-Resilient Multi-Object Tracking." AAAI (2024).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28115)] 
  [[code]( )]

- **USTrack:** Jianqiang Xia, DianXi Shi, Ke Song, Linna Song, XiaoLei Wang, Songchang Jin, Li Zhou, Yu Cheng, Lei Jin, Zheng Zhu, Jianan Li, Gang Wang, Junliang Xing, Jian Zhao.<br />
  "Unified Single-Stage Transformer Network for Efficient RGB-T Tracking." IJCAI (2024).
  [[paper](https://arxiv.org/abs/2308.13764)] 
  [[code]( )]

- **DMTrack:** Guangtong Zhang, Bineng Zhong, Qihua Liang, Zhiyi Mo, Shuxiang Song.<br />
  "Diffusion Mask-Driven Visual-language Tracking." IJCAI (2024).
  [[paper](https://www.ijcai.org/proceedings/2024/183)] 
  [[code]( )]


### ACM MM 2024

- **MambaTrack:** Changcheng Xiao, Qiong Cao, Zhigang Luo, Long Lan.<br />
  "MambaTrack: A Simple Baseline for Multiple Object Tracking with State Space Model." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2408.09178)] 
  [[code]( )]

- **CKD:** Andong Lu, Jiacong Zhao, Chenglong Li, Yun Xiao, Bin Luo.<br />
  "Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2410.11586)] 
  [[code](https://github.com/Multi-Modality-Tracking/CKD)]

- **IIMF:** Liqiu Chen, Yuqing Huang, Hengyu Li, Zikun Zhou, Zhenyu He.<br />
  "Simplifying Cross-modal Interaction via Modality-Shared Features for RGBT Tracking." ACM MM (2024).
  [[paper](https://dl.acm.org/doi/10.1145/3664647.3681564)] 
  [[code](https://github.com/Liqiu-Chen/IIMF)]
  
- **VoxelTrack:** Yuxuan Lu, Jiahao Nie, Zhiwei He, Hongjie Gu, Xudong Lv.<br />
  "VoxelTrack: Exploring Voxel Representation for 3D Point Cloud Object Tracking." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2408.02263)] 
  [[code]( )]

- **DenseTrack:** Yi Lei, Huilin Zhu, Jingling Yuan, Guangli Xiang, Xian Zhong, Shengfeng He.<br />
  "DenseTrack: Drone-based Crowd Tracking via Density-aware Motion-appearance Synergy." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2407.17272)] 
  [[code]( )]

- **GLATrack:** Guangyao Li, Yajun Jian, Yajun Jian, Yan Yan, Yan Yan, Hanzi Wang, Hanzi Wang.<br />
  "GLATrack: Global and Local Awareness for Open-Vocabulary Multiple Object Tracking." ACM MM (2024).
  [[paper](https://dl.acm.org/doi/10.1145/3664647.3681530)] 
  [[code]( )]
  
- **X-Prompt:** Pinxue Guo, Wanyun Li, Hao Huang, Lingyi Hong, Xinyu Zhou, Zhaoyu Chen, Jinglun Li, Kaixun Jiang, Wei Zhang, Wenqiang Zhang.<br />
  "X-Prompt: Multi-modal Visual Prompt for Video Object Segmentation." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2409.19342)] 
  [[code](https://github.com/PinxueGuo/X-Prompt.git)]
  
  
### Others 2024

- **CUTrack:** Jiahao Nie, Zhiwei He, Xudong Lv, Xueyi Zhou, Dong-Kyu Chae, Fei Xie.<br />
  "Towards Category Unification of 3D Single Object Tracking on Point Clouds." ICLR (2024).
  [[paper](https://arxiv.org/abs/2401.11204)] 
  [[code](https://github.com/Haooozi/CUTrack)]

- **SeqTrack3D:** Yu Lin, Zhiheng Li, Yubo Cui, Zheng Fang.<br />
  "SeqTrack3D: Exploring Sequence Information for Robust 3D Point Cloud Tracking." ICRA (2024).
  [[paper](https://arxiv.org/abs/2402.16249)] 
  [[code](https://github.com/aron-lin/seqtrack3d)]

- **VADT:** Guangtong Zhang, Qihua Liang, Zhiyi Mo, Ning Li, Bineng Zhong.<br />
  "Visual Adapt for RGBD Tracking." ICASSP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10447728)] 
  [[code]( )]

- **GFATrack:** Yanfang Deng, Canlong Zhang, Zhixin Li, Chunrong Wei, Zhiwen Wang, Shuqi Pan.<br />
  "Gradually Spatio-Temporal Feature Activation for Target Tracking." ICASSP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10447555)] 
  [[code]( )]

- **TDA-Track:** Changhong Fu, Yiheng Wang, Liangliang Yao, Guangze Zheng, Haobo Zuo, Jia Pan.<br />
  "Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking." IROS (2024).
  [[paper](https://arxiv.org/abs/2409.18533)] 
  [[code](https://github.com/vision4robotics/TDA-Track)]

- **PRL-Track:** Changhong Fu, Xiang Lei, Haobo Zuo, Liangliang Yao, Guangze Zheng, Jia Pan.<br />
  "Progressive Representation Learning for Real-Time UAV Tracking." IROS (2024).
  [[paper](https://arxiv.org/abs/2409.16652)] 
  [[code](https://github.com/vision4robotics/PRL-Track)]

- **MMG:** Baojie Fan, Zhiquan Wang, Jiajun Ai, Caiyu Zhang.<br />
  "Masked Mutual Guidance Transformer Tracking." IROS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10801735)] 
  [[code]( )]
  
- **TMTB:** Yimin Du, Bi Zeng, Qingmao Wei, Boquan Zhang, Huiting Hu.<br />
  "Transformer-Mamba-Based Trident-Branch RGB-T Tracker." PRICAI (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-96-0122-6_4)] 
  [[code]( )]

- **DepthRefiner:** Simiao Lai; Dong Wang; Huchuan Lu.<br />
  "DepthRefiner: Adapting RGB Trackers to RGBD Scenes via Depth-Fused Refinement." ICME (2024).
  [[paper](https://ieeexplore.ieee.org/document/10687717)] 
  [[code]( )]
  
- **HCV:** Liang-Chia Chen, Wei-Ta Chu.<br />
  "HCV: Lightweight Hybrid CNN-Vision Transformer for Visual Object Tracking." MMM (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-96-2061-6_4)] 
  [[code]( )]

- **DMITrack:** Zhiyi Mo, Guangtong Zhang, Jian Nong, Bineng Zhong, Zhi Li.<br />
  "Dual-stream Multi-modal Interactive Vision-language Tracking." MM Asia (2024).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3696409.3700220)] 
  [[code]( )]
  
- **3DPT:** Bocen Li, Yunzhi Zhuge, Shan Jiang, Lijun Wang, Yifan Wang, Huchuan Lu.<br />
  "3D Prompt Learning for RGB-D Tracking." ACCV (2024).
  [[paper](https://openaccess.thecvf.com/content/ACCV2024/html/Li_3D_Prompt_Learning_for_RGB-D_Tracking_ACCV_2024_paper.html)] 
  [[code]( )]

- **Depth-Attention:** Yu Liu, Arif Mahmood, Muhammad Haris Khan.<br />
  "Depth Attention for Robust RGB Tracking." ACCV (2024).
  [[paper](https://arxiv.org/abs/2410.20395)] 
  [[code](https://github.com/LiuYuML/Depth-Attention)]

- **SAM2VOT :** Cheng-Yen Yang, Hsiang-Wei Huang, Pyong-Kun Kim, Chien-Kai Kuo, Jui-Wei Chang, Kwang-Ju Kim, Chung-I Huang, Jenq-Neng Hwang.<br />
  "Adapting SAM 2 for Visual Object Tracking: 1st Place Solution for MMVPR Challenge Multi-Modal Tracking." ICPRW (2024).
  [[paper](https://arxiv.org/abs/2505.18111)] 
  [[code]( )]

- **VPLMMT:** Simiao Lai, Yuntao Wei, Dong Wang, Huchuan Lu.<br />
  "Visual Prompt with Larger Model for Multi-modal Tracking." ICPRW (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-88217-3_20)] 
  [[code]( )]
  
- **DTAT:** Yifan Pan, Tianyang Xu, Xue-Feng Zhu, Xiaoqing Luo, Xiao-Jun Wu, Josef Kittler.<br />
  "Learning Explicit Modulation Vectors for Disentangled Transformer Attention-Based RGB-D Visual Tracking." ICPR (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-78444-6_22)] 
  [[code]( )]

- **VISTAC:** Asfak Ali, Arya Pandit, Shirshendu Mandal, Srinjan Bhattacharjee, Sauptik Maiti, Suvojit Acharjee, Ram Sarkar, Sos S. Agaian, Khalifa Djemal.<br />
  "VISual Tracking in Adverse Conditions." ICPR (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-80139-6_7)] 
  [[code](https://sites.google.com/view/ju-nvisot/home)]
  
- **RADA:** Avinash Chouhan, Mayank Chandak, Arijit Sur, Dibyajyoti Chutia, Shiv Prasad Aggarwal .<br />
  "RADA: Reconstruction Assisted Domain Adaptation for Nighttime Aerial Tracking." ICPR (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-78192-6_21)] 
  [[code](https://github.com/chouhan-avinash/RADA)]
  
- **NT-VOT211:** Yu Liu, Arif Mahmood, Muhammad Haris Khan.<br />
  "NT-VOT211: A Large-Scale Benchmark for Night-time Visual Object Tracking." ACCV (2024).
  [[paper](https://arxiv.org/abs/2410.20421)] 
  [[code](https://github.com/LiuYuML/NV-VOT211)]

  
### ArXiv 2024

- **TBSI:** Bo Li, Fengguang Peng, Tianrui Hui, Xiaoming Wei, Xiaolin Wei, Lijun Zhang, Hang Shi, Si Liu.<br />
  "RGB-T Tracking with Template-Bridged Search Interaction and Target-Preserved Template Updating." TPAMI (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10706882)] 
  [[code](https://github.com/RyanHTR/TBSI)]

- **CTVLT:** Xiaokun Feng, Dailing Zhang, Shiyu Hu, Xuchen Li, Meiqi Wu, Jing Zhang, Xiaotang Chen, Kaiqi Huang.<br />
  "Enhancing Vision-Language Tracking by Effectively Converting Textual Cues into Visual Cues." ICASSP (2025).
  [[paper](https://arxiv.org/abs/2412.19648)] 
  [[code](https://github.com/XiaokunFeng/CTVLT)]
  
- **VOTReview:** Mengmeng Wang, Teli Ma, Shuo Xin, Xiaojun Hou, Jiazheng Xing, Guang Dai, Jingdong Wang, Yong Liu.<br />
  "Visual Object Tracking across Diverse Data Modalities: A Review." arXiv (2024).
  [[paper](https://arxiv.org/abs/2412.09991)] 
  [[code]( )]

- **TIRReview:** Di Yuan, Haiping Zhang, Xiu Shu, Qiao Liu, Xiaojun Chang, Zhenyu He, Guming Shi.<br />
  "Thermal Infrared Target Tracking: A Comprehensive Review." TIM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10339340)] 
  [[code]( )]

- **RGBTReview:** Haiping Zhang, Di Yuan, Xiu Shu, Zhihui Li, Qiao Liu, Xiaojun Chang, Zhenyu He, Guming Shi.<br />
  "A Comprehensive Review of RGBT Tracking." TIM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10616144)] 
  [[code]( )]
  
- **UAVReview:** Nianyi Sun, Jin Zhao, Qing Shi, Chang Liu, Peng Liu.<br />
  "Moving Target Tracking by Unmanned Aerial Vehicle: A Survey and Taxonomy." TII (2024).
  [[paper](https://ieeexplore.ieee.org/document/10445025)] 
  [[code]( )]

- **MMTrackingReview:** Pengyu Zhang, Dong Wang, Huchuan Lu.<br />
  "Multi-modal visual tracking: Review and experimental comparison ." CVM (2024).
  [[paper](https://link.springer.com/article/10.1007/s41095-023-0345-5)] 
  [[code](https://github.com/zhang-pengyu/Multimodal-Tracking-Survey)]
  
- **GLEE:** Junfeng Wu, Yi Jiang, Qihao Liu, Zehuan Yuan, Xiang Bai, Song Bai.<br />
  "General Object Foundation Model for Images and Videos at Scale." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2312.09158)] 
  [[code](https://glee-vision.github.io/)]

- **EfficientTAM:** Yunyang Xiong, Chong Zhou, Xiaoyu Xiang, Lemeng Wu, Chenchen Zhu, Zechun Liu, Saksham Suri, Balakrishnan Varadarajan, Ramya Akula, Forrest Iandola, Raghuraman Krishnamoorthi, Bilge Soran, Vikas Chandra.<br />
  "Efficient Track Anything." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.18933)] 
  [[code](https://yformer.github.io/efficient-track-anything/)]

- **DTVLT:** Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang.<br />
  "DTVLT: A Multi-modal Diverse Text Benchmark for Visual Language Tracking Based on LLM." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2410.02492)] 
  [[code](http://videocube.aitestunion.com/)]

- **COTD:** Xiaoyu Guo, Pengzhi Zhong, Hao Zhang, Ling Huang, Defeng Huang, Shuiwang Li.<br />
  "Camouflaged Object Tracking: A Benchmark." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.13877)] 
  [[code](https://github.com/openat25/HIPTrack-MLS)]

- **UW-COT:** Chunhui Zhang, Li Liu, Guanjie Huang, Zhipeng Zhang, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang.<br />
  "Underwater Camouflaged Object Tracking Meets Vision-Language SAM2." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.16902)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]

- **VLT:** Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang.<br />
  "Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.08887)] 
  [[code]( )]

- **LLOT:** Pengzhi Zhong, Xiaoyu Guo, Defeng Huang, Xiaojun Peng, Yian Li, Qijun Zhao, Shuiwang Li.<br />
  "Low-Light Object Tracking: A Benchmark." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.11463)] 
  [[code](https://github.com/OpenCodeGithub/H-DCPT)]

- **RGBEMOT:** Zhiyu Zhu, Junhui Hou, Jinjian Wu, Dapeng Wu.<br />
  "RGB-Event MOT: A Cross-Modal Benchmark for Multi-Object Tracking." ArXiv (2024).
  [[paper](https://openreview.net/forum?id=Z1Em654CSE)] 
  [[code](https://github.com/ZHU-Zhiyu/RGBEvt-MOT)]

- **TrackNetV4:** Arjun Raj, Lei Wang, Tom Gedeon.<br />
  "TrackNetV4: Enhancing Fast Sports Object Tracking with Motion Attention Maps." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.14543v1)] 
  [[code]( )]
  
- **BlinkTrack:** Yichen Shen, Yijin Li, Shuo Chen, Guanglin Li, Zhaoyang Huang, Hujun Bao, Zhaopeng Cui, Guofeng Zhang.<br />
  "BlinkTrack: Feature Tracking over 100 FPS via Events and Images." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.17981)] 
  [[code]( )]

- **MugTracker:** Hong Zhu, Pingping Zhang, Lei Xue, Guanglin Yuan.<br />
  "Multi-modal Understanding and Generation for Object Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10777574)] 
  [[code]( )]
  
- **TrackMamba:** Jiaming Zhang, Cheng Liang, Yutao Cui, Xiangbo Shu, Gangshan Wu, Limin Wang .<br />
  "TrackMamba: Mamba-Transformer Tracking." ArXiv (2024).
  [[paper](https://openreview.net/forum?id=V7QRVEZ0le)] 
  [[code]( )]

- **VLTVerse:** Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang.<br />
  "How Texts Help? A Fine-grained Evaluation to Reveal the Role of Language in Vision-Language Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.15600)] 
  [[code](http://metaverse.aitestunion.com/)]

- **CPIPTrack:** Hong Zhu, Qingyang Lu, Lei Xue, Pingping Zhang, Guanglin Yuan.<br />
  "Vision-Language Tracking With CLIP and Interactive Prompt Learning." TITS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10817474)] 
  [[code]( )]

- **PGM:** Hengyou Li, Xinyan Liu, Guorong Li, Shuhui Wang, Laiyun Qing, Qingming Huang.<br />
  "Boost Tracking by Natural Language With Prompt-Guided Grounding." TITS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10756281)] 
  [[code]( )]

- **BioDrone:** Xin Zhao, Shiyu Hu, Yipei Wang, Jing Zhang, Yimin Hu, Rongshuai Liu, Haibin Ling, Yin Li, Renshu Li, Kun Liu, Jiadong Li.<br />
  "BioDrone: A Bionic Drone-Based Single Object Tracking Benchmark for Robust Vision." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-023-01937-0)] 
  [[code](http://biodrone.aitestunion.com/)]

- **UniMod1K:** Xue-Feng Zhu, Tianyang Xu, Zongtao Liu, Zhangyong Tang, Xiao-Jun Wu, Josef Kittler.<br />
  "UniMod1K: Towards a More Universal Large-Scale Dataset and Benchmark for Multi-modal Learning." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-01999-8)] 
  [[code](https://github.com/xuefeng-zhu5/UniMod1K)]

- **IPL:** Andong Lu, Chenglong Li, Jiacong Zhao, Jin Tang, Bin Luo.<br />
  "Modality-missing RGBT Tracking: Invertible Prompt Learning and High-quality Benchmarks ." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-02311-4)] 
  [[code](https://github.com/mmic-lcl)]
  
- **SATrack:** Yinchao Ma, Qianjin Yu, Wenfei Yang, Tianzhu Zhang, Jinpeng Zhang.<br />
  "Learning Discriminative Features for Visual Tracking via Scenario Decoupling ." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-02307-0)] 
  [[code]( )]
    
- **EMTrack:** Chang Liu, Ziqi Guan, Simiao Lai, Yang Liu, Huchuan Lu, Dong Wang.<br />
  "EMTrack: Efficient Multimodal Object Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10747517)] 
  [[code]( )]

- **PiVOT:** Shih-Fang Chen, Jun-Cheng Chen, I-Hong Jhuo, Yen-Yu Lin.<br />
  "Improving Visual Object Tracking through Visual Prompting." TMM (2024).
  [[paper](https://arxiv.org/abs/2409.18901)] 
  [[code](https://github.com/chenshihfang/GOT)]

- **Linker:** Zizheng Xun, Shangzhe Di, Yulu Gao, Zongheng Tang, Gang Wang, Si Liu, Bo Li.<br />
  "Linker: Learning Long Short-term Associations for Robust Visual Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10416989)] 
  [[code]( )]
  
- **SIMix:** Jinpu Zhang, Ziwen Li, Ruonan Wei, Yuehuan Wang.<br />
  "Augment One with Others: Generalizing to Unforeseen Variations for Visual Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10814671)] 
  [[code]( )]
  
- **DANet:** Yingkai Fu, Meng Li, Wenxi Liu, Yuanchen Wang, Jiqing Zhang, Baocai Yin, Xiaopeng Wei, Xin Yang.<br />
  "Distractor-Aware Event-Based Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/document/10299598)] 
  [[code]( )]

- **SiamGAT:** Yanyan Shao, Dongyan Guo, Ying Cui, Zhenhua Wang, Liyan Zhang, Jianhua Zhang<br />
  "Graph Attention Network for Context-Aware Visual Tracking." TNNLS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10693651)] 
  [[code](https://git.io/SiamGAT)]

- **MAFNet:** Lei Liu, Mengya Zhang, Cheng Li, Chenglong Li, Jin Tang<br />
  "Cross-Modal Object Tracking via Modality-Aware Fusion Network and a Large-Scale Dataset." TNNLS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10545535)] 
  [[code](https://github.com/liulei970507/MAFNet)]
  
- **SiamTADT:** Luming Li, Chenglizhao Chen, Xu Yu, Shanchen Pang; Hong Qin<br />
  "SiamTADT: A Task-Aware Drone Tracker for Aerial Autonomous Vehicles." TVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10755105)] 
  [[code](https://github.com/xl0312/SiamTADT)]
  
- **NiDR:** Xu Lei, Yan Zhang, Chang Xu, Wensheng Cheng, Wen Yang.<br />
  "NiDR: Nighttime Aerial Tracking via Decoupled Representations." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10770249)] 
  [[code]( )]

- **DAT:** Haowei Sun, Jinwu Hu, Zhirui Zhang, Haoyuan Tian, Xinze Xie, Yufeng Wang, Zhuliang Yu, Xiaohua Xie, Mingkui Tan.<br />
  "A Cross-Scene Benchmark for Open-World Drone Active Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.00744)] 
  [[code](https://dat-benchmark.framer.website/)]

- **AVTrack:** You Wu, Yongxin Li, Mengyuan Liu, Xucheng Wang, Xiangyang Yang, Hengzhou Ye, Dan Zeng, Qijun Zhao, Shuiwang Li.<br />
  "Learning Adaptive and View-Invariant Vision Transformer with Multi-Teacher Knowledge Distillation for Real-Time UAV Tracking." ArXiv (2024).
  [[icml](https://openreview.net/pdf?id=eaNLvrP8n1)] 
  [[paper](https://arxiv.org/abs/2412.20002)] 
  [[code](https://github.com/wuyou3474/AVTrack)]

- **MambaNUT:** You Wu, Xiangyang Yang, Xucheng Wang, Hengzhou Ye, Dan Zeng, Shuiwang Li.<br />
  "MambaNUT: Nighttime UAV Tracking via Mamba and Adaptive Curriculum Learning." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.00626)] 
  [[code]( )]
  
- **DaDiff:** Haobo Zuo, Changhong Fu, Guangze Zheng, Liangliang Yao, Kunhan Lu, Jia Pan.<br />
  "DaDiff: Domain-aware Diffusion Model for Nighttime UAV Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2410.12270)] 
  [[code](https://github.com/vision4robotics/DaDiff)]

- **LDEnhancer:** Liangliang Yao, Changhong Fu, Yiheng Wang, Haobo Zuo, Kunhan Lu.<br />
  "Enhancing Nighttime UAV Tracking with Light Distribution Suppression." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.16631)] 
  [[code](https://github.com/vision4robotics/LDEnhancer)]

- **BihoT:** Hanzheng Wang, Wei Li, Xiang-Gen Xia, Qian Du.<br />
  "BihoT: A Large-Scale Dataset and Benchmark for Hyperspectral Camouflaged Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.12232)] 
  [[code]( )]

- **DDFNet:** Chenglong Li, Tao Wang, Zhaodong Ding, Yun Xiao, Jin Tang.<br />
  "Dynamic Disentangled Fusion Network for RGBT Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.08441)] 
  [[code]( )]

- **DS-MESA:** Pengcheng Shao, Tianyang Xu, Xuefeng Zhu, Xiaojun Wu, Josef Kittler.<br />
  "Dynamic Subframe Splitting and Spatio-Temporal Motion Entangled Sparse Attention for RGB-E Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.17560)] 
  [[code]( )]

- **MambaTrack:** Chunhui Zhang, Li Liu, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "MambaTrack: Exploiting Dual-Enhancement for Night UAV Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.15761)] 
  [[code]( )]

- **MambaEVT:** Xiao Wang, Chao wang, Shiao Wang, Xixi Wang, Zhicheng Zhao, Lin Zhu, Bo Jiang.<br />
  "MambaEVT: Event Stream based Visual Object Tracking using State Space Model." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.10487)] 
  [[code](https://github.com/Event-AHU/MambaEVT)]

- **MambaVT:** Simiao Lai, Chang Liu, Jiawen Zhu, Ben Kang, Yang Liu, Dong Wang, Huchuan Lu.<br />
  "MambaVT: Spatio-Temporal Contextual Modeling for robust RGB-T Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.07889)] 
  [[code]( )]

- **TrackingMamba:** Qingwang Wang, Liyao Zhou, Pengcheng Jin, Xin Qu, Hangwei Zhong, Haochen Song, Tao Shen.<br />
  "TrackingMamba: Visual State Space Model for Object Tracking." JSTAR (2024).
  [[paper](https://ieeexplore.ieee.org/document/10678881)] 
  [[code](https://github.com/KustTeamWQW/TrackingMamba)]
  
- **FocTrack:** Jian Tao, Sixian Chan, Zhenchao Shi, Cong Bai, Shengyong Chen.<br />
  "FocTrack: Focus Attention for Visual Tracking." PR (2024).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320324008793)] 
  [[code]( )]

- **UniRTL:** Lian Zhang, Lingxue Wang, Yuzhen Wu, Mingkun Chen, Dezhi Zheng, Liangcai Cao, Bangze Zeng, Yi Cai.<br />
  "UniRTL: A Universal RGBT and Low-light Benchmark for Object Tracking." PR (2024).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320324007350)] 
  [[code](https://github.com/Liamzh0331/Unismot)]

- **CVT-Track:** Jianan Li, Xiaoying Yuan, Haolin Qin, Ying Wang, Xincong Liu, Tingfa Xu.<br />
  "CVT-Track: Concentrating on Valid Tokens for One-Stream Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10659749)] 
  [[code]( )]

- **MFDSTrack:** Yamin Han, Mingyu Cai, Jie Wu, Zhixuan Bai, Tao Zhuo, Hongming Zhang.<br />
  "Visual Object Tracking with Multi-Frame Distractor Suppression." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10741210)] 
  [[code]( )]

- **AMATrack:** Ping Ye, Gang Xiao, Jun Liu.<br />
  "AMATrack: A Unified Network With Asymmetric Multimodal Mixed Attention for RGBD Tracking." TIM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10623547)] 
  [[code]( )]

- **LDLC:** Jun Yu, Zhongpeng Cai, Yihao Li, Lei Wang, Fang Gao, Ye Yu.<br />
  "Language-guided Dual-modal Local Correspondence for Single Object Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10659157)] 
  [[code]( )]
  
- **MGTrack:** Jiabing Xiong, Qiang Ling.<br />
  "Mask-Guided Siamese Tracking with a Frequency-Spatial Hybrid Network." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10662977)] 
  [[code](https://github.com/jiabingxiing/MGTrack)]
  
- **KSTrack:** Yuhang He, Zhiheng Ma, Xing Wei, Yihong Gong.<br />
  "Knowledge Synergy Learning for Multi-Modal Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10388341)] 
  [[code]( )]

- **SiamSRT:** Bo Huang, Zeyang Dou, Junjie Chen, Jianan Li, Ning Shen, Ying Wang.<br />
  "Searching Region-Free and Template-Free Siamese Network for Tracking Drones in TIR Videos." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10352116)] 
  [[code]( )]

- **SATDark:** Jialei Pan, Yanfeng Gu, Guoming Gao, Qiang Wang, Shaochuan Wu.<br />
  "SATDark: A Satellite Video Low-light Tracking Benchmark for Dark and Weak Vehicles." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10741334)] 
  [[code]( )]

- **HDSP:** Rui Yao, Lu Zhang, Yong Zhou, Hancheng Zhu, Jiaqi Zhao, Zhiwen Shao.<br />
  "Hyperspectral Object Tracking with Dual-Stream Prompt." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10798510)] 
  [[code](https://github.com/rayyao/HDSP)]

- **PHTrack:** Yuzeng Chen, Yuqi Tang, Xin Su, Jie Li, Yi Xiao, Jiang He, Qiangqiang Yuan.<br />
  "PHTrack: Prompting for Hyperspectral Video Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10680554)] 
  [[code](https://github.com/YZCU/PHTrack)]

- **LGSAT:** Langkun Chen, Long Gao, Yan Jiang, Yunsong Li, Gang He, Jifeng Ning.<br />
  "Local-Global Self-Attention for Transformer-based Object Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/document/10613604)] 
  [[code](https://github.com/lgao001/LGSAT)]

- **MVCTrack:** Zhaofeng Hu, Sifan Zhou, Shibo Zhao, Zhihang Yuan.<br />
  "MVCTrack: Boosting 3D Point Cloud Tracking via Multimodal-Guided Virtual Cues." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.02734)] 
  [[code](https://github.com/StiphyJay/MVCTrack)]
  
- **SiamMo:** Yuxiang Yang, Yingqi Deng, Jing Zhang, Hongjie Gu, Zhekang Don.<br />
  "SiamMo: Siamese Motion-Centric 3D Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.01688)] 
  [[code](https://github.com/HDU-VRLab/SiamMo)]

- **TP2N:** Basit Alawode, Sajid Javed, Arif Mahmood, Jiri Matas.<br />
  "Predicting the Best of N Visual Trackers." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2407.15707)] 
  [[code](https://github.com/BasitAlawode/Best_of_N_Trackers)]

- **PDAT:** Qiao Li, Kanlun Tan, Qiao Liu, Di Yuan, Xin Li, Yunpeng Liu.<br />
  "Progressive Domain Adaptation for Thermal Infrared Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2407.19430)] 
  [[code]( )]
  
- **FDTrack:** Zhao Gao, Dongming Zhou, Jinde Cao, Yisong Liu, Qingqing Shan.<br />
  "FDTrack: A Dual-head Focus Tracking Network with Frequency Enhancement." JSEN (2024).
  [[paper](https://ieeexplore.ieee.org/document/10778233)] 
  [[code]( )]

- **LMINet:** Jiatian Mei, Juxiang Zhou, Jun Wang, Jia Hao, Dongming Zhou, Jinde Cao.<br />
  "Learning Multi-frequency Integration Network for RGBT Tracking." JSEN (2024).
  [[paper](https://ieeexplore.ieee.org/document/10458005)] 
  [[code](https://github.com/mjt1312/Lminet)]

- **ETIT:** Weisheng Li, Shunping Chen, Yuhao Fang, Yidong Peng.<br />
  "Efficient Thermal Infrared Tracking via Multi-enhancement and Spatial Shift Pyramid." JSEN (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10630644)] 
  [[code]( )]

- **STNet:** Yidi Li, Hong Liu, Bing Yang.<br />
  "STNet: Deep Audio-Visual Fusion Network for Robust Speaker Tracking." TMM (2024).
  [[paper](https://arxiv.org/abs/2410.05964)] 
  [[code](https://github.com/liyidi/STNet)]

- **MATrack:** Guotian Zeng, Bi Zeng, Qingmao Wei, Huiting Hu, Hong Zhang.<br />
  "Visual Object Tracking with Mutual Affinity Aligned to Human Intuition." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10539277)] 
  [[code]( )]

- **CGBA:** Xingsen Huang, Deshui Miao, Hongpeng Wang, Yaowei Wang, Xin Li.<br />
  "Context-Guided Black-Box Attack for Visual Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10489919)] 
  [[code]( )]
  
- **OTETrack:** Li Shen, Xuyi Fan, Hongguang Li.<br />
  "Overlapped Trajectory-Enhanced Visual Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10630872)] 
  [[code](https://github.com/OrigamiSL/OTETrack)]

- **VLCTrack:** Jiahao Wang, Fang Liu, Licheng Jiao, Yingjia Gao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu.<br />
  "Visual and Language Collaborative Learning for RGBT Object Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10620225)] 
  [[code]( )]

- **STMT:** Dengdi Sun, Yajie Pan, Andong Lu, Chenglong Li, Bin Luo.<br />
  "Transformer RGBT Tracking With Spatio-Temporal Multimodal Tokens." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10589660)] 
  [[code](https://github.com/yinghaidada/STMT)]

- **TGTrack:** Liang Chen, Bineng Zhong, Qihua Liang, Yaozong Zheng, Zhiyi Mo, Shuxiang Song.<br />
  "Top-down Cross-modal Guidance for Robust RGB-T Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10614652)] 
  [[code]( )]

- **MELT:** Zhangyong Tang, Tianyang Xu, Xiao-Jun Wu, Josef Kittler.<br />
  "Multi-Level Fusion for Robust RGBT Tracking via Enhanced Thermal Representation." TOMM (2024).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3678176)] 
  [[code](https://github.com/Zhangyong-Tang/MELT)]

- **S2OTFormer:** Shenglan Li, Rui Yao, Yong Zhou, Hancheng Zhu, Jiaqi Zhao, Zhiwen Shao, Abdulmotaleb El Saddik.<br />
  "Motion-aware Self-supervised RGBT Tracking with Multi-modality Hierarchical Transformers." TOMM (2024).
  [[paper](https://dl.acm.org/doi/10.1145/3698399)] 
  [[code](https://github.com/LiShenglana/S2OTFormer)]

- **MCTrack:** Shilei Wang, Zhenhua Wang, Qianqian Sun, Gong Cheng, Jifeng Ning.<br />
  "Modelling of Multiple Spatial-Temporal Relations for Robust Visual Object Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10670064)] 
  [[code]( )]

- **MMSTC:** Tianlu Zhang, Qiang Jiao, Qiang Zhang, Jungong Han.<br />
  "Exploring Multi-modal Spatial-Temporal Contexts for High-performance RGB-T Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10605602)] 
  [[code]( )]

- **LMANet:** Yabin Zhu, Xingle Zhao, Chenglong Li, Jin Tang, Zhixiang Huang.<br />
  "Long-term Motion Assisted Remote Sensing Object Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10601232)] 
  [[code](https://github.com/zhaoxingle/LMANet)]
  
- **ADSF:** Jingjing Wu, Xi Zhou, Xiaohong Li, Hao Liu, Meibin Qi, Richang Hong.<br />
  "Asymmetric Deformable Spatio-temporal Framework for Infrared Object Tracking." TOMM (2024).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3678882)] 
  [[code]( )]
  
- **ReFocus:** Simiao Lai, Chang Liu, Dong Wang, Huchuan Lu.<br />
  "Refocus the Attention for Parameter-Efficient Thermal Infrared Object Tracking." TNNLS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10601348)] 
  [[code](https://github.com/laisimiao/ReFocus_TIRTracking)]
  
- **FRTT:** Tianyang Xu, Yifan Pan, Zhenhua Feng, Xuefeng Zhu, Chunyang Cheng, Xiao-Jun Wu, Josef Kittler.<br />
  "Learning Feature Restoration Transformer for Robust Dehazing Visual Object Tracking." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-02182-9)] 
  [[code]( )]

- **BDTrack:** You Wu, Xucheng Wang, Dan Zeng, Hengzhou Ye, Xiaolan Xie, Qijun Zhao, Shuiwang Li.<br />
  "Learning Motion Blur Robust Vision Transformers with Dynamic Early Exit for Real-Time UAV Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.05383)] 
  [[code](https://github.com/wuyou3474/BDTrack)]

- **NLMTrack:** Miao Yan, Ping Zhang, Haofei Zhang, Ruqian Hao, Juanxiu Liu, Xiaoyang Wang, Lin Liu.<br />
  "Enhancing Thermal Infrared Tracking with Natural Language Modeling and Coordinate Sequence Generation." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.08265)] 
  [[code](https://github.com/ELOESZHANG/NLMTrack)]

- **TRO:** Xiaoyu Guo, Pengzhi Zhong, Lizhi Lin, Hao Zhang, Ling Huang, Shuiwang Li.<br />
  "Tracking Reflected Objects: A Benchmark." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.05235)] 
  [[code](https://github.com/OpenCodeGithub/HIP-HaTrack)]

- **eMoE-Tracker:** Yucheng Chen, Lin Wang.<br />
  "eMoE-Tracker: Environmental MoE-based Transformer for Robust Event-guided Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.20024)] 
  [[code](https://vlislab22.github.io/eMoE-Tracker/)]
  
- **P2P:** Jiahao Nie, Fei Xie, Xueyi Zhou, Sifan Zhou, Zhiwei He, Dong-Kyu Chae.<br />
  "P2P: Part-to-Part Motion Cues Guide a Strong Tracking Framework for LiDAR Point Clouds." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.05238)] 
  [[code](https://github.com/haooozi/P2P)]
  
- **MDETrack:** Zhenyu Wei, Yujie He, Zhanchuan Cai.<br />
  "Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation Learning." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.14195)] 
  [[code](https://anonymous.4open.science/r/MDETrack)]

- **RGBS50:** Yunfeng Li, Bo Wang, Jiuran Sun, Xueyi Wu, Ye Li.<br />
  "RGB-Sonar Tracking Benchmark and Spatial Cross-Attention Transformer Tracker." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.07189)] 
  [[code](https://github.com/LiYunfengLYF/RGBS50)]

- **ViDSOD-100:** Junhao Lin, Lei Zhu, Jiaxing Shen, Huazhu Fu, Qing Zhang, Liansheng Wang.<br />
  "ViDSOD-100: A New Dataset and a Baseline Model for RGB-D Video Salient Object Detection." IJCV (2024).
  [[paper](https://arxiv.org/abs/2406.07189)] 
  [[code](https://github.com/jhl-Det/RGBD_Video_SOD)]

- **RGBT-Tiny:** Xinyi Ying, Chao Xiao, Ruojing Li, Xu He, Boyang Li, Zhaoxu Li, Yingqian Wang, Mingyuan Hu, Qingyu Xu, Zaiping Lin, Miao Li, Shilin Zhou, Wei An, Weidong Sheng, Li Liu.<br />
  "Visible-Thermal Tiny Object Detection: A Benchmark Dataset and Baselines." TPAMI (2025).
  [[paper](https://arxiv.org/abs/2406.14482)] 
  [[code](https://github.com/XinyiYing24/RGBT-Tiny)]

- **HGTM:** Qingyu Xu, Longguang Wang, Weidong Sheng, Yingqian Wang, Chao Xiao, Chao Ma, Wei An.<br />
  "Heterogeneous Graph Transformer for Multiple Tiny Object Tracking in RGB-T Videos." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10531011)] 
  [[code](https://github.com/xuqingyu26/HGTM)]
  
- **HSOD-BIT:** Haolin Qin, Tingfa Xu, Peifu Liu, Jingxuan Xu, Jianan Li.<br />
  "DMSSN: Distilled Mixed Spectral–Spatial Network for Hyperspectral Salient Object Detection." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10475351)] 
  [[code](https://github.com/anonymous0519/HSOD-BIT)]

- **QSFNet:** Liuxin Bao, Xiaofei Zhou, Xiankai Lu, Yaoqi Sun, Haibing Yin, Zhenghui Hu, Jiyong Zhang, Chenggang Yan.<br />
  "Quality-aware Selective Fusion Network for V-D-T Salient Object Detection." TIP (2024).
  [[paper](https://arxiv.org/abs/2405.07655)] 
  [[code](https://github.com/Lx-Bao/QSFNet)]

- **DWFPRNet:** Yi Luo, Feng Shao, Baoyang Mu, Hangwei Chen, Zhuo Li, Qiuping Jiang.<br />
  "Dynamic Weighted Fusion and Progressive Refinement Network for Visible-Depth-Thermal Salient Object Detection." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10556617)] 
  [[code]( )]
  
- **CRM:** Yuanliang Xue, Guodong Jin, Tao Shen, Lining Tan, Nian Wang, Jing Gao, Lianfeng Wang.<br />
  "Consistent Representation Mining for Multi-Drone Single Object Tracking." arxiv (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10551855)] 
  [[code](https://github.com/xyl-507/CRM)]
  
- **LaMOT:** Yunhao Li, Xiaoqiong Liu, Luke Liu, Heng Fan, Libo Zhang.<br />
  "LaMOT: Language-Guided Multi-Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.08324)] 
  [[code](https://github.com/Nathan-Li123/LaMOT)]

- **ABTrack:** Xiangyang Yang, Dan Zeng, Xucheng Wang, You Wu, Hengzhou Ye, Shuiwang Li.<br />
  "Adaptively Bypassing Vision Transformer Blocks for Efficient Visual Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.08037)] 
  [[code](https://github.com/1HykhqV3rU/ABTrack)]

- **PuTR:** Chongwei Liu, Haojie Li, Zhihui Wang, Rui Xu.<br />
  "PuTR: A Pure Transformer for Decoupled and Online Multi-Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.14119)] 
  [[code](https://github.com/chongweiliu/PuTR)]

- **TATrack:** Shuiwang Li, Xiangyang Yang, Xucheng Wang, Dan Zeng, Hengzhou Ye, Qijun Zhao.<br />
  "Learning Target-Aware Vision Transformers for Real-Time UAV Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10568178)] 
  [[code](https://github.com/xyyang317/TATrack)]

- **MATrack:** Guotian Zeng, Bi Zeng, Qingmao Wei, Huiting Hu, Hong Zhang.<br />
  "Visual Object Tracking with Mutual Affinity Aligned to Human Intuition." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10539277)] 
  [[code]( )]

- **SPOT:** Jilai Zheng, Wenxi Li, Chao Ma, Xiaokang Yang.<br />
  "Sparsely-Supervised Object Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10541917)] 
  [[code](https://github.com/VISION-SJTU/SPOT)]
  
- **BTSOT:** Omar Abdelaziz, Mohamed Shehata, Mohamed Mohamed.<br />
  "Beyond Traditional Single Object Tracking: A Survey." JMLC (2024).
  [[paper](https://arxiv.org/abs/2405.10439)] 
  [[code]( )]

- **RGBTSOT:** Mingzheng Feng, Jianbo Su.<br />
  "RGBT tracking: A comprehensive review." Information Fusion (2024).
  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253524002707)] 
  [[code]( )]

- **MMOT:** Chunhui Zhang, Li Liu, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "Awesome Multi-modal Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.14200)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]
  
- **QueryTrack:** Huijie Fan, Zhencheng Yu, Qiang Wang, Baojie Fan, Yandong Tang.<br />
  "QueryTrack: Joint-modality Query Fusion Network for RGBT Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10516307)] 
  [[code]( )]

- **AFter:** Andong Lu, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "AFter: Attention-based Fusion Router for RGBT Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.02717)] 
  [[code](https://github.com/Alexadlu/AFter)]
  
- **MoETrack:** Zhangyong Tang, Tianyang Xu, Zhenhua Feng, Xuefeng Zhu, He Wang, Pengcheng Shao, Chunyang Cheng, Xiao-Jun Wu, Muhammad Awais, Sara Atito, Josef Kittler.<br />
  "Revisiting RGBT Tracking Benchmarks from the Perspective of Modality Validity: A New Benchmark, Problem, and Method." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.00168)] 
  [[code](https://github.com/Zhangyong-Tang/MoETrack)]
  
- **PromptVT:** Minghua Zhang, Qiuyang Zhang, Wei Song, Dongmei Huang, Qi He.<br />
  "PromptVT: Prompting for Efficient and Accurate Visual Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10468656)] 
  [[code](https://github.com/faicaiwawa/PromptVT)]

- **MobileSiam-LT:** Xin Yang, Jinxiang Huang, Yizhao Liao, Yong Song, Ya Zhou, Jinqi Yang.<br />
  "Light Siamese Network for Long-term Onboard Aerial Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10521630)] 
  [[code](https://github.com/YoungZnBIT/PySOT-trial)]
  
- **CrossEI:** Zhiwen Chen, Jinjian Wu, Weisheng Dong, Leida Li, Guangming Shi.<br />
  "CrossEI: Boosting Motion-oriented Object Tracking with An Event Camera." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/document/10776574)] 
  [[code]( )]

- **Mamba-FETrack:** Ju Huang, Shiao Wang, Shuai Wang, Zhe Wu, Xiao Wang, Bo Jiang.<br />
  "Mamba-FETrack: Frame-Event Tracking via State Space Model." arxiv (2024).
  [[paper](https://arxiv.org/abs/2404.18174)] 
  [[code](https://github.com/Event-AHU/Mamba_FETrack)]

- **AttMOT:** Yunhao Li, Zhen Xiao, Lin Yang, Dan Meng, Xin Zhou, Heng Fan, Libo Zhang.<br />
  "AttMOT: Improving Multiple-Object Tracking by Introducing Auxiliary Pedestrian Attributes." TNNLS (2024).
  [[paper](https://arxiv.org/abs/2308.07537)] 
  [[code]()]

- **PillarTrack:** Weisheng Xu, Sifan Zhou, Zhihang Yuan.<br />
  "PillarTrack: Redesigning Pillar-based Transformer Network for Single Object Tracking on Point Clouds." arxiv (2024).
  [[paper](https://arxiv.org/abs/2404.07495)] 
  [[code](https://github.com/StiphyJay/PillarTrack)]

- **EasyTrack:** Baojie Fan, Wuyang Zhou, Kai Wang, Shijun Zhou, Fengyu Xu, Jiandong Tian.<br />
  "EasyTrack: Efficient and Compact One-stream 3D Point Clouds Tracker." arxiv (2024).
  [[paper](https://arxiv.org/abs/2404.05960)] 
  [[code](https://github.com/KnightApple427/Easytrack)]

- **Anti-UAV410:** Bo Huang, Jianan Li, Junjie Chen, Gang Wang, Jian Zhao, Tingfa Xu.<br />
  "Anti-UAV410: A Thermal Infrared Benchmark and Customized Scheme for Tracking Drones in the Wild." TPAMI (2024).
  [[paper](https://ieeexplore.ieee.org/document/10325629)] 
  [[code](https://github.com/HwangBo94/Anti-UAV410)]

- **RTSformer:** Fengwei Gu, Jun Lu, Chengtao Cai, Qidan Zhu, Zhaojie Ju.<br />
  "RTSformer: A Robust Toroidal Transformer With Spatiotemporal Features for Visual Tracking." THMS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10474210)] 
  [[code]( )]

- **TSF-SiamMU:** Weijie Yan, Guohua Gu, Yunkai Xu, Xiaofang Kong, Ajun Shao, Qian Chen.<br />
  "Twofold Structured Features-Based Siamese Network for Infrared Target Tracking." TCSS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10530921)] 
  [[code]( )]

- **GAA:** Mingyang Lei, Hong Song, Jingfan Fan, Deqiang Xiao, Danni Ai, Ying Gu, Jian Yang.<br />
  "GAA: Ghost Adversarial Attack for Object Tracking." TETCI (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10466775)] 
  [[code]( )]

- **Sigma:** Zifu Wan, Yuhao Wang, Silong Yong, Pingping Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie.<br />
  "Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2404.04256)] 
  [[code](https://github.com/zifuwan/Sigma)]

- **CaDeX++:** Yunzhou Song, Jiahui Lei, Ziyun Wang, Lingjie Liu, Kostas Daniilidis.<br />
  "Track Everything Everywhere Fast and Robustly." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.17931)] 
  [[code](https://timsong412.github.io/FastOmniTrack/)]
  
- **MPLKD:** Yang Luo, Xiqing Guo, Hao Li.<br />
  "From Two Stream to One Stream: Efficient RGB-T Tracking via Mutual Prompt Learning and Knowledge Distillation." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.16834)] 
  [[code](https://github.com/)]

- **MAPNet:** Xinglong Sun, Haijiang Sun, Shan Jiang, Jiacheng Wang, Xilai Wei, Zhonghe Hu.<br />
  "Multi-attention Associate Prediction Network for Visual Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.16395)] 
  [[code]( )]
  
- **ACTrack:** Yushan Han, Kaer Huang.<br />
  "ACTrack: Adding Spatio-Temporal Condition for Visual Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.07914)] 
  [[code]( )]
  
- **MT-Track :** Xiaoying Yuan, Tingfa Xu, Xincong Liu, Ying Wang, Haolin Qin, Yuqiang Fang, Jianan Li.<br />
  "Multi-step Temporal Modeling for UAV Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10464358/)] 
  [[code]( )]

- **OIFTrack:** Janani Kugarajeevan, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando.<br />
  "Optimized Information Flow for Transformer Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2402.08195)] 
  [[code](https://github.com/JananiKugaa/OIFTrack)]

- **SuperSBT:** Fei Xie, Wankou Yang, Chunyu Wang, Lei Chu, Yue Cao, Chao Ma, Wenjun Zeng.<br />
  "Correlation-Embedded Transformer Tracking: A Single-Branch Framework." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2401.12743)] 
  [[code](https://github.com/phiphiphi31/SBT)]
  

### NeurIPS 2023

- **MixFormerV2:** Yutao Cui, Tianhui Song, Gangshan Wu, Limin Wang.<br />
  "MixFormerV2: Efficient Fully Transformer Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2305.15896)] 
  [[code](https://github.com/MCG-NJU/MixFormerV2)]

- **RFGM:** Xinyu Zhou, Pinxue Guo, Lingyi Hong, Jinglun Li, Wei Zhang, Weifeng Ge, Wenqiang Zhang.<br />
  "Reading Relevant Feature from Global Representation Memory for Visual Object Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2402.14392)] 
  [[code]( )]
  
- **BadTrack:** Bin Huang, Jiaqian Yu, Yiwei Chen, Siyang Pan, Qiang Wang, Zhi Wang.<br />
  "BadTrack: A Poison-Only Backdoor Attack on Visual Object Tracking." NeurIPS (2023).
  [[paper](https://proceedings.neurips.cc//paper_files/paper/2023/hash/828bb8f42d4ab15322b9315151959c61-Abstract-Conference.html)] 
  [[code]( )]

- **ZoomTrack:** Yutong Kou, Jin Gao, Bing Li, Gang Wang, Weiming Hu, Yizheng Wang, Liang Li.<br />
  "ZoomTrack: Target-aware Non-uniform Resizing for Efficient Visual Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2310.10071)] 
  [[code](https://github.com/Kou-99/ZoomTrack)]

- **Type-to-Track:** Pha Nguyen, Kha Gia Quach, Kris Kitani, Khoa Luu.<br />
  "Type-to-Track: Retrieve Any Object via Prompt-based Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2305.13495)] 
  [[code](https://uark-cviu.github.io/Type-to-Track)]

- **MGIT:** Shiyu Hu, Dailin Zhang, Meiqi Wu, Xiaokun Feng, Xuchen Li, Xin Zhao, Kaiqi Huang.<br />
  "A Multi-modal Global Instance Tracking Benchmark (MGIT): Better Locating Target in Complex Spatio-temporal and Causal Relationship." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/xxxxx.xx)] 
  [[code](http://videocube.aitestunion.com/)]


### ICCV 2023

- **VTDNet:** Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu.<br />
  "Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving." ICCV (2023).
  [[paper](https://arxiv.org/abs/2309.04422)] 
  [[code](https://www.vis.xyz/pub/vtd)]
  
- **HiT:** Ben Kang, Xin Chen, Dong Wang, Houwen Peng, Huchuan Lu.<br />
  "Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.06904)] 
  [[code](https://github.com/kangben258/HiT)]

- **ROMTrack:** Yidong Cai, Jie Liu, Jie Tang, Gangshan Wu.<br />
  "Robust Object Modeling for Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.05140)] 
  [[code](https://github.com/dawnyc/ROMTrack)]

- **F-BDMTrack:** Dawei Yang, Jianfeng He, Yinchao Ma, Qianjin Yu, Tianzhu Zhang.<br />
  "Foreground-Background Distribution Modeling Transformer for Visual Object Tracking." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf)] 
  [[code]()]

- **MITS:** Yuanyou Xu, Zongxin Yang, Yi Yang.<br />
  "Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual Tracking and Segmentation." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/yoxu515/MITS)]

- **Aba-ViTrack:** Shuiwang Li, Yangxiang Yang, Dan Zeng, Xucheng Wang.<br />
  "Adaptive and Background-Aware Vision Transformer for Real-Time UAV Tracking." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/xyyang317/Aba-ViTrack)]
  
- **Omnimotion:** Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath Hariharan, Aleksander Holynski, Noah Snavely.<br />
  "Tracking Everything Everywhere All at Once." ICCV (2023).
  [[paper](https://arxiv.org/abs/2306.05422)] 
  [[code](https://omnimotion.github.io/)]
  
- **DEVA:** Ho Kei Cheng, Seoung Wug Oh, Brian Price, Alexander Schwing, Joon-Young Lee.<br />
  "Tracking Anything with Decoupled Video Segmentation." ICCV (2023).
  [[paper](https://arxiv.org/abs/2309.03903)] 
  [[code](https://hkchengrex.github.io/Tracking-Anything-with-DEVA)]

- **CiteTracker:** Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "CiteTracker: Correlating Image and Text for Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.11322)] 
  [[code](https://github.com/xinli/citetracker)]

- **DecoupleTNL:** Ding Ma, Xiangqian Wu.<br />
  "Tracking by Natural Language Specification with Long Short-term Context Decoupling." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf)] 
  [[code]()]
  
- **PVT++:** Bowen Li, Ziyuan Huang, Junjie Ye, Yiming Li, Sebastian Scherer, Hang Zhao, Changhong Fu.<br />
  "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework." ICCV (2023).
  [[paper](https://arxiv.org/abs/2211.11629)] 
  [[code](https://github.com/Jaraxxus-Me/PVT_pp)]

- **COHA:** Zhiyu Zhu, Junhui Hou, Dapeng Oliver Wu.<br />
  "Cross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers." ICCV (2023).
  [[paper](https://arxiv.org/abs/2307.04129)] 
  [[code](https://github.com/ZHU-Zhiyu/High-Rank_RGB-Event_Tracker)]

- **SyncTrack:** Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu.<br />
  "Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.12549)] 
  [[code](https://xxxxx)]
  
- **360VOT:** Huajian Huang, Yinzhe Xu, Yingshu Chen, Sai-Kit Yeung.<br />
  "360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2307.14630)] 
  [[code](https://360vot.hkustvgd.com/)]

- **PlanarTrack:** Xinran Liu, Xiaoqiong Liu, Ziruo Yi, Xin Zhou, Thanh Le, Libo Zhang, Yan Huang, Qing Yang, Heng Fan.<br />
  "PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2303.07625)] 
  [[code](https://hengfan2010.github.io/projects/PlanarTrack/)]
       
### CVPR 2023

- **X-Decoder:** Xueyan Zou, Zi-Yi Dou, Jianwei Yang, Zhe Gan, Linjie Li, Chunyuan Li, Xiyang Dai, Harkirat Behl, Jianfeng Wang, Lu Yuan, Nanyun Peng, Lijuan Wang, Yong Jae Lee, Jianfeng Gao.<br />
  "Generalized Decoding for Pixel, Image, and Language." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.11270)] 
  [[code](https://x-decoder-vl.github.io/)]
  
- **UNINEXT:** Bin Yan, Yi Jiang, Jiannan Wu, Dong Wang, Ping Luo, Zuhuan Yuan, Huchuan Lu.<br />
  "Universial Instance Perception as Object Discovery and Retrieval." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.06674)] 
  [[code](https://github.com/MasterBin-IIAU/UNINEXT)]
  
- **OmniTracker:** Junke Wang, Dongdong Chen, Zuxuan Wu, Chong Luo, Xiyang Dai, Lu Yuan, Yu-Gang Jiang.<br />
  "OmniTracker: Unifying Object Tracking by Tracking-with-Detection." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12079)] 
  [[code](https://github.com/)]

- **SUSHI:** Orcun Cetintas, Guillem Brasó, Laura Leal-Taixé.<br />
  "Unifying Short and Long-Term Tracking with Graph Hierarchies." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.03038)] 
  [[code](https://github.com/dvl-tum/SUSHI)]
  
- **DropMAE:** Qiangqiang Wu, Tianyu Yang, Ziquan Liu, Baoyuan Wu, Ying Shan, Antoni B. Chan.<br />
  "DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.00571)] 
  [[code](https://github.com/jimmy-dq/DropMAE)]
  
- **VideoTrack:** Fei Xie, Lei Chu, Jiahao Li, Yan Lu, Chao Ma.<br />
  "VideoTrack: Learning to Track Objects via Video Transformer." CVPR (2023).
  [[paper](https://arxiv.org/abs/x)] 
  [[code](https://github.com/phiphiphi31/VideoTrack)]
  
- **SwinV2:** Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, Yue Cao.<br />
  "Revealing the Dark Secrets of Masked Image Modeling." CVPR (2023).
  [[paper](https://arxiv.org/abs/2205.13543)] 
  [[code](https://github.com/SwinTransformer/MIM-Depth-Estimation)]
  
- **ViPT:** Jiawen Zhu, Simiao Lai, Xin Chen, Dong Wang, Huchuan Lu.<br />
  "Visual Prompt Multi-Modal Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.10826)] 
  [[code](https://github.com/jiawen-zhu/ViPT)]
  
 - **JointNLT:** Li Zhou, Zikun Zhou, Kaige Mao, Zhenyu He.<br />
  "Joint Visual Grounding and Tracking with Natural Language Specification." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12027)] 
  [[code](https://github.com/lizhou-cs/JointNLT)]
  
 - **ARKitTrack:** Haojie Zhao, Junsong Chen, Lijun Wang, Huchuan Lu.<br />
  "ARKitTrack: A New Diverse Dataset for Tracking Using Mobile RGB-D Data." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.13885)] 
  [[code](https://arkittrack.github.io/)]
  
 - **GRM:** Shenyuan Gao, Chunluan Zhou, Jun Zhang.<br />
  "Generalized Relation Modeling for Transformer Tracking." CVPR (2023).
  [[paper](https://arxiv.org/pdf/2303.16580v1.pdf)] 
  [[code](https://github.com/Little-Podi/GRM)]
  
 - **ARTrack:** Xing Wei, Yifan Bai, Yongchao Zheng, Dahu Shi, Yihong Gong.<br />
  "Autoregressive Visual Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/MIV-XJTU/ARTrack)]
  
 - **MAT:** Haojie Zhao, Dong Wang, Huchuan Lu.<br />
  "Representation Learning for Visual Object Tracking by Masked Appearance Transfer." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Representation_Learning_for_Visual_Object_Tracking_by_Masked_Appearance_Transfer_CVPR_2023_paper.html)] 
  [[code](https://github.com/difhnp/MAT)]
  
 - **EMT:** Jinyu Yang, Shang Gao, Zhe Li, Feng Zheng, Aleš Leonardis.<br />
  "Resource-Efficient RGBD Aerial Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Resource-Efficient_RGBD_Aerial_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/yjybuaa/RGBDAerialTracking)]
  
 - **TBSI:** Tianrui Hui, Zizheng Xun, Fengguang Peng, Junshi Huang, Xiaoming Wei, Xiaolin Wei, Jiao Dai, Jizhong Han, Si Liu.<br />
  "Bridging Search Region Interaction With Template for RGB-T Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hui_Bridging_Search_Region_Interaction_With_Template_for_RGB-T_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/RyanHTR/TBSI)]
  
 - **VisTracker:** Xianghui Xie, Bharat Lal Bhatnagar, Gerard Pons-Moll.<br />
  "Visibility Aware Human-Object Interaction Tracking from Single RGB Camera." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.16479v1)] 
  [[code](https://virtualhumans.mpi-inf.mpg.de/VisTracker/)]
  
 - **OVTrack:** Siyuan Li, Tobias Fischer, Lei Ke, Henghui Ding, Martin Danelljan, Fisher Yu.<br />
  "OVTrack: Open-Vocabulary Multiple Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.08408)] 
  [[code](https://www.vis.xyz/pub/ovtrack/)]
  
 - **SeqTrack:** Xin Chen, Houwen Peng, Dong Wang, Huchuan Lu, Han Hu.<br />
  "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.14394)] 
  [[code](https://github.com/microsoft/VideoX)]
  
 - **ImageBind:** Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra.<br />
  "IMAGEBIND: One Embedding Space To Bind Them All." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.05665)] 
  [[code](https://github.com/facebookresearch/ImageBind)]
  
 - **TCOW:** Basile Van Hoorick, Pavel Tokmakov, Simon Stent, Jie Li, Carl Vondrick.<br />
  "Tracking through Containers and Occluders in the Wild." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.03052)] 
  [[code](https://tcow.cs.columbia.edu/)]
  

### ACM MM 2023

- **SimOWT:** Bingyang Wang, Tanlin Li, Jiannan Wu, Yi Jiang, Huchuan Lu, You He.<br />
  "A Simple Baseline for Open-World Tracking via Self-training." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3611695)] 
  [[code](https://github.com/22109095/SimOWT)]

- **UTrack:** Jie Gao, Bineng Zhong, Yan Chen.<br />
  "Unambiguous Object Tracking by Exploiting Target Cues." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3612240)] 
  [[code]()]

- **PDST:** Jinpu Zhang, Ziwen Li, Ruonan Wei, Yuehuan Wang.<br />
  "Progressive Domain-style Translation for Nighttime Tracking." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3612305)] 
  [[code]()]
  
- **All-in-One:** Chunhui Zhang, Xin Sun, Li Liu, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang.<br />
  "All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment." ACM MM (2023).
  [[paper](https://arxiv.org/abs/2307.03373)] 
  [[code]( )]
  

### ArXiV 2023

- **LaTOT/MKDNet:** Yabin Zhu, Chenglong Li, Yao Liu, Xiao Wang, Jin Tang, Bin Luo, Zhixiang Huang.<br />
  "Tiny Object Tracking: A Large-scale Dataset and A Baseline." TNNLS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10035907)] 
  [[code](https://github.com/mmic-lcl/Datasets-and-benchmark-code)]

- **UPVPT:** Guangtong Zhang, Qihua Liang, Ning Li, Zhiyi Mo, Bineng Zhong.<br />
  "Robust Tracking via Unifying Pretrain-Finetuning and Visual Prompt Tuning." ACM MMAsia (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3595916.3626410)] 
  [[code]()]

- **TAO-Amodal:** Cheng-Yen Hsieh, Tarasha Khurana, Achal Dave, Deva Ramanan.<br />
  "Tracking Any Object Amodally." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2312.12433)] 
  [[code](https://tao-amodal.github.io/)]

- **HQTrack:** Jiawen Zhu, Zhenyu Chen, Zeqi Hao, Shijie Chang, Lu Zhang, Dong Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Hanyuan Chen, Chenyang Li.<br />
  "Tracking Anything in High Quality." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.13974)] 
  [[code](https://github.com/jiawen-zhu/HQTrack)]

- **SATracker:** Jiawei Ge, Xiangmei Chen, Jiuxin Cao, Xuelin Zhu, Weijia Liu, Bo Liu.<br />
  "Beyond Visual Cues: Synchronously Exploring Target-Centric Semantics for Vision-Language Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2311.17085)] 
  [[code]( )]

- **PSTM:** Zechu Zhou, Xinyu Zhou, Zhaoyu Chen, Pinxue Guo, Qian-Yu Liu, Wenqiang Zhang.<br />
  "Memory Network With Pixel-Level Spatio-Temporal Learning for Visual Object Tracking." TCSVT (2023).
  [[paper](https://ieeexplore.ieee.org/document/10114400)] 
  [[code]( )]

- **TransMDOT:** Guanlin Chen, Pengfei Zhu, Bing Cao, Xing Wang, Qinghua Hu.<br />
  "Cross-Drone Transformer Network for Robust Single Object Tracking." TCSVT (2023).
  [[paper](https://ieeexplore.ieee.org/document/10144283)] 
  [[code](https://github.com/cgjacklin/transmdot)]

- **MIA-Net:** Zhihao Liu, Yuanyuan Shang, Timing Li, Guanlin Chen, Yu Wang, Qinghua Hu.<br />
  "Robust Multi-Drone Multi-Target Tracking to Resolve Target Occlusion: A Benchmark." TMM (2023).
  [[paper](https://ieeexplore.ieee.org/document/10008047)] 
  [[code](https://github.com/VisDrone/Multi-Drone-Multi-Object-Detection-and-Tracking)]

- **PlugAtt:** Shaochuan Zhao, Tianyang Xu, Xiao-Jun Wu, Josef Kittler.<br />
  "Pluggable Attack for Visual Object Tracking." TIFS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10316262)] 
  [[code]( )]

- **FFTrack:** Xiantao Hu. Bineng Zhong. Qihua Liang. Shengping Zhang. Ning Li. Xianxian Li.<br />
  "Transformer Tracking via Frequency Fusion." TCSVT (2023).
  [[paper](https://ieeexplore.ieee.org/document/10163861)] 
  [[code]( )]

- **MMTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Guorong Li, Rongrong Ji, Xianxian Li.<br />
  "Towards Unified Token Learning for Vision-Language Tracking." TCSVT (2023).
  [[paper](https://arxiv.org/abs/2308.14103)] 
  [[code](https://github.com/Azong-HQU/MMTrack)]

- **OVLM:** Huanlong Zhang, Jingchao Wang, Jianwei Zhang, Tianzhu Zhang, Bineng Zhong.<br />
  "One-stream Vision-Language Memory Network for Object Tracking." TMM (2023).
  [[paper](https://ieeexplore.ieee.org/document/10149530)] 
  [[code]( )]
  
- **MPLT:** Yang Luo, Xiqing Guo, Hui Feng, Lei Ao.<br />
  "RGB-T Tracking via Multi-Modal Mutual Prompt Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2308.16386)] 
  [[code](https://github.com/HusterYoung/MPLT)]

- **CycleTrack:** Chuanming Tang, Kai Wang, Joost van de Weijer, Jianlin Zhang, Yongmei Huang.<br />
  "Exploiting Image-Related Inductive Biases in Single-Branch Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2310.19542)] 
  [[code](https://xxx)]
  
- **DCPT:** Jiawen Zhu, Huayi Tang, Zhi-Qi Cheng, Jun-Yan He, Bin Luo, Shihao Qiu, Shengming Li, Huchuan Lu.<br />
  "DCPT: Darkness Clue-Prompted Tracking in Nighttime UAVs." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.10491)] 
  [[code](https://xxx)]

- **SRT:** Tianpeng Liu, Jing Li, Jia Wu, Lefei Zhang, Jun Chang, Jun Wan, Lezhi Lian.<br />
  "Tracking with Saliency Region Transformer." TIP (2023).
  [[paper](https://ieeexplore.ieee.org/document/10359476)] 
  [[code](https://github.xxxxx)]

- **TATrans:** Pujian Lai, Meili Zhang, Gong Cheng, Shengyang Li, Xiankai Huang, Junwei Han.<br />
  "Target-aware Transformer for Satellite Video Object Tracking." TGRS (2023).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10342836)] 
  [[code](https://github.com/laybebe/TATrans_SVOT)]

- **STRtrack:** Shaochuan Zhao, Tianyang Xu, Xiaojun Wu, Josef Kittler.<br />
  "A Spatio-Temporal Robust Tracker with Spatial-Channel Transformer and Jitter Suppression." IJCV (2023).
  [[paper](https://link.springer.com/article/10.1007/s11263-023-01902-x)] 
  [[code](https://xxx)]

- **CoTracker:** Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht.<br />
  "CoTracker: It is Better to Track Together." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.07635)] 
  [[code](https://co-tracker.github.io/)]
  
- **LiteTrack:** Qingmao Wei, Bi Zeng, Jianqi Liu, Li He, Guotian Zeng.<br />
  "LiteTrack: Layer Pruning with Asynchronous Feature Extraction for Lightweight and Efficient Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.09249)] 
  [[code](https://github.com/TsingWei/LiteTrack)]
  
- **LightFC:** Li Yunfeng, Wang Bo, Li Ye, Liu Zhuoyan, Wu Xueyi.<br />
  "Lightweight Full-Convolutional Siamese Tracker." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2310.05392)] 
  [[code](https://github.com/LiYunfengLYF/LightFC)]

- **DETRrack:** Qingmao Wei, Bi Zeng, Guotian Zeng.<br />
  "Efficient Training for Visual Tracking with Deformable Transformer." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.02676)] 
  [[code](https:xxx)]

- **JN:** Qingmao Wei, Bi Zeng, Guotian Zeng.<br />
  "Towards Efficient Training with Negative Samples in Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.02903)] 
  [[code](hxx)]
  
- **P3DTrack:** Jiawei He, Lue Fan, Yuqi Wang, Yuntao Chen, Zehao Huang, Naiyan Wang, Zhaoxiang Zhang.<br />
  "Tracking Objects with 3D Representation from Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05416)] 
  [[code](https:/xx)]
  
- **SAM-DA:** Liangliang Yao, Haobo Zuo, Guangze Zheng, Changhong Fu, Jia Pan.<br />
  "SAM-DA: UAV Tracks Angthing at Night with SAM-Powered Domain Adaptation." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.01024)] 
  [[code](https:/github.com/vision4robotics/sam-da)]
  
- **SparseTrack:** Zelin Liu, Xinggang Wang, Cheng Wang, Wenyu Liu, Xiang Bai.<br />
  "SparseTrack: Multi-Object Tracking by Performing Scene Decomposition based on Pseudo-Depth." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05238)] 
  [[code](https://github.com/hustvl/SparseTrack)]
  
- **MACFT:** Yang Luo, Xiqing Guo, Mingtao Dong, Jin Yu.<br />
  "RGB-T Tracking Based on Mixed Attention." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.04264)] 
  [[code](https:/xx)]
  
- **AFNet:** Jiqing Zhang, Yuanchen Wang, Wenxi Liu, Meng Li, Jinpeng Bai, Baocai Yin, Xin Yang.<br />
  "Frame-Event Alignment and Fusion Network for High Frame Rate Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.15688)] 
  [[code](https:/xx)]
  
- **MFT:** Michal Neoral, Jonáš Šerých, Jiří Matas.<br />
  "MFT: Long-Term Tracking of Every Pixel." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.12998)] 
  [[code](https:/xx)]
  
- **S3Track:** Fatemeh Azimi, Fahim Mannan, Felix Heide.<br />
  "S3Track: Self-supervised Tracking with Soft Assignment Flow." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.09981)] 
  [[code](https:/xx)]
    
- **TransSOT:** Janani Thangavel, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando.<br />
  "Transformers in Single Object Tracking: An Experimental Survey." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2302.11867)] 
  [[code]()]
  
- **ProFormer:** Yabin Zhu, Chenglong Li, Xiao Wang, Jin Tang, Zhixiang Huang.<br />
  "RGBT Tracking via Progressive Fusion Transformer with Dynamically Guided Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2303.14778)] 
  [[code]()]
  
- **SiamTHN:** Jiahao Bao, Kaiqiang Chen, Xian Sun, Liangjin Zhao, Wenhui Diao, Menglong Yan.<br />
  "SiamTHN: Siamese Target Highlight Network for Visual Tracking." TCSVT (2023).
  [[paper](https://arxiv.org/abs/2303.12304)] 
  [[code]()]

- **SOTVerse:** Shiyu Hu, Xin Zhao, Kaiqi Huang.<br />
  "SOTVerse: A User-defined Task Space of Single Object Tracking." IJCV (2023).
  [[paper](https://arxiv.org/abs/2204.07414)] 
  [[code](http://metaverse.aitestunion.com/sotverse)]

- **TSMTrack:** Chuanming Tang, Qintao Hu, Gaofan Zhou, Jinzhen Yao, Jianlin Zhang, Yongmei Huang, Qixiang Ye.<br />
  "Transformer Sub-Patch Matching for High-Performance Visual Object Tracking." TITS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10101686)] 
  [[code](https:/xx)]

- **TADS:** Xin Li, Wenjie Pei, Yaowei Wang, Zhenyu He, Huchuan Lu, Ming-Hsuan Yang.<br />
  "Self-Supervised Tracking via Target-Aware Data Synthesis." TNNLS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10004981)] 
  [[code]()]
  
- **Diffusion Init:** Renjie Wang, Tianyang Xu, Shaochuan Zhao, Xiao-Jun Wu, Josef Kittler.<br />
  "Diffusion Init: Stronger Initialisation of Decision-Based Black-Box Attacks for Visual Object Tracking." ACPR (2023).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-47637-2_28)] 
  [[code]( )]

- **TAT:** Ziyi Cheng, Baoyuan Wu, Zhenya Zhang, Jianjun Zhao.<br />
  "TAT: Targeted Backdoor Attacks Against Visual Object Tracking." PR (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320323003308?via%3Dihub)] 
  [[code](https://github.com/MisakaZipi/TAT)]

- **SRNet:** Nana Fan, Qiao Liu, Xin Li, Zikun Zhou, Zhenyu He.<br />
  "Siamese Residual Network for Efficient Visual Tracking." Information Sciences (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0020025522015778?via%3Dihub)] 
  [[code]()]

### IJCAI 2023

- **OSP2B:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Zhengyi Bao, Mingyu Gao, Jing Zhang.<br />
  "OSP2B: One-Stage Point-to-Box Network for 3D Siamese Tracking." IJCAI (2023).
  [[paper](https://arxiv.org/abs/2304.11584)] 
  [[code](https://github.com/HaozheQi/P2B)]
  
  
### ICRA 2023

- **SGDViT:** Liangliang Yao, Changhong Fu, Sihang Li, Guangze Zheng, Junjie Ye.<br />
  "SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking." ICRA (2023).
  [[paper](https://arxiv.org/abs/2303.04378v1)] 
  [[code](https://github.com/vision4robotics/SGDViT)]
  
- **ClimRT:** Changhong Fu, Mutian Cai, Sihang Li, Kunhan Lu, Haobo Zuo, Chongjun Liu.<br />
  "Continuity-Aware Latent Interframe Information Mining for Reliable UAV Tracking." ICRA (2023).
  [[paper](https://arxiv.org/abs/2303.04525v1)] 
  [[code](https://github.com/vision4robotics/ClimRT)]
  
### IROS 2023

- **TOTEM:** Kalyan Garigapati, Erik Blasch, Jie Wei, Haibin Ling.<br />
  "Transparent Object Tracking with Enhanced Fusion Module." IROS (2023).
  [[paper](https://arxiv.org/abs/2309.06701)] 
  [[code](https://github.com/kalyan0510/TOTEM)]

- **CDT:** Kunhan Lu, Changhong Fu, Yucheng Wang, Haobo Zuo, Guangze Zheng, and Jia Pan.<br />
  "Cascaded Denoising Transformer for UAV Nighttime Tracking." RAL (2023).
  [[paper](https://arxiv.org/xxxx)] 
  [[code](https://github.com/vision4robotics/CDT)]
  
- **TRTrack:** Sihang Li, Changhong Fu.<br />
  "TRTrack: Boosting UAV Object Tracking with Voxel-based Trajectory-aware Reconstruction Training." IROS (2023).
  [[paper](https://arxiv.org/abs/xxxx)] 
  [[code](https://github.com/vision4robotics/TRTrack)]
  
### WACV 2023

- **MVT:** Goutam Yelluru Gopal, Maria A. Amer.<br />
  "Mobile Vision Transformer-based Visual Object Tracking." BMVC (2023).
  [[paper](https://arxiv.org/abs/2309.05829)] 
  [[code](https://github.com/goutamyg/MVT)]
  
- **E.T.Track:** Philippe Blatter, Menelaos Kanakis, Martin Danelljan, Luc Van Gool.<br />
  "Efficient Visual Tracking with Exemplar Transformers." WACV (2023).
  [[paper](https://arxiv.org/abs/2112.09686)] 
  [[code](https://github.com/pblatter/ettrack)]
  

### AAAI 2023

- **CTTrack:** Zikai Song, Run Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Compact Transformer Tracker with Correlative Masked Modeling." AAAI (2023).
  [[paper](https://arxiv.org/abs/2301.10938)] 
  [[code](https://github.com/HUSTDML/CTTrack)]
  
- **TATrack:** Kaijie He, Canlong Zhang, Sheng Xie, Zhixin Li, Zhiwen Wang.<br />
  "Target-Aware Tracking with Long-term Context Attention." AAAI (2023).
  [[paper](https://arxiv.org/abs/2302.13840)] 
  [[code](https://github.com/hekaijie123/TATrack)]
  
- **RGBD1K:** Xue-Feng Zhu, Tianyang Xu, Zhangyong Tang, Zucheng Wu, Haodong Liu, Xiao Yang, Xiao-Jun Wu, Josef Kittler.<br />
  "RGBD1K: A Large-scale Dataset and Benchmark for RGB-D Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2208.09787)] 
  [[code](https://github.com/xuefeng-zhu5/RGBD1K)]

- **GdaTFT:** Yun Liang; Qiaoqiao Li; Fumian Long.<br />
  "Global Dilated Attention and Target Focusing Network for Robust Tracking." AAAI (2023).
  [[paper](https://underline.io/lecture/69278-global-dilated-attention-and-target-focusing-network-for-robust-tracking)] 
  [[code](https://github.com/)]
  
- **GLT-T:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Mingyu Gao, Jing Zhang.<br />
  "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds." AAAI (2023).
  [[paper](https://arxiv.org/abs/2211.10927)] 
  [[extended](https://arxiv.org/abs/2304.00242)] 
  [[code](https://github.com/haooozi/GLT-T)]
  
- **RSPT:** Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang, Yizhou Wang.<br />
  "RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2304.03623)] 
  [[code](https://sites.google.com/view/aot-rspt)]


### NeurIPS 2022

- **SwinTrack:** Liting Lin, Heng Fan, Yong Xu, Haibin Ling.<br />
  "SwinTrack: A Simple and Strong Baseline for Transformer Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2112.00995)] 
  [[code](https://github.com/LitingLin/SwinTrack)]
  
- **VLTrack:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing.<br />
  "Divert More Attention to Vision-Language Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2207.01076)] 
  [[code](https://github.com/JudasDie/SOTS)]
  
- **GKB:** Zhiyu Zhu, Junhui Hou, Xianqiang Lyu.<br />
  "Leaning Graph-embedded Key-event Back-tracing for Object Tracking in Event Clouds." NeurIPS (2022).
  [[paper](https://nips.cc/Conferences/2022/Schedule?showEvent=54651)] 
  [[code](https://github.com/ZHU-Zhiyu/Event-tracking)]
  
- **TAP-Vid:** Carl Doersch, Ankush Gupta, Larisa Markeeva, Lucas Smaira, Yusuf Aytar, Andrew Zisserman, Yi Yang.<br />
  "TAP-Vid: A Benchmark for Tracking Any Point in a Video." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2211.03726)] 
  [[code](https://github.com/deepmind/tapnet)]

  
### ECCV 2022

- **OSTrack:** Botao Ye, Hong Chang, Bingpeng Ma, Shiguang Shan.<br />
  "Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11991)] 
  [[code](https://github.com/botaoye/OSTrack)]
  
- **Unicorn:** Bin Yan, Yi Jiang, Peize Sun, Dong Wang, Zehuan Yuan, Ping Luo, Huchuan Lu.<br />
  "Unicorn: Towards Grand Unification of Object Tracking." ECCV (2022) Oral.
  [[paper](https://arxiv.org/abs/2207.07078)] 
  [[code](https://github.com/MasterBin-IIAU/Unicorn)]
  
- **SimTrack:** Boyu Chen, Peixia Li, Lei Bai, Lei Qiao, Qiuhong Shen, Bo Li, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.05328)] 
  [[code](https://github.com/LPXTT/SimTrack)]
  
- **CIA:** Zhixiong Pi, Weitao Wan, Chong Sun, Changxin Gao, Nong Sang, Chen Li.<br />
  "Hierarchical Feature Embedding for Visual Tracking." ECCV (2022).
  [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4400_ECCV_2022_paper.php)] 
  [[code](https://github.com/zxgravity/CIA)]
  
- **RTS:** Matthieu Paul,Martin Danelljan,Christoph Mayer,Luc Van Gool.<br />
  "Robust Visual Tracking by Segmentation." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11191)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **AiATrack:** Shenyuan Gao, Chunluan Zhou, Chao Ma, Xinggang Wang, Junsong Yuan.<br />
  "AiATrack: Attention in Attention for Transformer Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.09603)] 
  [[code](https://github.com/Little-Podi/AiATrack)]

- **HCAT:** Xin Chen, Dong Wang, Dongdong Li, Huchuan Lu.<br />
  "Efficient Visual Tracking via Hierarchical Cross-Attention Transformer." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.13537)] 
  [[code](https://github.com/chenxin-dlut/HCAT)]

- **SLTtrack:** Minji Kim, Seungkwan Lee, Jungseul Ok, Bohyung Han, Minsu Cho.<br />
  "Towards Sequence-Level Training for Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.05810)] 
  [[code](https://github.com/byminji/SLTtrack)]
  
- **FEAR:** Vasyl Borsuk, Roman Vei, Orest Kupyn, Tetiana Martyniuk, Igor Krashenyi, Jiři Matas.<br />
  "FEAR: Fast, Efficient, Accurate and Robust Visual Tracker." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2112.07957.pdf)] 
  [[code](https://xxxxxxx)]
  
- **PersonPath22:** Bing Shuai, Alessandro Bergamo, Uta Buechler, Andrew Berneshawi, Alyssa Boden, Joseph Tighe.<br />
  "Large Scale Real-World Multi-Person Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2211.02175)] 
  [[code](https://amazon-science.github.io/tracking-dataset/personpath22.html)]
  
- **STNet:** Le Hui, Lingpeng Wang, Linghua Tang, Kaihao Lan, Jin Xie, Jian Yang.<br />
  "3D Siamese Transformer Network for Single Object Tracking on Point Clouds." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.11995)] 
  [[code](https://github.com/fpthink/STNet)]
  
- **P3AFormer:** Zelin Zhao, Ze Wu, Yueqing Zhuang, Boxun Li, Jiaya Jia.<br />
  "Tracking Objects as Pixel-wise Distributions." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.05518)] 
  [[code](https://sjtuytc.github.io/zelin_pages/p3aformer.html)]
  
- **TETer:** Siyuan Li, Martin Danelljan, Henghui Ding, Thomas E. Huang, Fisher Yu.<br />
  "Tracking Every Thing in the Wild." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.12978)] 
  [[code](http://vis.xyz/pub/tet)]
  
- **ByteTrack:** Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang.<br />
  "ByteTrack: Multi-Object Tracking by Associating Every Detection Box." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2110.06864v2.pdf)] 
  [[code](https://github.com/ifzhang/ByteTrack)]

- **MOTR:** Fangao Zeng, Bin Dong, Yuang Zhang, Tiancai Wang, Xiangyu Zhang, Yichen Wei.<br />
  "MOTR: End-to-End Multiple-Object Tracking with Transformer." ECCV (2022).
  [[paper](https://arxiv.org/abs/2105.03247)] 
  [[code](https://github.com/megvii-research/MOTR)]
  
- **MTracker:** Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, Wenyu Liu.<br />
  "Robust Multi-Object Tracking by Marginal Inference." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.03727)] 
  [[code](https://xxxxxxx)]
  

  
  
### CVPR 2022

- **MixFormer:** Yutao Cui, Jiang Cheng, Limin Wang, Gangshan Wu.<br />
  "MixFormer: End-to-End Tracking with Iterative Mixed Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11082)] 
  [[code](https://github.com/MCG-NJU/MixFormer)]
  
- **OWTB:** Yang Liu, Idil Esen Zulfikar, Jonathon Luiten, Achal Dave, Deva Ramanan, Bastian Leibe, Aljoša Ošep, Laura Leal-Taixé.<br />
  "Opening up Open-World Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2104.11221)] 
  [[code](https://openworldtracking.github.io/)]
  
- **UTT:** Fan Ma, Mike Zheng Shou, Linchao Zhu, Haoqi Fan, Yilei Xu, Yi Yang, Zhicheng Yan.<br />
  "Unified Transformer Tracker for Object Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.15175)] 
  [[code](https://github.com/Flowerfan/Trackron)]
  
- **CSWinTT:** Zikai Song, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Transformer Tracking with Cyclic Shifting Window Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2205.03806)] 
  [[code](https://github.com/SkyeSong38/CSWinTT)]
  
- **ToMP:** Christoph Mayer, Martin Danelljan, Goutam Bhat, Matthieu Paul, Danda Pani Paudel, Fisher Yu, Luc Van Gool.<br />
  "Transforming Model Prediction for Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11192)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **TCTrack:** Ziang Cao, Ziyuan Huang, Liang Pan, Shiwei Zhang, Ziwei Liu, Changhong Fu.<br />
  "TCTrack: Temporal Contexts for Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01885)] 
  [[code](https://github.com/vision4robotics/TCTrack)]
  
- **SBT:** Fei Xie, Chunyu Wang, Guangting Wang, Yue Cao, Wankou Yang, Wenjun Zeng.<br />
  "Correlation-Aware Deep Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01666)] 
  [[code](https://github.com/phiphiphi31/SuperSBT)]
  
- **AdaRS:** Yihao Li, Jun Yu, Zhongpeng Cai, Yuwen Pan.<br />
  "Cross-Modal Target Retrieval for Tracking by Natural Language." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/html/Li_Cross-Modal_Target_Retrieval_for_Tracking_by_Natural_Language_CVPRW_2022_paper.html)] 
  [[code](xxxx)]
  
- **STNet:** Jiqing Zhang, Bo Dong, Haiwei Zhang, Jianchuan Ding, Felix Heide, Baocai Yin, Xin Yang.<br />
  "Spiking Transformers for Event-based Single Object Tracking." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html)] 
  [[code](https://github.com/Jee-King/CVPR2022_STNet)]
  
- **VTUAV:** Pengyu Zhang, Jie Zhao, Dong Wang, Huchuan Lu, Xiang Ruan.<br />
  "Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.04120)] 
  [[code](https://zhang-pengyu.github.io/DUT-VTUAV/)]
  
- **UAVMOT:** Shuai Liu, Xin Li, Huchuan Lu, You He.<br />
  "Multi-Object Tracking Meets Moving UAV." CVPR (2022).
  [[paper](https://arxiv.org/abs/xxxx.xxxx)] 
  [[code](https://github.com/LiuShuaiyr/UAVMOT)]
  
- **GTR:** Xingyi Zhou, Tianwei Yin, Vladlen Koltun, Phillip Krähenbühl.<br />
  "Global Tracking Transformers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.13250)] 
  [[code](https://github.com/xingyizhou/GTR)]
  
- **GTELT:** Zikun Zhou, Jianqiu Chen, Wenjie Pei, Kaige Mao, Hongpeng Wang, Zhenyu He.<br />
  "Global Tracking via Ensemble of Local Trackers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.16092)] 
  [[code](https://github.com/ZikunZhou/GTELT)]
  
- **RBO:** Feng Tang, Qiang Ling.<br />
  "Ranking-based Siamese Visual Tracking." CVPR (2022).
  [[paper](https://arxiv.org/pdf/2205.11761.pdf)] 
  [[code](https://github.com/sansanfree/RBO)]
  
- **ULAST:** Qiuhong Shen, Lei Qiao, Jinyang Guo, Peixia Li, Xin Li, Bo Li, Weitao Feng, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Unsupervised Learning of Accurate Siamese Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.01475)] 
  [[code](https://github.com/FlorinShum/ULAST)]
  
- **UDAT:** Junjie Ye, Changhong Fu, Guangze Zheng, Danda Pani Paudel, Guang Chen.<br />
  "Unsupervised Domain Adaptation for Nighttime Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.10541)] 
  [[code](https://github.com/vision4robotics/UDAT)]
  
- **M2Track:** Chaoda Zheng, Xu Yan, Haiming Zhang, Baoyuan Wang, Shenghui Cheng, Shuguang Cui, Zhen Li.<br />
  "Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01730)] 
  [[code](https://github.com/Ghostish/Open3DSOT)]
  

### IJCAI 2022

- **InBN:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing, Yilin Lyu, Bing Li, Weiming Hu.<br />
  "Learning Target-aware Representation for Visual Tracking via Informative Interactions." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2201.02526)] 
  [[code](https://xxxxxxx)]
  
- **SparseTT:** Zhihong Fu, Zehua Fu, Qingjie Liu, Zehua Fu, Yunhong Wang.<br />
  "SparseTT: Visual Tracking with Sparse Transformers." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.03776)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
- **HybTransT:** Ilchae Jung, Minji Kim, Eunhyeok Park, Bohyung Han.<br />
  "Online Hybrid Lightweight Representations Learning: Its Application to Visual Tracking." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.11179)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
  
### MICCAI 2022

- **TLT:** Wen Tang, Han Kang, Haoyue Zhang, Pengxin Yu, Corey W. Arnold, Rongguo Zhang.<br />
  "Transformer Lesion Tracker." MICCAI (2022).
  [[paper](https://arxiv.org/abs/2206.06252)] 
  [[code](https://github.com/TangWen920812/TLT)]
  
  
### ArXiv 2022
 
- **VisDrone:** Pengfei Zhu, Longyin Wen, Dawei Du, Xiao Bian, Heng Fan, Qinghua Hu, Haibin Ling.<br />
  "Detection and Tracking Meet Drones Challenge." TPAMI (2022).
  [[paper](https://arxiv.org/abs/2001.06303)] 
  [[code](https://github.com/VisDrone/VisDrone-Dataset)]

- **GIT:** Shiyu Hu, Xin Zhao, Lianghua Huang, Kaiqi Huang.<br />
  "Global Instance Tracking: Locating Target More Like Humans." IEEE TPAMI (2022).
  [[paper](https://arxiv.org/pdf/2202.13073.pdf)] 
  [[code](http://videocube.aitestunion.com/)]

- **ProTrack:** Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Prompting for Multi-Modal Tracking." ACM MM (2022).
  [[paper](https://arxiv.org/abs/2207.14571)] 
  [[code]( )]

- **QuadTreeCapsule:** Ding Ma, Xiangqian Wu.<br />
  "QuadTreeCapsule: QuadTree Capsules for Deep Regression Tracking." ACM MM (2022).
  [[paper](https://dl.acm.org/doi/10.1145/3503161.3548236)] 
  [[code]( )]
  
- **GATransT:** Libo Wang, Si Chen, Zhen Wang, Da-Han Wang, Shunzhi Zhu.<br />
  "Graph Attention Transformer Network for Robust Visual Tracking." ICONIP (2022).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-99-1639-9_14)] 
  [[code]()]

- **SiamTDN:** Yanjie Liang, Penghui Zhao, Yifei Hao, Hanzi Wang.<br />
  "Siamese Template Diffusion Networks for Robust Visual Tracking." ICME (2022).
  [[paper](https://ieeexplore.ieee.org/document/9859929)] 
  [[code]()]
  
- **TAT:** Kaihao Lan, Haobo Jiang, Jin Xie.<br />
  "Temporal-aware Siamese Tracker: Integrate Temporal Context for 3D Object Tracking." ACCV (2022).
  [[paper](https://openaccess.thecvf.com/content/ACCV2022/html/Lan_Temporal-aware_Siamese_Tracker_Integrate_Temporal_Context_for_3D_Object_Tracking_ACCV_2022_paper.html)] 
  [[code](https://github.com/tqsdyy/TAT)]
  
- **EgoTracks:** Hao Tang, Kevin Liang, Kristen Grauman, Matt Feiszli, Weiyao Wang.<br />
  "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2301.03213)] 
  [[code]()]
  
 - **COESOT:** Chuanming Tang, Xiao Wang, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang, Yaowei Wang, Yonghong Tian.<br />
  "Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.11010)] 
  [[code](COESOT)]
  
- **WATB:** Fasheng Wang, Ping Cao, Fu Li, Xing Wang, Bing He, Fuming Sun.<br />
  "WATB: Wild Animal Tracking Benchmark." IJCV (2022).
  [[paper](https://link.springer.com/content/pdf/10.1007/s11263-022-01732-3.pdf?pdf=button)] 
  [[code](https://w-1995.github.io/)]
  
- **UAV2UAV:** Yong Wang, Zirong Huang, Robert Laganière, Huanlong Zhang, Lu Ding.<br />
  "A UAV to UAV tracking benchmark." KBS (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S095070512201293X)] 
  [[code](https://github.com/hapless19/UAV2UAV-dataset)]
  
- **UOT100:** K. Panetta, L. Kezebou, V. Oludare, and S. S. Agaian.<br />
  "Comprehensive Underwater Object Tracking Benchmark Dataset and Underwater Image Enhancement With GAN." IEEE JOE (2022).
  [[paper](https://ieeexplore.ieee.org/document/9499961)] 
  [[code](https://www.kaggle.com/datasets/landrykezebou/uot100-underwater-object-tracking-dataset)]
  
- **NeighborTrack:** Yu-Hsi Chen, Chien-Yao Wang, Cheng-Yun Yang, Hung-Shuo Chang, Youn-Long Lin, Yung-Yu Chuang, Hong-Yuan Mark Liao.<br />
  "NeighborTrack: Improving Single Object Tracking by Bipartite Matching with Neighbor Tracklets." ArXiv (2022).
  [[paper](https://arxiv.org/pdf/2211.06663.pdf)] 
  [[code](https   )]
  
- **MTTSiam:** Ali Sekhavati, Won-Sook Lee.<br />
  "Multi-Template Temporal Siamese Network for Long-Term Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13812)] 
  [[code](https://github.com/AliGreen0/MTTSiam)]
  
- **PruningInTracking:** Saksham Aggarwal, Taneesh Gupta, Pawan Kumar Sahu, Arnav Chavan, Rishabh Tiwari, Dilip K. Prasad, Deepak K. Gupta.<br />
  "On designing light-weight object trackers through network pruning: Use CNNs or transformers?." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13769)] 
  [[code](https   )]
  
- **ProContEXT:** Jin-Peng Lan, Zhi-Qi Cheng, Jun-Yan He, Chenyang Li, Bin Luo, Xu Bao, Wangmeng Xiang, Yifeng Geng, Xuansong Xie.<br />
  "ProContEXT: Exploring Progressive Context Transformer for Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2210.15511)] 
  [[code](https://drive.google.com/drive/folders/18kHdBNEwvbk8S4-mwHaI-mw5w6cK-pyY?usp=sharing)]
  
- **TSFMO:** Zhewen Zhang, Fuliang Wu, Yuming Qiu, Jingdong Liang, Shuiwang Li.<br />
  "Tracking Small and Fast Moving Objects: A Benchmark." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2209.04284)] 
  [[code](https://github.com/CodeOfGithub/S-KeepTrack)]
  
- **SFTransT:** Chuanming Tang, Xiao Wang, Yuanchao Bai, Zhe Wu, Jianlin Zhang, Yongmei Huang.<br />
  "Learning Spatial-Frequency Transformer for Visual Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.08829)] 
  [[code](https://github.com/Tchuanm/SFTransT.git)]
  
- **DMTracker:** Shang Gao, Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Learning Dual-Fused Modality-Aware Representations for RGBD Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.03055)] 
  [[code](https://github.com/ShangGaoG/DMTracker)]
  
- **AVisT:** Mubashir Noman, Wafa Al Ghallabi, Daniya Najiha, Christoph Mayer, Akshay Dudhane, Martin Danelljan, Hisham Cholakkal, Salman Khan, Luc Van Gool, Fahad Shahbaz Khan.<br />
  "AVisT: A Benchmark for Visual Object Tracking in Adverse Visibility." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.06888)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **RGBDReview:** Jinyu Yang, Zhe Li, Song Yan, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen, Ling Shao.<br />
  "RGBD Object Tracking: An In-depth Review." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.14134)] 
  [[code](https://github.com/memoryunreal/RGBD-tracking-review)]
  
- **WebUAV-3M:** Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Yuxuan Zhang, Xiang Wan, Shiming Ge.<br />
  "WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.07425)] 
  [[code](https://github.com/983632847/WebUAV-3M)]
  
- **SiamTracking4UAV:** Changhong Fu, Kunhan Lu, Guangze Zheng, Junjie Ye, Ziang Cao, Bowen Li.<br />
  "Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2205.04281)] 
  [[code](https://github.com/vision4robotics/SiameseTracking4UAV)]
  
- **SOTSurvey:** Zahra Soleimanitaleb, Mohammad Ali Keyvanrad.<br />
  "Single Object Tracking: A Survey of Methods, Datasets, and Evaluation Metrics." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.13066)] 
  
- **SOTRearch:** Ruize Han, Wei Feng, Qing Guo, Qinghua Hu.<br />
  "Single Object Tracking Research: A Survey." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.11410)] 
  
- **VOTSurvey:** Fei Chen, Xiaodong Wang, Yunxiang Zhao, Shaohe Lv, Xin Niu.<br />
  "Visual object tracking: A survey." CVIU (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1077314222001011?dgcid=author)] 
  
- **TransT-M:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Huchuan Lu.<br />
  "High-Performance Transformer Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13533)] 
  [[code](https://github.com/chenxin-dlut/TransT-M)]
   
- **GUSOT:** Zhiruo Zhou, Hongyu Fu, Suya You, C. -C. Jay Kuo.<br />
  "GUSOT: Green and Unsupervised Single Object Tracking for Long Video Sequences" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.07629)] 
  [[code](https://github.com/xxxxxx)]
  
- **SiamAttack:** Zhenbang Li, Yaya Shi, Jin Gao, Shaoru Wang, Bing Li, Pengpeng Liang.<br />
  "A Simple and Strong Baseline for Universal Targeted Attacks on Siamese Visual Tracking" IEEE TCSVT (2022).
  [[paper](https://ieeexplore.ieee.org/document/9576540)] 
  [[code](https://github.com/lizhenbang56/SiamAttack)]

- **SRRT:** Jiawen Zhu, Xin Chen, Dong Wang, Wenda Zhao, Huchuan Lu.<br />
  "SRRT: Exploring Search Region Regulation for Visual Object Tracking" IEEE TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10549949)] 
  [[code]( )]
  
- **DIMBA:** Xiangyu Yin, Wenjie Ruan, Jonathan Fieldsend.<br />
  "DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.08044)] 
  [[code](https://github.com/xxxxxxxx)]
  
- **P-SiamFC++:** Xucheng Wang, Dan Zeng, Qijun Zhao, Shuiwang Li.<br />
  "Rank-Based Filter Pruning for Real-Time UAV Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.01768)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **SkeleVision:** Nilaksh Das, Sheng-Yun Peng, Duen Horng Chau.<br />
  "SkeleVision: Towards Adversarial Resiliency of Person Tracking with Multi-Task Learning." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.00734)] 
  [[code](https://github.com/nilakshdas/SkeleVision)]
  
- **CAJMU:** Qiuhong Shen, Xin Li, Fanyang Meng, Yongsheng Liang.<br />
  "Context-aware Visual Tracking with Joint Meta-updating." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.01513)] 
  [[code](https://github.com/xxxxxxxx)]
  
- **ResamplingNet:** Haobo Zuo, Changhong Fu, Sihang Li, Junjie Ye, and Guangze Zheng.<br />
  "ResamplingNet: End-to-End Adaptive Feature Resampling Network for Real-Time Aerial Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/ResamplingNet)]
  
- **LPAT:** Changhong Fu, Weiyu Peng, Sihang Li, Junjie Ye, and Ziang Cao.<br />
  "Local Perception-Aware Transformer for Aerial Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.00662)] 
  [[code](https://github.com/vision4robotics/LPAT)]
  
- **AFRT:** Haobo Zuo, Changhong Fu, Sihang Li, Junjie Ye, and Guangze Zheng.<br />
  "End-to-End Feature Decontaminated Network for UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/FDNT)]
  
- **FDT:** Changhong Fu, Haobo Zuo, Guangze Zheng, Junjie Ye, and Bowen Li.<br />
  "Feature-Distilled Transformer for UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/FDT-tracker)]
  
- **HighlightNet:** Changhong Fu, Haolin Dong.<br />
  "HighlightNet: Highlighting Low-Light Potential Features for Real-Time UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/HighlightNet)]
  
- **LAE-PVT:** Bowen Li, Yiming Li, Junjie Ye, Changhong Fu, and Hang Zhao.<br />
  "Predictive Visual Tracking: A New Benchmark and Baseline Approach." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/LAE-PVT-master)]
  
- **SiamPSA:** Guangze Zheng, Changhong Fu, Junjie Ye, Bowen Li, Geng Lu, and Jia Pan.<br />
  "SiamPSA: Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/SiamPSA)]
  
- **AdaptiveSiam:** Madhu Kiran, Le Thanh Nguyen-Meidine, Rajat Sahay, Rafael Menelau Oliveira E Cruz, Louis-Antoine Blais-Morin, Eric Granger.<br />
  "Generative Target Update for Adaptive Siamese Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2202.09938)] 
  [[code](https://anonymous.4open.science/r/AdaptiveSiamese-CE78/)]
  
- **DST:** Yao Sui, Guanghui Wang, Li Zhang.<br />
  "In Defense of Subspace Tracker: Orthogonal Embedding for Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.07927)] 
  [[code](https://xxxxxxx)]
  
- **SiamLA:** Jiahao Nie, Han Wu, Zhiwei He, Yuxiang Yang, Mingyu Gao, Zhekang Dong.<br />
  "Learning Localization-aware Target Confidence for Siamese Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.14093)] 
  [[code](https://xxxxxxx/)]
  
- **DUT-Anti-UAV:** Jie Zhao, Jingshu Zhang, Dongdong Li, Dong Wang.<br />
  "Vision-based Anti-UAV Detection and Tracking." TITS (2022).
  [[paper](https://arxiv.org/abs/2205.10851)] 
  [[code](https://github.com/wangdongdut/DUT-Anti-UAV)]
  
- **CoCoLoT:** Matteo Dunnhofer, Christian Micheloni.<br />
  "CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking." ICPR (2022).
  [[paper](https://arxiv.org/abs/2205.04261)] 
  [[code](https://xxxxxxx)]
  
- **EUSA:** Siao Liu, Zhaoyu Chen, Wei Li, Jiwei Zhu, Jiafeng Wang, Wenqiang Zhang, Zhongxue Gan.<br />
  "Efficient universal shuffle attack for visual object tracking." ICASSP (2022).
  [[paper](https://arxiv.org/abs/2203.06898)] 
  [[code](https://xxxxxxx)]
  
- **ITB:** Xin Li, Qiao Liu, Wenjie Pei, Qiuhong Shen, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "An Informative Tracking Benchmark." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2112.06467)] 
  [[code](https://github.com/XinLi-zn/Informative-tracking-benchmark)]
  
- **VisEvent:** Xiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li, Yaowei Wang, Yonghong Tian, Feng Wu.<br />
  "VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2108.05015)] 
  [[code](https://sites.google.com/view/viseventtrack/)]
  
- **RPT++:** Ziang Ma, Haitao Zhang, Linyuan Wang, Jun Yin.<br />
  "RPT++: Customized Feature Representation for Siamese Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.12194)] 
  [[code](https://xxxxxxx/)]
  
- **IAT:** Mengmeng Wang, Xiaoqian Yang, Yong Liu.<br />
  "Explicitly Modeling the Discriminability for Instance-Aware Visual Object Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.13259)] 
  [[code](https://xxxxxxx/)]
  
- **ALT:** Di Yuan, Xiaojun Chang, Qiao Liu, Dehua Wang, Zhenyu He.<br />
  "Active Learning for Deep Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.15030)] 
  [[code](https://xxxxxxx/)]
  
- **FSLT:** Jinghao Zhou, Bo Li, Peng Wang, Peixia Li, Weihao Gan, Wei Wu, Junjie Yan, Wanli Ouyang.<br />
  "Real-Time Visual Object Tracking via Few-Shot Learning." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2103.10130.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **DML:** Jinghao Zhou, Bo Li, Lei Qiao, Peng Wang, Weihao Gan, Wei Wu, Junjie Yan, Wanli Ouyang.<br />
  "Higher Performance Visual Tracking with Dual-Modal Localization." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2103.10089.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **TREG:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Target Transformed Regression for Accurate Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2104.00403.pdf)] 
  [[code](https://github.com/MCG-NJU/TREG)]
  
- **SiamSTM:** Jinpu Zhang, Yuehuan Wang.<br />
  "Spatio-Temporal Matching for Siamese Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.02408.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **TrTr:** Moju Zhao, Kei Okada, Masayuki Inaba.<br />
  "TrTr: Visual Tracking with Transformer." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.03817.pdf)] 
  [[code](https://github.com/tongtybj/TrTr)]

- **TS-RCN:** Ning Zhang, Jingen Liu, Ke Wang, Dan Zeng, Tao Mei.<br />
  "Robust Visual Object Tracking with Two-Stream Residual Convolutional Networks." ArXiv (2020).
  [[paper](https://arxiv.org/pdf/2005.06536.pdf)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **DMV:** Gunhee Nam, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "DMV: Visual Object Tracking via Part-level Dense Memory and Voting-based Retrieval." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2003.09171v1)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **FCOT:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Fully Convolutional Online Tracking." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2004.07109)] 
  [[code](https://github.com/MCG-NJU/FCOT)]
  
  
### AAAI 2022

- **HDN:** Xinrui Zhan, Yueran Liu, jianke Zhu, Yang Li.<br />
  "Homography Decomposition Networks for Planar Object Tracking." AAAI (2022).
  [[paper](https://arxiv.org/pdf/2112.07909.pdf)] 
  [[code](https://github.com/zhanxinrui/HDN)]

- **MArMOT:** Chenglong Li, Tianhao Zhu, Lei Liu, Xiaonan Si, Zilin Fan, Sulan Zhai.<br />
  "Cross-Modal Object Tracking: Modality-Aware Representations and a Unified Benchmark." AAAI (2022).
  [[paper](https://arxiv.org/abs/2111.04264)] 
  [[code](https://github.com/xxxxx/MArMOT)]

- **APFNet:** Yun Xiao, Mengmeng Yang, Chenglong Li, Lei Liu, Jin Tang.<br />
  "Attribute-based Progressive Fusion Network for RGBT Tracking." AAAI (2022).
  [[paper](https://github.com/yangmengmeng1997/APFNet/tree/main/Paper)] 
  [[code](https://github.com/yangmengmeng1997/APFNet)]

- **TAV:** Tahar Allouche, Jerome Lang, Florian Yger.<br />
  "Truth-Tracking via Approval Voting: Size Matters." AAAI (2022).
  [[paper](https://arxiv.org/abs/2112.04387)] 
  [[code](https://github.com/zhanxinrui/HDN)]
  
  
### ICLR 2022

- **FSBA:** Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia.<br />
  "Few-Shot Backdoor Attacks on Visual Object Tracking." ICLR (2022).
  [[paper](https://openreview.net/pdf?id=qSV5CuSaK_a)] 
  [[code](https://www.dropbox.com/s/nfg7en8azc1cvz3/codes_FSBA_ICLR22.zip?dl=0)]
  
  
### ICRA 2022

- **Ad2Attack:** Changhong Fu, Sihang Li, Xinnan Yuan, Junjie Ye, Ziang Cao, Fangqiang Ding.<br />
  "Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking." ICRA (2022).
  [[paper](https://arxiv.org/abs/2203.01516)] 
  [[code](https://github.com/vision4robotics/Ad2Attack)]
 
- **SCT:** Junjie Ye, Changhong Fu, Ziang Cao, Shan An, Guangze Zheng, Bowen Li.<br />
  "Tracker Meets Night: A Transformer Enhancer for UAV Tracking." ICRA/RAL (2022).
  [[paper](https://ieeexplore.ieee.org/document/9696362)] 
  [[code](https://github.com/vision4robotics/SCT)]

- **SiamX:** Huajian Huang, Sai-Kit Yeung.<br />
  "SiamX: An Efficient Long-term Tracker Using Cross-level Feature Correlation and Adaptive Tracking Scheme." ICRA (2022).
  [[paper](https://huajianup.github.io/research/SiamX/SiamX_ICRA2022_final.pdf)] 
  [[code](https://huajianup.github.io/research/SiamX/)]
 
 
### WACV 2022

- **SiamTPN:** Daitao Xing, Nikolaos Evangeliou, Athanasios Tsoukalas, Anthony Tzes.<br />
  "Siamese Transformer Pyramid Networks for Real-Time UAV Tracking." WACV (2022).
  [[paper](https://arxiv.org/pdf/2110.08822.pdf)] 
  [[code](https://github.com/RISC-NYUAD/SiamTPNTracker)]
  
### ICCV 2021

- **STARK:** Bin Yan, Houwen Peng, Jianlong Fu, Dong Wang, Huchuan Lu.<br />
  "Learning Spatio-Temporal Transformer for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2103.17154.pdf)] 
  [[code](https://github.com/researchmm/Stark)]
  
- **AutoMatch:**  Zhang Zhipeng, Liu Yihao, Wang Xiao, Li Bing, Hu Weiming. <br />
  "Learn to Match: Automatic Matching Network Design for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00803.pdf)]
  [[code](https://github.com/JudasDie/SOTS)]
  
- **DDT:** Bin Yu, Ming Tang, Linyu Zheng, Guibo Zhu, Jinqiao Wang.<br />
  "High-Performance Discriminative Tracking with Transformers." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.pdf)] 
  [[code](https://github.com/xxxx/xxxx)]
  
- **HiFT:**  Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li. <br />
  "HiFT: Hierarchical Feature Transformer for Aerial Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00202.pdf)]
  [[code](https://github.com/vision4robotics/HiFT)]
  
- **DualTFR:**  Fei Xie, Chunyu Wang, Guangting Wang, Wankou Yang, Wenjun Zeng. <br />
  "Learning Tracking Representations via Dual-Branch Fully Transformer Networks." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2112.02571)]
  [[code](https://github.com/phiphiphi31/DualTFR)]
  
- **DMB:**  Fei Xie, Wankou Yang, Kaihua Zhang, Bo Liu, Wanli Xue, Wangmeng Zuo. <br /> 
  "Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking." ICCVW (2021).
  [[paper](https://arxiv.org/pdf/2009.09669.pdf)]
  [[code](https://github.com/phiphiphi31/DMB)]

- **KeepTrack:** Christoph Mayer, Martin Danelljan, Danda Pani Paudel, Luc Van Gool.<br />
  "Learning Target Candidate Association to Keep Track of What Not to Track." ICCV (2021).
  [[paper](https://arxiv.org/abs/2103.16556)] 
  [[code](https://github.com/visionml/pytracking)]

- **SAOT:** Zikun Zhou, Wenjie Pei, Xin Li, Hongpeng Wang, Feng Zheng, Zhenyu He. <br />
  "Saliency-Associated Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03637.pdf)]
  [[code](https://github.com/ZikunZhou/SAOT)]
 
- **MLVSNet:** Zhoutao Wang, Qian Xie, Yu-Kun Lai, Jing Wu, Kun Long , Jun Wang. <br />
  "MLVSNet: Multi-level Voting Siamese Network for 3D Visual Tracking." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_MLVSNet_Multi-Level_Voting_Siamese_Network_for_3D_Visual_Tracking_ICCV_2021_paper.pdf)]
  [[code](https://github.com/CodeWZT/MLVSNet)]
  
 - **EFTrack:** Jiqing Zhang, Xin Yang, Yingkai Fu, Xiaopeng Wei, Baocai Yin, Bo Dong. <br />
  "Object Tracking by Jointly Exploiting Frame and Event Domain." ICCV (2021).
  [[paper](https://arxiv.org/abs/2109.09052)]
  [[code](https://github.com/Jee-King/ICCV2021_Event_Frame_Tracking)]
  
 - **Box2Mask:** Bin Zhao, Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Generating Masks from Boxes by Mining Spatio-Temporal Consistencies in Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2101.02196)]
  [[code](https://github.com/visionml/pytracking)]
  
- **DepthTrack:** Song Yan, Jinyu Yang, Jani Käpylä, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen. <br />
  "DepthTrack : Unveiling the Power of RGBD Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.13962)]
  [[code](https://github.com/xiaozai/DeT)]
  
- **USOT:** Jilai Zheng, Chao Ma, Houwen Peng, Xiaokang Yang. <br />
  "Learning to Track Objects from Unlabeled Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.12711)]
  [[code](https://github.com/VISION-SJTU/USOT)]
  
- **TOTB:** Heng Fan, Halady Akhilesha Miththanthaya, Harshit, Siranjiv Ramana Rajan, Xiaoqiong Liu, Zhilin Zou, Yuewei Lin, Haibin Ling. <br />
  "Transparent Object Tracking Benchmark." ICCV (2021).
  [[paper](https://arxiv.org/abs/2011.10875)]
  [[code](https://hengfan2010.github.io/projects/TOTB/)]
  
- **TREK-150:** Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, Christian Micheloni. <br />
  "Is First Person Vision Challenging for Object Tracking?." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2108.13665)]
  [[code](https://machinelearning.uniud.it/datasets/trek150/)]
  [[toolkit](https://github.com/matteo-dunnhofer/TREK-150-toolkit)]
  
- **VASR:** Kenan Dai, Jie Zhao, Lijun Wang, Dong Wang, Jianhua Li, Huchuan Lu, Xuesheng Qian, Xiaoyun Yang. <br />
  "Video Annotation for Visual Tracking via Selection and Refinement." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03821.pdf)]
  [[code](https://github.com/Daikenan/VASR)]
  
- **BAT:** Chaoda Zheng, Xu Yan, Jiantao Gao, Weibing Zhao, Wei Zhang, Zhen Li, Shuguang Cui. <br />
  "Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.04728.pdf)]
  [[code](https://github.com/Ghostish/BAT)]
  
- **ABA:** Qing Guo, Ziyi Cheng, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yang Liu, Jianjun Zhao. <br />
  "Learning to Adversarially Blur Visual Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2107.12085)]
  [[code](https://github.com/tsingqguo/ABA)]
  
  
### CVPR 2021

- **TransT:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun yang, Huchuan Lu. <br />
  "Transformer Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.15436)]
  [[code](https://github.com/chenxin-dlut/TransT)]
  
- **Alpha-Refine:** Bin Yan, Xinyu Zhang, Dong Wang, Huchuan Lu, Xiaoyun Yang. <br />
  "Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation." CVPR (2021).
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)]
  [[code](https://github.com/MasterBin-IIAU/AlphaRefine)]
  
- **LightTrack:** Bin Yan, Houwen Peng, Kan Wu, Dong Wang, Jianlong Fu, Huchuan Lu. <br />
  "LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.14545)]
  [[code](https://github.com/cvpr-2021/lighttrack)]
  
- **TrTrack:** Ning Wang, Wengang Zhou, Jie Wang, Houqiang Li. <br />
  "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.11681.pdf)]
  [[code](https://github.com/594422814/TransformerTrack)]
  
- **STMTrack:** Zhihong Fu, Qingjie Liu, Zehua Fu, Yunhong Wang. <br />
  "STMTrack: Template-free Visual Tracking with Space-time Memory Networks." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00324)]
  [[code](https://github.com/fzh0917/STMTrack)]
  
- **SiamGAT:** Dongyan Guo, Yanyan Shao, Ying Cui, Zhenhua Wang, Liyan Zhang, Chunhua Shen.<br />
  "Graph Attention Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2011.11204)] 
  [[code](https://github.com/ohhhyeahhh/SiamGAT)]
  
- **SiamACM:** Wencheng Han, Xingping Dong, Fahad Shahbaz Khan, Ling Shao, Jianbing Shen.<br />
  "Learning to Fuse Asymmetric Feature Maps in Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2012.02776.pdf)] 
  [[code](https://github.com/wencheng256/SiamBAN-ACM)]
  
- **PST:** Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "Polygonal Point Set Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.pdf)] 
  [[code](https://github.com/PST)]
  
- **PUL:** Qiangqiang Wu, Jia Wan, Antoni B. Chan. <br />
  "Progressive Unsupervised Learning for Visual Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.pdf)]
  [[code](https://github.com/PUL)]
  
- **CapsuleRRT:** Ding Ma, Xiangqian Wu. <br />
  "CapsuleRRT: Relationships-Aware Regression Tracking via Capsules." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.pdf)]
  [[code](https://github.com/CapsuleRRT)]
  
- **Semi-Track:** Yang Fu, Sifei Liu, Umar Iqbal, Shalini De Mello, Humphrey Shi, Jan Kautz.<br />
  "Learning to Track Instances without Video Annotations." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2104.00287.pdf)] 
  [[code](https://oasisyang.github.io/projects/semi-track/index.html)]

- **RE-Siam:** Deepak K. Gupta, Devanshu Arya, Efstratios Gavves. <br />
  "Rotation Equivariant Siamese Networks for Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2012.13078)]
  [[code](https://github.com/dkgupta90/re-siamnet)]
  
- **SiamNLP:** Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff. <br />
  "Siamese Natural Language Tracker: Tracking by Natural Language Descriptions with Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/abs/1912.02048v2)]
  [[code](https://github.com/fredfung007/snlt)]
  
- **LangTrackBenchmark:** Xiao Wang, Xiujun Shu, Zhipeng Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu. <br />
  "Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.16746.pdf)]
  [[code](https://sites.google.com/view/langtrackbenchmark/)]
  
- **DroneCrowd:** Longyin Wen, Dawei Du, Pengfei Zhu, Qinghua Hu, Qilong Wang, Liefeng Bo, Siwei Lyu. <br />
  "Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2105.02440.pdf)]
  [[code](https://github.com/VisDrone/DroneCrowd)]
  
- **DMTrack:** Zikai Zhang, Bineng Zhong, Shengping Zhang, Zhenjun Tang, Xin Liu, Zhaoxiang Zhang. <br />
  "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.12041)]
  [[code](https://github.com/hqucv/dmtrack)]
  
- **LF-Siam:** Siyuan Cheng, Bineng Zhong, Guorong Li, Xin Liu, Zhenjun Tang, Xianxian Li, Jing Wang. <br />
  "Learning to Filter: Siamese Relation Network for Robust Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00829)]
  [[code](https://github.com/hqucv/siamrn)]
  
- **IoU Attack:** Shuai Jia, Yibing Song, Chao Ma, Xiaokang Yang. <br />
  "IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.14938)]
  [[code](https://github.com/VISION-SJTU/IoUattack)]
  
- **MeanShift++:** Jennifer Jang, Heinrich Jiang. <br />
  "MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.pdf)]
  [[code](https://github.com/MeanShift++)]
  
  
### IROS 2021

- **CRACT:** Heng Fan, Haibin Ling.<br />
  "CRACT: Cascaded Regression-Align-Classification for Robust Visual Tracking." IROS (2020).
  [[paper](https://arxiv.org/abs/2011.12483)] 

- **SiamAPN++:** Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li.<br />
  "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2106.08816.pdf)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]

- **DarkLighter:** Junjie Ye, Changhong Fu, Guangze Zheng, Ziang Cao, Bowen Li.<br />
  "DarkLighter: Light Up the Darkness for UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2107.14389.pdf)] 
  [[code](https://github.com/vision4robotics/DarkLighter)]
  
- **PTT:** Jiayao Shan, Sifan Zhou, Zheng Fang, Yubo Cui.<br />
  "PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds." IROS (2021).
  [[paper](https://arxiv.org/abs/2108.06455)] 
  [[code](https://github.com/shanjiayao/PTT)]
  
  
### NeurIPS 2021

- **PathTrack:** Drew Linsley, Girik Malik, Junkyung Kim, Lakshmi Narasimhan Govindarajan, Ennio Mingolla, Thomas Serre.<br />
  "Tracking Without Re-recognition in Humans and Machines." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/a2557a7b2e94197ff767970b67041697-Abstract.html)] 
  [[code](http://bit.ly/InTcircuit)]
  
- **UniTrack:** Zhongdao Wang, Hengshuang Zhao, Ya-Li Li, Shengjin Wang, Philip Torr, Luca Bertinetto.<br />
  "Do Different Tracking Tasks Require Different Appearance Models?." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/06997f04a7db92466a2baa6ebc8b872d-Abstract.html)] 
  [[code](https://zhongdao.github.io/UniTrack/)]

  
### WACV 2021

- **MART:** Heng Fan, Haibin Ling.<br />
  "MART: Motion-Aware Recurrent Neural Network for Robust Visual Tracking." WACV (2021).
  [[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Fan_MART_Motion-Aware_Recurrent_Neural_Network_for_Robust_Visual_Tracking_WACV_2021_paper.pdf)] 
  [[code](https://hengfan2010.github.io/projects/MART/MART.htm)]
  
- **SiamSE:** Ivan Sosnovik, Artem Moskalev, Arnold Smeulders.<br />
  "Scale Equivariance Improves Siamese Tracking." WACV (2021).
  [[paper](https://arxiv.org/pdf/2007.09115.pdf)] 
  [[code](https://github.com/ISosnovik/SiamSE)]
  
- **TracKlinic:** Heng Fan, Fan Yang, Peng Chu, Yuewei Lin, Lin Yuan, Haibin Ling. <br />
  "TracKlinic: Diagnosis of Challenge Factors in Visual Tracking." WACV (2021).
  [[paper](https://arxiv.org/abs/1911.07959)]
  [[code](https://hengfan2010.github.io/projects/TracKlinic/TracKlinic.htm.)]
  
  
### AAAI 2021

- **MUG:** Lijun Zhou, Antoine Ledent, Qintao Hu, Ting Liu, Jianlin Zhang, Marius Kloft.<br />
  "Model Uncertainty Guides Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16473)] 
  
- **UPA:** Li Ding, Yongwei Wang, Kaiwen Yuan, Minyang Jiang, Ping Wang, Hua Huang, Z. Jane Wang. <br />
  "Towards Universal Physical Attacks on Single Object Tracking." AAAI (2021).
  [[paper](https://www.aaai.org/AAAI21Papers/AAAI-2606.DingL.pdf)]

- **PACNet:** Dawei Zhang, Zhonglong Zheng, Riheng Jia, Minglu Li.<br />
  "Visual Tracking via Hierarchical Deep Reinforcement Learning." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16443)] 
  
- **MSANet:** Xuesong Chen, Canmiao Fu, Feng Zheng, Yong Zhao, Hongsheng Li, Ping Luo, Guo-Jun Qi. <br />
  "A Unified Multi-Scenario Attacking Network for Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16195)]
  

### Others 2021

- **SiamAPN:** Changhong Fu, Ziang Cao, Yiming Li, Junjie Ye, Chen Feng.<br />
  "Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network." IEEE TGRS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9477413)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]
  
- **SiamGAN:** Yifei Zhou, Jing Li, Jun Chang, Yafu Xiao, Jun Wan, Hang Sun.<br />
  "Siamese Guided Anchoring Network for Visual Tracking." IEEE IJCNN (2021).
  [[paper](https://ieeexplore.ieee.org/document/9533985)] 
  [[code](https://github.com/xxxxx.xx)]
  
- **τ:** Matteo Dunnhofer, Kristian Simonato, Christian Micheloni.<br />
  "Combining complementary trackers for enhanced long-term visual object tracking." IVC (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0262885622000774?via%3Dihub)] 
  [[code](https://github.com/xxxxx.xx)]
  
- **CCR:** Shiming Ge, Chunhui Zhang, Shikun Li, Dan Zeng, Dacheng Tao.<br />
  "Cascaded Correlation Refinement for Robust Deep Tracking." IEEE TNNLS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9069312)] 
  [[code](https://github.com/983632847/CCR)]
  
- **PCDHV:** Ying Wang, Tingfa Xu, Jianan Li, Shenwang Jiang, Junjie Chen.<br />
  "Pyramid Correlation based Deep Hough Voting for Visual Object Tracking." ACML (2021).
  [[paper](https://arxiv.org/abs/2110.07994)] 
  
- **TrackMLP:** Tianyu Zhu, Rongkai Ma, Mehrtash Harandi, Tom Drummond. <br />
  "Learning Online for Unified Segmentation and Tracking Models." IJCNN (2021).
  [[paper](https://arxiv.org/abs/2111.06994)]

- **TAPL:** Wei han, Hantao Huang, Xiaoxi Yu.<br />
  "TAPL: Dynamic Part-based Visual Tracking via Attention-guided Part Localization." BMVC (2021).
  [[paper](https://arxiv.org/abs/2110.13027)] 
 
- **CHASE:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Li Cheng, Hossein Ghanei-Yakhdan, Shohreh Kasaei.<br />
  "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search." BMVC (2021).
  [[paper](https://arxiv.org/abs/2107.03463)] 
  
### ECCV 2020

- **Ocean:** Zhipeng Zhang, Houwen Peng, Jianlong Fu, Bing Li, Weiming Hu. <br />
  "Ocean: Object-aware Anchor-free Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2006.10721.pdf)]
  [[code](https://github.com/researchmm/TracKit)]
  
- **KYS:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Know Your Surroundings: Exploiting Scene Information for Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2003.11014v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]
  
- **PGNet:** Bingyan Liao, Chenye Wang, Yayun Wang, Yaonong Wang, Jun Yin. <br />
  "PG-Net: Pixel to Global Matching Network for Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2003.11014)]
  
- **STN:** Yuan Liu, Ruoteng Li, Yu Cheng, Robby T.Tan, Xiubao Sui. <br />
  "Object Tracking using Spatio-Temporal Networks for Future Prediction Location." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670001.pdf)]
  
- **RPT:** Ziang Ma, Linyuan Wang, Haitao Zhang, Wei Lu, Jun Yin. <br />
  "RPT: Learning Point Set Representation for Siamese Visual Tracking." ECCVW (2020).
  [[paper](https://arxiv.org/abs/2008.03467)]
  [[code](https://github.com/zhanght021/RPT)]
  
- **CenterTrack:** Xingyi Zhou, Vladlen Koltun, and Philipp Krahenbuhl. <br />
  "Tracking objects as points." ECCV (2020).
  [[paper](https://arxiv.org/abs/2004.01177)]
  [[code](https://github.com/xingyizhou/CenterTrack)]
  
- **PointTracker:** Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen, Errui Ding, Liusheng Huang. <br />
  "Segment as Points for Efficient Online Multi-Object Tracking and Segmentation." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.01550)]
  [[code](https://github.com/detectRecog/PointTrack)]
  
- **DCFST:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Learning Feature Embeddings for Discriminant Model based Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/1906.10414)]
  [[code](https://github.com/noneUmbrella/DCFST)]
  
- **CLNet:** Xingping Dong, Jianbing Shen, Ling Shao, Fatih Porikli. <br />
  "CLNet: A Compact Latent Network for Fast Adjusting Siamese Tracker." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650375.pdf)]
  [[code](https://github.com/xingpingdong/CLNet-tracking)]
  
- **RTAA:** Shuai Jia, Chao Ma, Yibing Song, Xiaokang Yang. <br />
  "Robust Tracking against Adversarial Attacks." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.09919)]
  [[code](https://github.com/joshuajss/RTAA)]
  
- **EAA:** Siyuan Liang, Xingxing Wei, Siyuan Yao, Xiaochun Cao. <br />
  "Efficient Adversarial Attacks for Visual Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2008.00217)]

- **SPARK:** Qing Guo, Xiaofei Xie, Felix Juefei-Xu, Lei Ma, Zhongguo Li, Wanli Xue, Wei Feng, Yang Liu. <br />
  "SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1910.08681.pdf)]
  
- **CAT:** Chenglong Li, Lei Liu, Andong Lu, Qing Ji, Jin Tang. <br />
  "Challenge-Aware RGBT Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.13143)]

- **JDE:** Zhongdao Wang, Liang Zheng, Yixuan Liu, Shengjin Wang. <br />
  "Towards Real-Time Multi-Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1909.12605v1.pdf)]
  [[code](https://gitee.com/mat026/Towards-Realtime-MOT)]
  
- **Chained-Tracker:** Jinlong Peng, Changan Wang, Fangbin Wan, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yanwei Fu. <br />
  "Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2007.14557.pdf)]
  [[code](https://github.com/pjl1995/CTracker)]
  
- **TAO:** Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan. <br />
  "TAO: A Large-scale Benchmark for Tracking Any Object." ECCV (2020).
  [[paper](https://arxiv.org/abs/2005.10356)]
  [[code](http://taodataset.org/)]

### CVPR2020

* **MAML:** Guangting Wang, Chong Luo, Xiaoyan Sun, Zhiwei Xiong, Wenjun Zeng.<br />
  "Tracking by Instance Detection: A Meta-Learning Approach." CVPR (2020 **Oral**).
  [[paper](https://arxiv.org/pdf/2004.00830v1.pdf)]

* **Siam R-CNN:** Paul Voigtlaender, Jonathon Luiten, Philip H.S. Torr, Bastian Leibe.<br />
  "Siam R-CNN: Visual Tracking by Re-Detection." CVPR (2020).
  [[BoLTVOS](https://arxiv.org/pdf/1904.04552.pdf)] 
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)] 
  [[code](https://www.vision.rwth-aachen.de/page/siamrcnn)]

* **D3S:** Alan Lukežič, Jiří Matas, Matej Kristan.<br />
  "D3S – A Discriminative Single Shot Segmentation Tracker." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/alanlukezic/d3s)]

* **PrDiMP:** Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Probabilistic Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12565v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **ROAM:** Tianyu Yang, Pengfei Xu, Runbo Hu, Hua Chai, Antoni B. Chan.<br />
  "ROAM: Recurrently Optimizing Tracking Model." CVPR (2020).
  [[paper](https://arxiv.org/pdf/1907.12006v3.pdf)]
  [[code](https://github.com/skyoung/ROAM)]

* **AutoTrack:** Yiming Li, Changhong Fu, Fangqiang Ding, Ziyuan Huang, Geng Lu.<br />
  "AutoTrack: Towards High-Performance Visual Tracking for UAV with Automatic Spatio-Temporal Regularization." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12949.pdf)]
  [[code](https://github.com/vision4robotics/AutoTrack)]

* **SiamBAN:** Zedu Chen, Bineng Zhong, Guorong Li, Shengping Zhang, Rongrong Ji.<br />
  "Siamese Box Adaptive Network for Visual Tracking." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/hqucv/siamban)]

* **SiamCAR:** Dongyan Guo, Jun Wang, Ying Cui, Zhenhua Wang, Shengyong Chen.<br />
  "SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/abs/1911.07241)]
  [[code](https://github.com/ohhhyeahhh/SiamCAR)]

* **SiamAttn:** Yuechen Yu, Yilei Xiong, Weilin Huang, Matthew R. Scott. <br />
  "Deformable Siamese Attention Networks for Visual Object Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2004.06711v1.pdf)]
  
* **CSA:** Bin Yan, Dong Wang, Huchuan Lu, Xiaoyun Yang.<br />
  "Cooling-Shrinking Attack: Blinding the Tracker with Imperceptible Noises." CVPR (2020).
  [[paper](https://arxiv.org/abs/2003.09595)]
  [[code](https://github.com/MasterBin-IIAU/CSA)]

* **LTMU:** Kenan Dai, Yunhua Zhang, Dong Wang, Jianhua Li, Huchuan Lu, Xiaoyun Yang.<br />
  "High-Performance Long-Term Tracking with Meta-Updater." CVPR (2020).
  [[paper](https://arxiv.org/abs/2004.00305)]
  [[code](https://github.com/Daikenan/LTMU)]
  
* **MAST:** Zihang Lai, Erika Lu, Weidi Xie.<br />
  "MAST: A Memory-Augmented Self-supervised Tracker." CVPR (2020).
  [[paper](https://arxiv.org/abs/2002.07793)]
  [[code](https://github.com/zlai0/MAST)]
  
* **CGACD:** Fei Du, Peng Liu, Wei Zhao, Xianglong Tang.<br />
  "Correlation-Guided Attention for Corner Detection Based Visual Tracking." CVPR (2020).
  [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Du_Correlation-Guided_Attention_for_Corner_Detection_Based_Visual_Tracking_CVPR_2020_paper.pdf)]
  [[code](https://github.com/feiaxyt/CGACD)]

### IJCAI 2020

- **TLPG-Tracker:** Siyuan Li, Zhi Zhang, Ziyu Liu, Anna Wang, Linglong Qiu, Feng Du. <br />
  "TLPG-Tracker: Joint Learning of Target Localization and Proposal Generation for Visual Tracking." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/99)]
  
- **E3SN:** Meng Lan, Yipeng Zhang, Qinning Xu, Lefei Zhang. <br />
  "E3SN: Efficient End-to-End Siamese Network for Video Object Segmentation." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/98)]
  
### AAAI 2020

- **SiamFC++:** Yinda Xu, Zeyu Wang, Zuoxin Li, Ye Yuan, Gang Yu. <br />
  "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1911.06188v4.pdf)]
  [[code](https://github.com/MegviiDetection/video_analyst)]
  
- **DROL:** Jinghao Zhou, Peng Wang, Haoyang Sun. <br />
  "Discriminative and Robust Online Learning for Siamese Visual Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1909.02959)]
  [[code](https://github.com/shallowtoil/DROL)]
  
- **POST:** Ning Wang, Wengang Zhou, Guojun Qi, Houqiang Li. <br />
  "POST: POlicy-Based Switch Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6899)]
  
- **SPS:** Qintao Hu, Lijun Zhou, Xiaoxiao Wang, Yao Mao, Jianlin Zhang, Qixiang Ye. <br />
  "SPSTracker: Sub-Peak Suppression of Response Map for Robust Object Tracking." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1912.00597.pdf)]
  [[code](https://www.ctolib.com/https://github.com/TrackerLB/SPSTracker)]
  
- **RPOT:** Yifan Yang, Guorong Li, Yuankai Qi, Qingming Huang. <br />
  "Release the Power of Online-Training for Robust Visual Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6956)]
  
- **MetaRTT:** Ilchae Jung, Kihyun You, Hyeonwoo Noh, Minsu Cho, Bohyung Han. <br />
  "Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6779)]
  
- **GlobalTrack:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1912.08531)]
  [[code](https://github.com/huanglianghua/GlobalTrack)]

### Others 2020

* **VTT:** Tianling Bian, Yang Hua, Tao Song, Zhengui Xue, Ruhui Ma, Neil Robertson, Haibing Guan.<br />
  "VTT: Long-term Visual Tracking with Transformers." ICPR 2020. 
  [[paper](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **COMET:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Hossein Ghanei-Yakhdan, Shohreh Kasaei, and Li Cheng.<br />
  "COMET: Context-aware iOu-guided network for sMall objEct Tracking." ACCV 2020. 
  [[paper](https://arxiv.org/pdf/2006.02597.pdf)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **SiamKPN:** Qiang Li, Zekui Qin, Wenbo Zhang, Wen Zheng.<br />
  "Siamese Keypoint Prediction Network for Visual Object Tracking." ArXiv 2020. 
  [[paper](https://arxiv.org/abs/2006.04078)]
  [[code](https://github.com/ZekuiQin/SiamKPN)]

* **SiamCAN:** Wenzhang Zhou, Longyin Wen, Libo Zhang, Dawei Du, Tiejian Luo, Yanjun Wu. <br />
  "SiamMan: Siamese Motion-aware Network for Visual Tracking." TIP 2020. 
  [[paper](https://arxiv.org/abs/1912.05515v2)]
  [[paper_new](https://arxiv.org/abs/1912.05515v2)]
  [[code](https://isrc.iscas.ac.cn/gitlab/research/siamcan)]
  
### ICCV 2019

* **DiMP:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Learning Discriminative Model Prediction for Tracking." ICCV (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Bhat_Learning_Discriminative_Model_Prediction_for_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **GradNet:** Peixia Li, Boyu Chen, Wanli Ouyang, Dong Wang, Xiaoyun Yang, Huchuan Lu. <br />
  "GradNet: Gradient-Guided Network for Visual Object Tracking." ICCV (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_GradNet_Gradient-Guided_Network_for_Visual_Object_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/LPXTT/GradNet-Tensorflow)]

* **MLT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. <br />
  "Deep Meta Learning for Real-Time Target-Aware Visual Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Choi_Deep_Meta_Learning_for_Real-Time_Target-Aware_Visual_Tracking_ICCV_2019_paper.pdf)]

* **SPLT:** Bin Yan, Haojie Zhao, Dong Wang, Huchuan Lu, Xiaoyun Yang <br />
  "'Skimming-Perusal' Tracking: A Framework for Real-Time and Robust Long-Term Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yan_Skimming-Perusal_Tracking_A_Framework_for_Real-Time_and_Robust_Long-Term_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/iiau-tracker/SPLT)]

* **ARCF:** Ziyuan Huang, Changhong Fu, Yiming Li, Fuling Lin, Peng Lu. <br />
  "Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Learning_Aberrance_Repressed_Correlation_Filters_for_Real-Time_UAV_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/vision4robotics/ARCF-tracker)]

* **BGDT:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "Bridging the Gap Between Detection and Tracking: A Unified Approach." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Bridging_the_Gap_Between_Detection_and_Tracking_A_Unified_Approach_ICCV_2019_paper.pdf)]

* **PAT:** Rey Reza Wiyatno, Anqi Xu. <br />
  "Physical Adversarial Textures That Fool Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wiyatno_Physical_Adversarial_Textures_That_Fool_Visual_Object_Tracking_ICCV_2019_paper.pdf)]

* **GFS-DCF:** Tianyang Xu, Zhen-Hua Feng, Xiao-Jun Wu, Josef Kittler. <br />
  "Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Joint_Group_Feature_Selection_and_Discriminative_Filter_Learning_for_Robust_ICCV_2019_paper.pdf)]
  [[code](https://github.com/XU-TIANYANG/GFS-DCF)]

* **CDTB:** Alan Lukežič, Ugur Kart, Jani Käpylä, Ahmed Durmush, Joni-Kristian Kämäräinen, Jiří Matas, Matej Kristan. <br />
  "CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Lukezic_CDTB_A_Color_and_Depth_Visual_Object_Tracking_Dataset_and_ICCV_2019_paper.pdf)]
  
* **fdKCF:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Fast-deepKCF Without Boundary Effect." ICCV (2019).
  [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zheng_Fast-deepKCF_Without_Boundary_Effect_ICCV_2019_paper.pdf)]

* **VOT2019:** Kristan, Matej, et al.<br />
  "The Seventh Visual Object Tracking VOT2019 Challenge Results." ICCV workshops (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCVW_2019/papers/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.pdf)]

### CVPR2019

* **SiamMask:** Qiang Wang, Li Zhang, Luca Bertinetto, Weiming Hu, Philip H.S. Torr.<br />
  "Fast Online Object Tracking and Segmentation: A Unifying Approach." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1812.05050.pdf)]
  [[project](http://www.robots.ox.ac.uk/~qwang/SiamMask/)]
  [[code](https://github.com/foolwood/SiamMask)]

* **SiamRPN++:** Bo Li, Wei Wu, Qiang Wang, Fangyi Zhang, Junliang Xing, Junjie Yan.<br />
  "SiamRPN++: Evolution of Siamese Visual Tracking with Very Deep Networks." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_SiamRPN_Evolution_of_Siamese_Visual_Tracking_With_Very_Deep_Networks_CVPR_2019_paper.pdf)]
  [[project](http://bo-li.info/SiamRPN++/)]

* **ATOM:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. <br />
  "ATOM: Accurate Tracking by Overlap Maximization." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Danelljan_ATOM_Accurate_Tracking_by_Overlap_Maximization_CVPR_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **SiamDW:** Zhipeng Zhang, Houwen Peng.<br />
  "Deeper and Wider Siamese Networks for Real-Time Visual Tracking." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **GCT:** Junyu Gao, Tianzhu Zhang, Changsheng Xu.<br />
  "Graph Convolutional Tracking." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Graph_Convolutional_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **ASRCF:** Kenan Dai, Dong Wang, Huchuan Lu, Chong Sun, Jianhua Li. <br />
  "Visual Tracking via Adaptive Spatially-Regularized Correlation Filters." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_Visual_Tracking_via_Adaptive_Spatially-Regularized_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/Daikenan/ASRCF)]

* **UDT:** Ning Wang, Yibing Song, Chao Ma, Wengang Zhou, Wei Liu, Houqiang Li.<br />
  "Unsupervised Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01828.pdf)]
  [[code](https://github.com/594422814/UDT)]

* **TADT:** Xin Li, Chao Ma, Baoyuan Wu, Zhenyu He, Ming-Hsuan Yang.<br />
  "Target-Aware Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01772.pdf)]
  [[project](https://xinli-zn.github.io/TADT-project-page/)]
  [[code](https://github.com/XinLi-zn/TADT)]

* **C-RPN:** Heng Fan, Haibin Ling.<br />
  "Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_Siamese_Cascaded_Region_Proposal_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]

* **SPM:** Guangting Wang, Chong Luo, Zhiwei Xiong, Wenjun Zeng.<br />
  "SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_SPM-Tracker_Series-Parallel_Matching_for_Real-Time_Visual_Object_Tracking_CVPR_2019_paper.pdf)]

* **OTR:** Ugur Kart, Alan Lukezic, Matej Kristan, Joni-Kristian Kamarainen, Jiri Matas. <br />
  "Object Tracking by Reconstruction with View-Specific Discriminative Correlation Filters." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/ugurkart/OTR)]

* **RPCF:** Yuxuan Sun, Chong Sun, Dong Wang, Huchuan Lu, You He. <br />
  "ROI Pooled Correlation Filters for Visual Tracking." CVPR (2019).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_ROI_Pooled_Correlation_Filters_for_Visual_Tracking_CVPR_2019_paper.pdf)]

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.<br />
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

### AAAI2019

* **LDES:** Yang Li, Jianke Zhu, Steven C.H. Hoi, Wenjie Song, Zhefeng Wang, Hantang Liu.<br />
  "Robust Estimation of Similarity Transformation for Visual Object Tracking." AAAI (2019). 
  [[paper](https://arxiv.org/pdf/1712.05231.pdf)]
  [[code](https://github.com/ihpdep/LDES)] 
  
* **ANT:** Yuankai Qi, Shengping Zhang, Weigang Zhang, Li Su, Qingming Huang, Ming-Hsuan Yang.<br />
  "Learning Attribute-Specific Representations for Visual Tracking." AAAI (2019). 
  [[paper](https://faculty.ucmerced.edu/mhyang/papers/aaai2019_tracking.pdf)]
  
* **Re2EMA:** Jianglei Huang, Wengang Zhou.<br />
  "Re2EMA: Regularized and Reinitialized Exponential Moving Average for Target Model Update in Object Tracking." AAAI (2019). 
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/4862)]

### NIPS2018

* **DAT:** Shi Pu, Yibing Song, Chao Ma, Honggang Zhang, Ming-Hsuan Yang.<br />
  "Deep Attentive Tracking via Reciprocative Learning." NIPS (2018). 
  [[paper](https://arxiv.org/pdf/1810.03851.pdf)] 
  [[project](https://ybsong00.github.io/nips18_tracking/index)] 
  [[code](https://github.com/shipubupt/NIPS2018)] 

### ECCV2018

* **UPDT:** Goutam Bhat, Joakim Johnander, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg.<br />
  "Unveiling the Power of Deep Tracking." ECCV (2018). 
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Goutam_Bhat_Unveiling_the_Power_ECCV_2018_paper.pdf)]  

* **DaSiamRPN:** Zheng Zhu, Qiang Wang, Bo Li, Wu Wei, Junjie Yan, Weiming Hu.<br />
  "Distractor-aware Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdf)]
  [[github](https://github.com/foolwood/DaSiamRPN)]
  
* **SiamMCF:** Henrique Morimitsu.<br />
  "Multiple Context Features in Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](https://link.springer.com/content/pdf/10.1007%2F978-3-030-11009-3_6.pdf)]
  [[github](https://github.com/hmorimitsu/siam-mcf)]

* **SACF:** Mengdan Zhang, Qiang Wang, Junliang Xing, Jin Gao, Peixi Peng, Weiming Hu, Steve Maybank.<br />
  "Visual Tracking via Spatially Aligned Correlation Filters Network." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/mengdan_zhang_Visual_Tracking_via_ECCV_2018_paper.pdf)]

* **RTINet:** Yingjie Yao, Xiaohe Wu, Lei Zhang, Shiguang Shan, Wangmeng Zuo.<br />
  "Joint Representation and Truncated Inference Learning for Correlation Filter based Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yingjie_Yao_Joint_Representation_and_ECCV_2018_paper.pdf)]

* **Meta-Tracker:** Eunbyung Park, Alexander C. Berg.<br />
  "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers."
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunbyung_Park_Meta-Tracker_Fast_and_ECCV_2018_paper.pdf)]
  [[github](https://github.com/silverbottlep/meta_trackers)]

* **DSLT:** Xiankai Lu, Chao Ma*, Bingbing Ni, Xiaokang Yang, Ian Reid, Ming-Hsuan Yang.<br />
  "Deep Regression Tracking with Shrinkage Loss." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiankai_Lu_Deep_Regression_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/chaoma99/DSLT)]

* **DRL-IS:** Liangliang Ren, Xin Yuan, Jiwen Lu, Ming Yang, Jie Zhou.<br />
  "Deep Reinforcement Learning with Iterative Shift for Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Liangliang_Ren_Deep_Reinforcement_Learning_ECCV_2018_paper.pdf)]

* **RT-MDNet:** Ilchae Jung, Jeany Son, Mooyeol Baek, Bohyung Han.<br />
  "Real-Time MDNet." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Ilchae_Jung_Real-Time_MDNet_ECCV_2018_paper.pdf)]

* **ACT:** Boyu Chen, Dong Wang, Peixia Li, Huchuan Lu.<br />
  "Real-time 'Actor-Critic' Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Boyu_Chen_Real-time_Actor-Critic_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/bychen515/ACT)]

* **StructSiam:** Yunhua Zhang, Lijun Wang, Dong Wang, Mengyang Feng, Huchuan Lu, Jinqing Qi.<br />
  "Structured Siamese Network for Real-Time Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yunhua_Zhang_Structured_Siamese_Network_ECCV_2018_paper.pdf)]

* **MemTrack:** Tianyu Yang, Antoni B. Chan.<br />
  "Learning Dynamic Memory Networks for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianyu_Yang_Learning_Dynamic_Memory_ECCV_2018_paper.pdf)]

* **SiamFC-tri:** Xingping Dong, Jianbing Shen.<br />
  "Triplet Loss in Siamese Network for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf)]
  [[github](https://github.com/shenjianbing/TripletTracking)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Efstratios_Gavves_Long-term_Tracking_in_ECCV_2018_paper.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Matthias_Muller_TrackingNet_A_Large-Scale_ECCV_2018_paper.pdf)] 
  [[project](http://tracking-net.org/)]


### CVPR2018

* **VITAL:** Yibing Song, Chao Ma, Xiaohe Wu, Lijun Gong, Linchao Bao, Wangmeng Zuo, Chunhua Shen, Rynson Lau, and Ming-Hsuan Yang.
  "VITAL: VIsual Tracking via Adversarial Learning." CVPR (2018 **Spotlight**). 
  [[project](https://ybsong00.github.io/cvpr18_tracking/index)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.pdf)]
  [[github](https://github.com/ybsong00/Vital_release)]

* **LSART:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Learning Spatial-Aware Regressions for Visual Tracking." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.pdf)]

* **SiamRPN:** Bo Li, Wei Wu, Zheng Zhu, Junjie Yan.
  "High Performance Visual Tracking with Siamese Region Proposal Network." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf)]

* **TRACA:** Jongwon Choi, Hyung Jin Chang, Tobias Fischer, Sangdoo Yun, Kyuewang Lee, Jiyeoup Jeong, Yiannis Demiris, Jin Young Choi.
  "Context-aware Deep Feature Compression for High-speed Visual Tracking." CVPR (2018). 
  [[project](https://sites.google.com/site/jwchoivision/)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.pdf)]

* **RASNet:** Qiang Wang, Zhu Teng, Junliang Xing, Jin Gao, Weiming Hu, Stephen Maybank.
  "Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking." CVPR 2018. 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf)]

* **SA-Siam:** Anfeng He, Chong Luo, Xinmei Tian, Wenjun Zeng.
  "A Twofold Siamese Network for Real-Time Object Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf)]

* **STRCF:** Feng Li, Cheng Tian, Wangmeng Zuo, Lei Zhang, Ming-Hsuan Yang.
  "Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.pdf)]
  [[github](https://github.com/lifeng9472/STRCF)]

* **FlowTrack:** Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan.
  "End-to-end Flow Correlation Tracking with Spatial-temporal Attention." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.pdf)]

* **DEDT:** Kourosh Meshgi, Shigeyuki Oba, Shin Ishii.
  "Efficient Diverse Ensemble for Discriminative Co-Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.pdf)]

* **SINT++:** Xiao Wang, Chenglong Li, Bin Luo, Jin Tang.
  "SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf)]

* **DRT:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Correlation Tracking via Joint Discrimination and Reliability Learning." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Correlation_Tracking_via_CVPR_2018_paper.pdf)]

* **MCCT:** Ning Wang, Wengang Zhou, Qi Tian, Richang Hong, Meng Wang, Houqiang Li.
  "Multi-Cue Correlation Filters for Robust Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.pdf)]
  [[github](https://github.com/594422814/MCCT)]

* **MKCF:** Ming Tang, Bin Yu, Fan Zhang, Jinqiao Wang.
  "High-speed Tracking with Multi-kernel Correlation Filters." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Tang_High-Speed_Tracking_With_CVPR_2018_paper.pdf)]

* **HP:** Xingping Dong, Jianbing Shen, Wenguan Wang, Yu, Liu, Ling Shao, and Fatih Porikli.
  "Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.pdf)]

### NIPS2017

* **HART:** Adam R. Kosiorek, Alex Bewley, Ingmar Posner. 
  "Hierarchical Attentive Recurrent Tracking." NIPS (2017). 
  [[paper](https://papers.nips.cc/paper/6898-hierarchical-attentive-recurrent-tracking.pdf)]
  [[github](https://github.com/akosiorek/hart)]


### ICCV2017

* **CREST:** Yibing Song, Chao Ma, Lijun Gong, Jiawei Zhang, Rynson Lau, Ming-Hsuan Yang. 
  "CREST: Convolutional Residual Learning for Visual Tracking." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Song_CREST_Convolutional_Residual_ICCV_2017_paper.pdf)]
  [[project](http://www.cs.cityu.edu.hk/~yibisong/iccv17/index.html)]
  [[github](https://github.com/ybsong00/CREST-Release)]

* **EAST:** Chen Huang, Simon Lucey, Deva Ramanan.
  "Learning Policies for Adaptive Tracking with Deep Feature Cascades." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Learning_Policies_for_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Huang_Learning_Policies_for_ICCV_2017_supplemental.zip)]

* **PTAV:** Heng Fan and Haibin Ling. 
  "Parallel Tracking and Verifying: A Framework for Real-Time and High Accuracy Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Fan_Parallel_Tracking_and_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fan_Parallel_Tracking_and_ICCV_2017_supplemental.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/PTAV/ptav.htm)]
  [[code](http://www.dabi.temple.edu/~hbling/code/PTAV/serial_ptav_v1.zip)]

* **BACF:** Hamed Kiani Galoogahi, Ashton Fagg, Simon Lucey. 
  "Learning Background-Aware Correlation Filters for Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_supplemental.pdf)]
  [[code](http://www.hamedkiani.com/uploads/5/1/8/8/51882963/bacf_toupload.zip)]
  [[project](http://www.hamedkiani.com/bacf.html)]

* **TSN:** Zhu Teng, Junliang Xing, Qiang Wang, Congyan Lang, Songhe Feng and Yi Jin.
  "Robust Object Tracking based on Temporal and Spatial Deep Networks." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Teng_Robust_Object_Tracking_ICCV_2017_paper.pdf)]

* **p-tracker:** James Supančič, III; Deva Ramanan.
  "Tracking as Online Decision-Making: Learning a Policy From Streaming Videos With Reinforcement Learning." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Supancic_Tracking_as_Online_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Supancic_Tracking_as_Online_ICCV_2017_supplemental.pdf)]

* **DSiam:** Qing Guo; Wei Feng; Ce Zhou; Rui Huang; Liang Wan; Song Wang.
  "Learning Dynamic Siamese Network for Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf)]
  [[github](https://github.com/tsingqguo/DSiam)]

* **SP-KCF:** Xin Sun; Ngai-Man Cheung; Hongxun Yao; Yiluan Guo.
  "Non-Rigid Object Tracking via Deformable Patches Using Shape-Preserved KCF and Level Sets." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Sun_Non-Rigid_Object_Tracking_ICCV_2017_paper.pdf)]

* **UCT:** Zheng Zhu, Guan Huang, Wei Zou, Dalong Du, Chang Huang.
  "UCT: Learning Unified Convolutional Networks for Real-Time Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Zhu_UCT_Learning_Unified_ICCV_2017_paper.pdf)]

* Tobias Bottger, Patrick Follmann.
  "The Benefits of Evaluating Tracker Performance Using Pixel-Wise Segmentations." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Bottger_The_Benefits_of_ICCV_2017_paper.pdf)]

* **CFWCR:** Zhiqun He, Yingruo Fan, Junfei Zhuang, Yuan Dong, HongLiang Bai.
  "Correlation Filters With Weighted Convolution Responses." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/He_Correlation_Filters_With_ICCV_2017_paper.pdf)]
  [[github](https://github.com/he010103/CFWCR)]

* **IBCCF:** Feng Li, Yingjie Yao, Peihua Li, David Zhang, Wangmeng Zuo, Ming-Hsuan Yang.
  "Integrating Boundary and Center Correlation Filters for Visual Tracking With Aspect Ratio Variation." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Li_Integrating_Boundary_and_ICCV_2017_paper.pdf)]
  [[github](https://github.com/lifeng9472/IBCCF)]

* **RFL:** Tianyu Yang, Antoni B. Chan.
  "Recurrent Filter Learning for Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Yang_Recurrent_Filter_Learning_ICCV_2017_paper.pdf)]


### CVPR2017

* **ECO:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. 
  "ECO: Efficient Convolution Operators for Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Danelljan_ECO_Efficient_Convolution_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Danelljan_ECO_Efficient_Convolution_2017_CVPR_supplemental.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/ecotrack/index.html)]
  [[github](https://github.com/martin-danelljan/ECO)]

* **CFNet:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Andrea Vedaldi, Philip H. S. Torr.
  "End-to-end representation learning for Correlation Filter based tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Valmadre_End-To-End_Representation_Learning_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Valmadre_End-To-End_Representation_Learning_2017_CVPR_supplemental.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/cfnet.html)]
  [[github](https://github.com/bertinetto/cfnet)]

* **CACF:** Matthias Mueller, Neil Smith, Bernard Ghanem. 
  "Context-Aware Correlation Filter Tracking." CVPR (2017 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Mueller_Context-Aware_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Mueller_Context-Aware_Correlation_Filter_2017_CVPR_supplemental.zip)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-ca-cf-tracking.aspx)]
  [[code](https://github.com/thias15/Context-Aware-CF-Tracking)]

* **RaF:** Le Zhang, Jagannadan Varadarajan, Ponnuthurai Nagaratnam Suganthan, Narendra Ahuja and Pierre Moulin
  "Robust Visual Tracking Using Oblique Random Forests." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Robust_Visual_Tracking_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Zhang_Robust_Visual_Tracking_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/zhangleuestc/incremental-oblique-random-forest)]
  [[code](https://github.com/ZhangLeUestc/Incremental-Oblique-Random-Forest)]

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang. 
  "Multi-Task Correlation Particle Filter for Robust Object Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Multi-Task_Correlation_Particle_CVPR_2017_paper.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]

* **ACFN:** Jongwon Choi, Hyung Jin Chang, Sangdoo Yun, Tobias Fischer, Yiannis Demiris, and Jin Young Choi.
  "Attentional Correlation Filter Network for Adaptive Visual Tracking." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Choi_Attentional_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Choi_Attentional_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/acfn-1)]
  [[test code](https://drive.google.com/file/d/0B0ZkG8zaRQoLQUswbW9qSWFaU0U/view?usp=drive_web)]
  [[training code](https://drive.google.com/file/d/0B0ZkG8zaRQoLZVVranBnbHlydnM/view?usp=drive_web)]

* **LMCF:** Mengmeng Wang, Yong Liu, Zeyi Huang. 
  "Large Margin Object Tracking with Circulant Feature Maps." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Large_Margin_Object_CVPR_2017_paper.pdf)]
  [[zhihu](https://zhuanlan.zhihu.com/p/25761718)]

* **ADNet:** Sangdoo Yun, Jongwon Choi, Youngjoon Yoo, Kimin Yun, Jin Young Choi.
  "Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning." CVPR (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yun_Action-Decision_Networks_for_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Yun_Action-Decision_Networks_for_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/view/cvpr2017-adnet)]

* **CSR-DCF:** Alan Lukežič, Tomáš Vojíř, Luka Čehovin, Jiří Matas, Matej Kristan. 
  "Discriminative Correlation Filter with Channel and Spatial Reliability." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lukezic_Discriminative_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Lukezic_Discriminative_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[code](https://github.com/alanlukezic/csr-dcf)]

* **BranchOut:** Bohyung Han, Jack Sim, Hartwig Adam.
  "BranchOut: Regularization for Online Ensemble Tracking with Convolutional Neural Networks." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Han_BranchOut_Regularization_for_CVPR_2017_paper.pdf)]

* **AMCT:** Donghun Yeo, Jeany Son, Bohyung Han, Joonhee Han.
  "Superpixel-based Tracking-by-Segmentation using Markov Chains." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yeo_Superpixel-Based_Tracking-By-Segmentation_Using_CVPR_2017_paper.pdf)]

* **SANet:** Heng Fan, Haibin Ling. 
  "SANet: Structure-Aware Network for Visual Tracking." CVPRW (2017). 
  [[paper](https://arxiv.org/pdf/1611.06878.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/SANet/SANet.html)]
  [[code](http://www.dabi.temple.edu/~hbling/code/SANet/sanet_code.zip)]

### ECCV2016

* **SiameseFC:** Luca Bertinetto, Jack Valmadre, João F. Henriques, Andrea Vedaldi, Philip H.S. Torr. 
  "Fully-Convolutional Siamese Networks for Object Tracking." ECCV workshop (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1606.09549v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/siamese-fc.html)]
  [[github](https://github.com/bertinetto/siamese-fc)]

* **GOTURN:** David Held, Sebastian Thrun, Silvio Savarese. 
  "Learning to Track at 100 FPS with Deep Regression Networks." ECCV (2016). 
  [[paper](http://davheld.github.io/GOTURN/GOTURN.pdf)]
  [[project](http://davheld.github.io/GOTURN/GOTURN.html)]
  [[github](https://github.com/davheld/GOTURN)]

* **C-COT:** Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. 
  "Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking." ECCV (2016). 
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/index.html)]
  [[github](https://github.com/martin-danelljan/Continuous-ConvOp)]

* **CF+AT:** Adel Bibi, Matthias Mueller, and Bernard Ghanem. 
  "Target Response Adaptation for Correlation Filter Tracking." ECCV (2016). 
  [[paper](http://www.adelbibi.com/papers/ECCV2016/Target_Adap.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-target-response-adaptation.aspx)]
  [[github](https://github.com/adelbibi/Target-Response-Adaptation-for-Correlation-Filter-Tracking)]

* Yao Sui, Ziming Zhang,  Guanghui Wang, Yafei Tang, Li Zhang. 
  "Real-Time Visual Tracking: Promoting the Robustness of Correlation Filter Learning." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08173.pdf)]

* Yao Sui, Guanghui Wang, Yafei Tang, Li Zhang. 
  "Tracking Completion." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08171v1.pdf)]

### CVPR2016

* **MDNet:** Nam, Hyeonseob, and Bohyung Han. 
  "Learning Multi-Domain Convolutional Neural Networks for Visual Tracking." CVPR (2016).
  [[paper](http://arxiv.org/pdf/1510.07945v2.pdf)]
  [[VOT_presentation](http://votchallenge.net/vot2015/download/presentation_Hyeonseob.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/mdnet/)]
  [[github](https://github.com/HyeonseobNam/MDNet)]

* **SINT:** Ran Tao, Efstratios Gavves, Arnold W.M. Smeulders. 
  "Siamese Instance Search for Tracking." CVPR (2016).
  [[paper](https://staff.science.uva.nl/r.tao/pub/TaoCVPR2016.pdf)]
  [[project](https://staff.fnwi.uva.nl/r.tao/projects/SINT/SINT_proj.html)]

* **SCT:** Jongwon Choi, Hyung Jin Chang, Jiyeoup Jeong, Yiannis Demiris, and Jin Young Choi.
  "Visual Tracking Using Attention-Modulated Disintegration and Integration." CVPR (2016).
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Choi_Visual_Tracking_Using_CVPR_2016_paper.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/sct)]

* **STCT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu.
  "STCT: Sequentially Training Convolutional Networks for Visual Tracking." CVPR (2016).
  [[paper](http://www.ee.cuhk.edu.hk/~wlouyang/Papers/WangLJ_CVPR16.pdf)]
  [[github](https://github.com/scott89/STCT)]

* **SRDCFdecon:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking." CVPR (2016).
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/AdaptiveDecon_CVPR16.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/index.html)]

* **HDT:** Yuankai Qi, Shengping Zhang, Lei Qin, Hongxun Yao, Qingming Huang, Jongwoo Lim, Ming-Hsuan Yang. 
  "Hedged Deep Tracking." CVPR (2016). 
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr16_hedge_tracking.pdf)]
  [[project](https://sites.google.com/site/yuankiqi/hdt/)]

* **Staple:** Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip H.S. Torr. 
  "Staple: Complementary Learners for Real-Time Tracking." CVPR (2016). 
  [[paper](http://120.52.73.75/arxiv.org/pdf/1512.01355v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/staple.html)]
  [[github](https://github.com/bertinetto/staple)]

* **EBT:** Gao Zhu, Fatih Porikli, and Hongdong Li.
  "Beyond Local Search: Tracking Objects Everywhere with Instance-Specific Proposals." CVPR (2016). 
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Beyond_Local_Search_CVPR_2016_paper.pdf)]
  [[exe](http://www.votchallenge.net/vot2016/download/02_EBT.zip)]

* **DLSSVM:** Jifeng Ning, Jimei Yang, Shaojie Jiang, Lei Zhang and Ming-Hsuan Yang. 
  "Object Tracking via Dual Linear Structured SVM and Explicit Feature Map." CVPR (2016). 
  [[paper](http://www4.comp.polyu.edu.hk/~cslzhang/paper/cvpr16/DLSSVM.pdf)]
  [[code](http://www4.comp.polyu.edu.hk/~cslzhang/code/DLSSVM_CVPR.zip)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/DLSSVM/DLSSVM.htm)]

### NIPS2016
* **Learnet:** Luca Bertinetto, João F. Henriques, Jack Valmadre, Philip H. S. Torr, Andrea Vedaldi. 
  "Learning feed-forward one-shot learners." NIPS (2016). 
  [[paper](https://arxiv.org/pdf/1606.05233v1.pdf)]

### ICCV2015

* **FCNT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu. 
  "Visual Tracking with Fully Convolutional Networks." ICCV (2015). 
  [[paper](http://202.118.75.4/lu/Paper/ICCV2015/iccv15_lijun.pdf)]
  [[project](http://scott89.github.io/FCNT/)]
  [[github](https://github.com/scott89/FCNT)]

* **SRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Learning Spatially Regularized Correlation Filters for Visual Tracking." ICCV (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/SRDCF_ICCV15.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **CF2:** Chao Ma, Jia-Bin Huang, Xiaokang Yang and Ming-Hsuan Yang.
  "Hierarchical Convolutional Features for Visual Tracking." ICCV (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/iccv15_tracking.pdf)]
  [[project](https://sites.google.com/site/jbhuang0604/publications/cf2)]
  [[github](https://github.com/jbhuang0604/CF2)]

* Naiyan Wang, Jianping Shi, Dit-Yan Yeung and Jiaya Jia.
  "Understanding and Diagnosing Visual Tracking Systems." ICCV (2015). 
  [[paper](http://winsty.net/papers/diagnose.pdf)]
  [[project](http://winsty.net/tracker_diagnose.html)]
  [[code](http://winsty.net/diagnose/diagnose_code.zip)]\

* **DeepSRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Convolutional Features for Correlation Filter Based Visual Tracking." ICCV workshop (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/ConvDCF_ICCV15_VOTworkshop.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **RAJSSC:** Mengdan Zhang, Junliang Xing, Jin Gao, Xinchu Shi, Qiang Wang, Weiming Hu. 
  "Joint Scale-Spatial Correlation Tracking with Adaptive Rotation Estimation." ICCV workshop (2015). 
  [[paper](http://www.cv-foundation.org//openaccess/content_iccv_2015_workshops/w14/papers/Zhang_Joint_Scale-Spatial_Correlation_ICCV_2015_paper.pdf)]
  [[poster](http://www.votchallenge.net/vot2015/download/poster_Mengdan_Zhang.pdf)]

### CVPR2015

* **MUSTer:** Zhibin Hong, Zhe Chen, Chaohui Wang, Xue Mei, Danil Prokhorov, Dacheng Tao. 
  "MUlti-Store Tracker (MUSTer): A Cognitive Psychology Inspired Approach to Object Tracking." CVPR (2015). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Hong_MUlti-Store_Tracker_MUSTer_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/multistoretrackermuster/)]

* **LCT:** Chao Ma, Xiaokang Yang, Chongyang Zhang, Ming-Hsuan Yang.
  "Long-term Correlation Tracking." CVPR (2015).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Ma_Long-Term_Correlation_Tracking_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/chaoma99/cvpr15_tracking)]
  [[github](https://github.com/chaoma99/lct-tracker)]

* **DAT:** Horst Possegger, Thomas Mauthner, and Horst Bischof. 
  "In Defense of Color-based Model-free Tracking." CVPR (2015). 
  [[paper](https://lrs.icg.tugraz.at/pubs/possegger_cvpr15.pdf)]
  [[project](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/dat)]
  [[code](https://lrs.icg.tugraz.at/downloads/dat-v1.0.zip)]

* **RPT:** Yang Li, Jianke Zhu and Steven C.H. Hoi. 
  "Reliable Patch Trackers: Robust Visual Tracking by Exploiting Reliable Patches." CVPR (2015). 
  [[paper](https://github.com/ihpdep/ihpdep.github.io/raw/master/papers/cvpr15_rpt.pdf)]
  [[github](https://github.com/ihpdep/rpt)]

### ICML2015

* **CNN-SVM:** Seunghoon Hong, Tackgeun You, Suha Kwak and Bohyung Han.
  "Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network ." ICML (2015)
  [[paper](http://120.52.73.80/arxiv.org/pdf/1502.06796.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/CNN_SVM/)]

### BMVC2014

* **DSST:** Martin Danelljan, Gustav Häger, Fahad Shahbaz Khan and Michael Felsberg. 
  "Accurate Scale Estimation for Robust Visual Tracking." BMVC (2014).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/ScaleTracking_BMVC14.pdf)]
  [[PAMI](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html)]

### ECCV2014

* **MEEM:** Jianming Zhang, Shugao Ma, and Stan Sclaroff.
  "MEEM: Robust Tracking via Multiple Experts using Entropy Minimization." ECCV (2014).
  [[paper](http://cs-people.bu.edu/jmzhang/MEEM/MEEM-eccv-preprint.pdf)]
  [[project](http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html)]

* **TGPR:** Jin Gao, Haibin Ling, Weiming Hu, Junliang Xing.
  "Transfer Learning Based Visual Tracking with Gaussian Process Regression." ECCV (2014).
  [[paper](http://www.dabi.temple.edu/~hbling/publication/tgpr-eccv14.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/TGPR.htm)]

* **STC:** Kaihua Zhang, Lei Zhang, Ming-Hsuan Yang, David Zhang.
  "Fast Tracking via Spatio-Temporal Context Learning." ECCV (2014).
  [[paper](http://arxiv.org/pdf/1311.1939v1.pdf)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/STC/STC.htm)]

* **SAMF:** Yang Li, Jianke Zhu.
  "A Scale Adaptive Kernel Correlation Filter Tracker with Feature Integration." ECCV workshop (2014).
  [[paper](http://link.springer.com/content/pdf/10.1007%2F978-3-319-16181-5_18.pdf)]
  [[github](https://github.com/ihpdep/samf)]

### NIPS2013

* **DLT:** Naiyan Wang and Dit-Yan Yeung. 
  "Learning A Deep Compact Image Representation for Visual Tracking." NIPS (2013). 
  [[paper](http://winsty.net/papers/dlt.pdf)]
  [[project](http://winsty.net/dlt.html)]
  [[code](http://winsty.net/dlt/DLTcode.zip)]
 
 ### PAMI & IJCV & TIP

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
    " Learning Multi-task Correlation Particle Filters for Visual Tracking." TPAMI (2017).
      [[paper]( )]
      [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/lmcpf.html)]
      [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_mcpf/Source_Code/Source_Code.zip)] 

* **RSST:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
  " Robust Structural Sparse Tracking." TPAMI (2017).
  [[paper]( )
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/rsst.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_RSST/RSSTDeep/RSSTDeep_Code.zip)] 

* **fDSST:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg.
  "Discriminative Scale Space Tracking." TPAMI (2017).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/index.html)]
  [[code](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/fDSST_code.zip)] 

* **KCF:** João F. Henriques, Rui Caseiro, Pedro Martins, Jorge Batista. 
  "High-Speed Tracking with Kernelized Correlation Filters." TPAMI (2015).
  [[paper](http://www.robots.ox.ac.uk/~joao/publications/henriques_tpami2015.pdf)]
  [[project](http://www.robots.ox.ac.uk/~joao/circulant/)]

* **CLRST:** Tianzhu Zhang, Si Liu, Narendra Ahuja, Ming-Hsuan Yang, Bernard Ghanem.  
  "Robust Visual Tracking Via Consistent Low-Rank Sparse Learning." IJCV (2015). 
  [[paper](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/tianzhu%20zhang_files/Journal%20Articles/IJCV15_zhang_Low-Rank%20Sparse%20Learning.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/Robust%20Visual%20Tracking%20Via%20Consistent%20Low-Rank%20Sparse.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/material/LRT_Code.zip)]

* **DNT:** Zhizhen Chi, Hongyang Li, Huchuan Lu, Ming-Hsuan Yang. 
  "Dual Deep Network for Visual Tracking." TIP (2017). 
  [[paper](https://arxiv.org/pdf/1612.06053v1.pdf)]

* **DRT:** Junyu Gao, Tianzhu Zhang, Xiaoshan Yang, Changsheng Xu. 
  "Deep Relative Tracking." TIP (2017). 
  [[paper](http://ieeexplore.ieee.org/abstract/document/7828108/)]

* **BIT:** Bolun Cai, Xiangmin Xu, Xiaofen Xing, Kui Jia, Jie Miao, Dacheng Tao.
  "BIT: Biologically Inspired Tracker." TIP (2016). 
  [[paper](http://caibolun.github.io/papers/BIT_TIP.pdf)]
  [[project](http://caibolun.github.io/BIT/index.html)]
  [[github](https://github.com/caibolun/BIT)]

* **CNT:** Kaihua Zhang, Qingshan Liu, Yi Wu, Minghsuan Yang. 
  "Robust Visual Tracking via Convolutional Networks Without Training." TIP (2016). 
  [[paper](http://kaihuazhang.net/CNT.pdf)]
  [[code](http://kaihuazhang.net/CNT_matlab.rar)]
  
  ## ArXiv

* **DCFNet:** Qiang Wang, Jin Gao, Junliang Xing, Mengdan Zhang, Weiming Hu. 
  "DCFNet: Discriminant Correlation Filters Network for Visual Tracking." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1704.04057.pdf)]
  [[code](https://github.com/foolwood/DCFNet#dcfnet-discriminant-correlation-filters-network-for-visual-tracking)]

* **RDT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. 
  "Visual Tracking by Reinforced Decision Making." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1702.06291.pdf)]

* **MSDAT:** Xinyu Wang, Hanxi Li, Yi Li, Fumin Shen, Fatih Porikli .
  "Robust and Real-time Deep Tracking Via Multi-Scale Domain Adaptation." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1701.00561.pdf)]

* **RLT:** Da Zhang, Hamid Maei, Xin Wang, Yuan-Fang Wang.
  "Deep Reinforcement Learning for Visual Object Tracking in Videos." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1701.08936v1.pdf)]

* **SCF:** Wangmeng Zuo, Xiaohe Wu, Liang Lin, Lei Zhang, Ming-Hsuan Yang. 
  "Learning Support Correlation Filters for Visual Tracking." arXiv (2016).
  [[paper](https://arxiv.org/pdf/1601.06032.pdf)]
  [[project](http://faculty.ucmerced.edu/mhyang/project/scf/)]

* **CRT:** Kai Chen, Wenbing Tao. 
  "Convolutional Regression for Visual Tracking." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1611.04215.pdf)]

* **BMR:** Kaihua Zhang, Qingshan Liu, and Ming-Hsuan Yang. 
  "Visual Tracking via Boolean Map Representations." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1610.09652v1.pdf)]

* **YCNN:** Kai Chen, Wenbing Tao. 
  "Once for All: a Two-flow Convolutional Neural Network for Visual Tracking." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1604.07507v1.pdf)]

* **ROLO:** Guanghan Ning, Zhi Zhang, Chen Huang, Zhihai He, Xiaobo Ren, Haohong Wang. 
  "Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking." arXiv (2016). 
  [[paper](http://arxiv.org/pdf/1607.05781v1.pdf)]
  [[project](http://guanghan.info/projects/ROLO/)]
  [[github](https://github.com/Guanghan/ROLO/)]

* **SO-DLT:** Naiyan Wang, Siyi Li, Abhinav Gupta, Dit-Yan Yeung. 
  "Transferring Rich Feature Hierarchies for Robust Visual Tracking." arXiv (2015). 
  [[paper](https://arxiv.org/pdf/1501.04587v2.pdf)]
  [[code](http://www.votchallenge.net/vot2016/download/08_SO-DLT.zip)]

* **DMSRDCF:** Susanna Gladh, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg. 
  "Deep Motion Features for Visual Tracking." ICPR **Best Paper** (2016). 
  [[paper](https://arxiv.org/pdf/1612.06615v1.pdf)]

## Benchmark

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1803.09502.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[project](https://silviogiancola.github.io/publication/2018-03-trackingnet/details/)]
  [[paper](https://arxiv.org/pdf/1803.10794.pdf)] 

* **UAVDT:** Dawei Du, Yuankai Qi, Hongyang Yu, Yifang Yang, Kaiwen Duan, GuoRong Li, Weigang Zhang,  Weihai; Qingming Huang, Qi Tian.<br />
  "The Unmanned Aerial Vehicle Benchmark: Object Detection and Tracking." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1804.00518.pdf)]

* **Dataset-AMP:** Luka Čehovin Zajc; Alan Lukežič; Aleš Leonardis; Matej Kristan.
  "Beyond Standard Benchmarks: Parameterizing Performance Evaluation in Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zajc_Beyond_Standard_Benchmarks_ICCV_2017_paper.pdf)]

* **Dataset-NFS:** Hamed Kiani Galoogahi, Ashton Fagg, Chen Huang, Deva Ramanan and Simon Lucey.
  "Need for Speed: A Benchmark for Higher Frame Rate Object Tracking." ICCV (2017)
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Need_for_Speed_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Need_for_Speed_ICCV_2017_supplemental.pdf)]
  [[project](http://ci2cv.net/nfs/index.html)]

* **Dataset-DTB70:** Siyi Li, Dit-Yan Yeung.
  "Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models." AAAI (2017)
  [[paper](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14338/14292)]
  [[project](https://github.com/flyers/drone-tracking)]
  [[dataset](https://www.dropbox.com/s/s1fj99s2six4lrs/DTB70.tar.gz?dl=0)]

* **Dataset-UAV123:** Matthias Mueller, Neil Smith and Bernard Ghanem.
  "A Benchmark and Simulator for UAV Tracking." ECCV (2016)
  [[paper](https://ivul.kaust.edu.sa/Documents/Publications/2016/A%20Benchmark%20and%20Simulator%20for%20UAV%20Tracking.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-benchmark-simulator-uav.aspx)]
  [[dataset](https://ivul.kaust.edu.sa/Pages/Dataset-UAV123.aspx)]

* **Dataset-TColor-128:** Pengpeng Liang, Erik Blasch, Haibin Ling.
  "Encoding color information for visual tracking: Algorithms and benchmark." TIP (2015)
  [[paper](http://www.dabi.temple.edu/~hbling/publication/TColor-128.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/data/TColor-128/TColor-128.html)]
  [[dataset](http://www.dabi.temple.edu/~hbling/data/TColor-128/Temple-color-128.zip)]

* **Dataset-NUS-PRO:** Annan Li, Min Lin, Yi Wu, Ming-Hsuan Yang, and Shuicheng Yan.
  "NUS-PRO: A New Visual Tracking Challenge." PAMI (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/pami15_nus_pro.pdf)]
  [[project](https://sites.google.com/site/li00annan/nus-pro)]
  [[Data_360](https://d9fca6.lc.yunpan.cn/lk/cqKIc6DU3t2eJ)(code:bf28)]
  [[Data_baidu]](https://pan.baidu.com/s/1pJHvbSn#list/path=%2F)]
  [[View_360](https://6aa275.lc.yunpan.cn/lk/cqK479PfzDrPX)(code:515a)]
  [[View_baidu]](https://pan.baidu.com/s/1hqKXcuK)]

* **Dataset-PTB:** Shuran Song and Jianxiong Xiao.
  "Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines." ICCV (2013)
  [[paper](http://vision.princeton.edu/projects/2013/tracking/paper.pdf)]
  [[project](http://tracking.cs.princeton.edu/)]
  [[5 validation](http://tracking.cs.princeton.edu/ValidationSet.zip)]
  [[95 evaluation](http://tracking.cs.princeton.edu/EvaluationSet.tgz)]

* **Dataset-ALOV300+:** Arnold W. M. Smeulders, Dung M. Chu, Rita Cucchiara, Simone Calderara, Afshin Dehghan, Mubarak Shah.
  "Visual Tracking: An Experimental Survey." PAMI (2014)
  [[paper](http://crcv.ucf.edu/papers/Tracking_Survey.pdf)]
  [[project](http://imagelab.ing.unimore.it/dsm/)]
  [Mirror Link:ALOV300++ Dataset](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/Frames.zip)
  [Mirror Link:ALOV300++ Groundtruth](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/GT.zip)

* **OTB2013:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Online Object Tracking: A Benchmark." CVPR (2013).
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr13_benchmark.pdf)]

* **OTB2015:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Object Tracking Benchmark." TPAMI (2015).
  [[paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7001050&tag=1)]
  [[project](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)]

* **Dataset-VOT:**
  **[[project](http://www.votchallenge.net/)]**



## Distinguished Researchers & Teams
Distinguished visual tracking researchers who have published +3 papers which have a major impact on the field of visual tracking and are still active in the field of visual tracking.(Names listed in no particular order.)

* [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/)
* [Haibin Ling](http://www.dabi.temple.edu/~hbling/)
* [Huchuan Lu](http://ice.dlut.edu.cn/lu/)
* [Hongdong Li](http://users.cecs.anu.edu.au/~hongdong/)
* [Lei Zhang](http://www4.comp.polyu.edu.hk/~cslzhang/)
* [Matej Kristan](http://www.vicos.si/People/Matejk)
* [João F. Henriques](http://www.robots.ox.ac.uk/~joao/)
* [Martin Danelljan](http://users.isy.liu.se/cvl/marda26/)
* [Kaihua Zhang](http://kaihuazhang.net/)
* [Hamed Kiani](http://www.hamedkiani.com/)
* [Luca Bertinetto](http://www.robots.ox.ac.uk/~luca/index.html)
* [Tianzhu Zhang](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/index.html)
* [Chao Ma](https://www.chaoma.info/)
* [Yibing Song](https://ybsong00.github.io/)
* [Dong Wang](http://www.escience.cn/people/wangdongdut/index.html)
* [**Torr Vision Group**](http://www.robots.ox.ac.uk/~tvg/people.php)
* [**Computer Vision Laboratory, POSTECH**](http://cvlab.postech.ac.kr/lab/index.php)
