# Visual Object Tracking

## Paper List

### :star2: Recommendations :star2:

- **VOTSurvey:** Sajid Javed, Martin Danelljan, Fahad Shahbaz Khan, Muhammad Haris Khan, Michael Felsberg, Jiri Matas.<br />
  "Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook." TAPMI (2023).
  [[paper](https://arxiv.org/abs/2112.02838)] 
  
- **DL4VT:** Seyed Mojtaba Marvasti-Zadeh, Li Cheng, Senior Member, Hossein Ghanei-Yakhdan, Shohreh Kasaei, Senior Member.<br />
  "Deep Learning for Visual Tracking: A Comprehensive Survey." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/1912.00535.pdf)] 
  [[code](https://github.com/MMarvasti/Deep-Learning-for-Visual-Tracking-Survey)]
   
- **SAMURAI:** Cheng-Yen Yang, Hsiang-Wei Huang, Wenhao Chai, Zhongyu Jiang, Jenq-Neng Hwang.<br />
  "SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memory." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.11922)] 
  [[code](https://github.com/yangchris11/samurai)]

- **DAMv2:** Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, Hengshuang Zhao.<br />
  "Depth Anything V2." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2406.09414)] 
  [[code](https://depth-anything-v2.github.io/)]

- **4M-21:** Roman Bachmann, Oğuzhan Fatih Kar, David Mizrahi, Ali Garjani, Mingfei Gao, David Griffiths, Jiaming Hu, Afshin Dehghan, Amir Zamir.<br />
  "4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2406.09406)] 
  [[code](https://4m.epfl.ch/)]
      
- **SAM:** Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick.<br />
  "Segment Anything." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.02643v1.pdf)] 
  [[homepage](https://segment-anything.com/)] 
  [[code](https://github.com/facebookresearch/segment-anything)]
  
- **TAM:** Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, Feng Zheng.<br />
  "Track Anything: Segment Anything Meets Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.11968)] 
  [[code](https://github.com/gaomingqi/Track-Anything)]
  
- **SAM-Track:** Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, Yi Yang.<br />
  "Segment-and-Track Anything." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.06558)] 
  [[code](https://github.com/z-x-yang/Segment-and-Track-Anything)]
  
- **SEEM:** Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Gao, Yong Jae Lee.<br />
  "Segment Everything Everywhere All at Once." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.06718v1.pdf)] 
  [[code](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)]

- **SAM-PT:** Frano Rajič, Lei Ke, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, Fisher Yu.<br />
  "Segment Anything Meets Point Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.01197)] 
  [[code](https:/github.com/syscv/sam-pt)]
  
- **ReviewLLM:** Jiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu, Chong Ma, Sigang Yu, Haixing Dai.<br />
  "Review of Large Vision Models and Visual Prompt Engineering." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.00855)]
  [[code](https://github.com/xxx)]
  
- **ChatVideo:** Junke Wang, Dongdong Chen, Chong Luo, Xiyang Dai, Lu Yuan, Zuxuan Wu, Yu-Gang Jiang.<br />
  "ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.14407)] 
  [[code](https://www.wangjunke.info/ChatVideo/)]
  
- **Video-ChatGPT:** Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan.<br />
  "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05424)] 
  [[code](https://github.com/mbzuai-oryx/Video-ChatGPT)]
  
- **SegGPT:** Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang.<br />
  "SegGPT: Segmenting Everything In Context." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.03284)] 
  [[code](https://github.com/baaivision/Painter)]



### ICCV 2025

- **UMDATrack:** Siyuan Yao, Rui Zhu, Ziqi Wang, Wenqi Ren, Yanyang Yan, Xiaochun Cao.<br />
  "UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.00648)] 
  [[code](https://github.com/Z-Z188/UMDATrack)]


  
### CVPR 2025

- **ARPTrack:** Shiyi Liang, Yifan Bai, Yihong Gong, Xing Wei.<br />
  "Autoregressive Sequential Pretraining for Visual Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Autoregressive_Sequential_Pretraining_for_Visual_Tracking_CVPR_2025_paper.html)] 
  [[code](https://arptrack.github.io/)]

- **DreamTrack:** Mingzhe Guo, Weiping Tan, Wenyu Ran, Liping Jing, Zhipeng Zhang.<br />
  "DreamTrack: Dreaming the Future for Multimodal Visual Object Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Guo_DreamTrack_Dreaming_the_Future_for_Multimodal_Visual_Object_Tracking_CVPR_2025_paper.html)] 
  [[code]( )]

- **MamTrack:** Chuanyu Sun, Jiqing Zhang, Yang Wang, Huilin Ge, Qianchen Xia, Baocai Yin, Xin Yang.<br />
  "Exploring Historical Information for RGBE Visual Tracking with Mamba." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Exploring_Historical_Information_for_RGBE_Visual_Tracking_with_Mamba_CVPR_2025_paper.html)] 
  [[code](https://github.com/scy0712/MamTrack)]
  
- **PURA:** Zekai Shao, Yufan Hu, Bin Fan, Hongmin Liu.<br />
  "PURA: Parameter Update-Recovery Test-Time Adaption for RGB-T Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Shao_PURA_Parameter_Update-Recovery_Test-Time_Adaption_for_RGB-T_Tracking_CVPR_2025_paper.html)] 
  [[code](https://melantech.github.io/PURA)]

- **ACAttack:** Xinyu Xiang, Qinglong Yan, Hao Zhang, Jiayi Ma.<br />
  "ACAttack: Adaptive Cross Attacking RGB-T Tracker via Multi-Modal Response Decoupling." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Xiang_ACAttack_Adaptive_Cross_Attacking_RGB-T_Tracker_via_Multi-Modal_Response_Decoupling_CVPR_2025_paper.html)] 
  [[code](https://github.com/Xinyu-Xiang/ACAttack)]
  
- **MITracker:** Mengjie Xu, Yitao Zhu, Haotian Jiang, Jiaming Li, Zhenrong Shen, Sheng Wang, Haolin Huang, Xinyu Wang, Qing Yang, Han Zhang, Qian Wang.<br />
  "MITracker: Multi-View Integration for Visual Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2502.20111)] 
  [[code](https://mii-laboratory.github.io/MITracker/)]

- **SPMTrack:** Wenrui Cai, Qingjie Liu, Yunhong Wang.<br />
  "SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.18338)] 
  [[code](https://github.com/WenRuiCai/SPMTrack)]
  
- **ORTrack :** You Wu, Xucheng Wang, Xiangyang Yang, Mengyuan Liu, Dan Zeng, Hengzhou Ye, Shuiwang Li.<br />
  "Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2504.09228)] 
  [[code](https://github.com/wuyou3474/ORTrack)]

- **SGLATrack:** Chaocan Xue, Bineng Zhong, Qihua Liang, Yaozong Zheng, Ning Li, Yuanliang Xue, Shuxiang Song.<br />
  "Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.06625)] 
  [[code](https://github.com/GXNU-ZhongLab/SGLATrack)]

- **DUTrack:** Xiaohai Li, Bineng Zhong, Qihua Liang, Zhiyi Mo, Jian Nong, Shuxiang Song.<br />
  "Dynamic Updates for Language Adaptation in Visual-Language Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.06621)] 
  [[code](https://github.com/GXNU-ZhongLab/DUTrack)]

- **MambaVLT:** Xinqi Liu, Li Zhou, Zikun Zhou, Jianqiu Chen, Zhenyu He.<br />
  "MambaVLT: Time-Evolving Multimodal State Space Model for Vision-Language Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2411.15459)] 
  [[code]( )]

- **Mono3DVLT:** Hongkai Wei, Yang Yang, Shijie Sun, Mingtao Feng, Xiangyu Song, Qi Lei, Hongli Hu, Rong Wang, Huansheng Song, Naveed Akhtar, Ajmal Saeed Mian.<br />
  "Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Wei_Mono3DVLT_Monocular-Video-Based_3D_Visual_Language_Tracking_CVPR_2025_paper.html)] 
  [[code](https://github.com/hongkai-wei/Mono3DVLT)]
  
- **EdgeTAM:** Chong Zhou, Chenchen Zhu, Yunyang Xiong, Saksham Suri, Fanyi Xiao, Lemeng Wu, Raghuraman Krishnamoorthi, Bo Dai, Chen Change Loy, Vikas Chandra, Bilge Soran.<br />
  "EdgeTAM: On-Device Track Anything Model." CVPR (2025).
  [[paper](https://arxiv.org/abs/2501.07256)] 
  [[code](https://github.com/facebookresearch/EdgeTAM)]

- **DAM4SAM:** Jovana Videnovic, Alan Lukezic, Matej Kristan.<br />
  "A Distractor-Aware Memory for Visual Object Tracking with SAM2." CVPR (2025).
  [[paper](https://arxiv.org/abs/2411.17576)] 
  [[code](https://github.com/jovanavidenovic/DAM4SAM)]

- **MUST:** Haolin Qin, Tingfa Xu, Tianhao Li, Zhenxiang Chen, Tao Feng, Jianan Li.<br />
  "MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.17699)] 
  [[code](https://github.com/q2479036243/MUST-Multispectral-UAV-Single-Object-Tracking)]

- **ETAP:** Friedhelm Hamann, Daniel Gehrig, Filbert Febryanto, Kostas Daniilidis, Guillermo Gallego.<br />
  "ETAP: Event-based Tracking of Any Point." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Hamann_ETAP_Event-based_Tracking_of_Any_Point_CVPR_2025_paper.html)] 
  [[code](https://github.com/tub-rip/ETAP)]

- **Chrono:** Inès Hyeonsu Kim, Seokju Cho, Jiahui Huang, Jung Yi, Joon-Young Lee, Seungryong Kim.<br />
  "Exploring Temporally-Aware Features for Point Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Exploring_Temporally-Aware_Features_for_Point_Tracking_CVPR_2025_paper.html)] 
  [[code](https://cvlab-kaist.github.io/Chrono/)]

- **Tracktention:** Zihang Lai, Andrea Vedaldi.<br />
  "Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Tracktention_Leveraging_Point_Tracking_to_Attend_Videos_Faster_and_Better_CVPR_2025_paper.html)] 
  [[code](https://zlai0.github.io/TrackTention/)]

- **TimeTracker:** Haoyue Liu, Jinghan Xu, Yi Chang, Hanyu Zhou, Haozhi Zhao, Lin Wang, Luxin Yan.<br />
  "TimeTracker: Event-based Continuous Point Tracking for Video Frame Interpolation with Non-linear Motion." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_TimeTracker_Event-based_Continuous_Point_Tracking_for_Video_Frame_Interpolation_with_CVPR_2025_paper.html)] 
  [[code]( )]
  
- **ADMCMT:** Huijie Fan, Yu Qiao, Yihao Zhen, Tinghui Zhao, Baojie Fan, Qiang Wang.<br />
  "All-Day Multi-Camera Multi-Target Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Fan_All-Day_Multi-Camera_Multi-Target_Tracking_CVPR_2025_paper.html)] 
  [[code](https://github.com/QTRACKY/ADMCMT)]

- **OmniTrack:** Kai Luo, Hao Shi, Sheng Wu, Fei Teng, Mengfei Duan, Chang Huang, Yuhang Wang, Kaiwei Wang, Kailun Yang.<br />
  "Omnidirectional Multi-Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.04565)] 
  [[code](https://github.com/xifen523/OmniTrack)]

- **DFormerv2:** Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, Qibin Hou.<br />
  "DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation." CVPR (2025).
  [[paper](https://arxiv.org/abs/2504.04701)] 
  [[code](https://github.com/VCIP-RGBD/DFormer)]
  
- **JTD-UAV:** Yifan Wang, Jian Zhao, Zhaoxin Fan, Xin Zhang, Xuecheng Wu, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li.<br />
  "JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems ." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html)] 
  [[code]( )]

- **Anti-UAV:** Yifei Dong, Fengyi Wu, Sanjian Zhang, Guangyu Chen, Yuzhi Hu, Masumi Yano, Jingdong Sun, Siyu Huang, Feng Liu, Qi Dai, Zhi-Qi Cheng.<br />
  "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions." CVPRW (2025).
  [[paper](https://arxiv.org/abs/2504.11967)] 
  [[code]( )]

- **StrongSiamTracker:** Xiaolong Cui, Liu Wan, Lingqi Kong, Jimin Li, Chaojie Zhang, Ruohan Zhao, Panlong Wu, Shan He.<br />
  "StrongSiamTracker: A Siamese Tracker with Dynamic Global Detection for Robust Anti-UAV Tracking." CVPRW (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025W/Anti-UAV/html/Cui_StrongSiamTracker_A_Siamese_Tracker_with_Dynamic_Global_Detection_for_Robust_CVPRW_2025_paper.html)] 
  [[code]( )]

- **DLST:** Jiahao Zhang, Yixin Wei, Jinli Zhang, Zongli Jiang, Peiwen Yu, Yufei Ma, Runan Jin.<br />
  "DLST: Dual-Template Co-Evolution Learning for Robust Long-Term Drone Tracking in Dynamic Environments." CVPRW (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025W/Anti-UAV/html/Zhang_DLST_Dual-Template_Co-Evolution_Learning_for_Robust_Long-Term_Drone_Tracking_in_CVPRW_2025_paper.html)] 
  [[code]( )]
  
- **FDTrack:** Chenxu Peng, Chenxu Wang, Minrui Zou, Danyang Li, Zhengpeng Yang, Yimian Dai, Ming-Ming Cheng, Xiang Li.<br />
  "A Simple Detector with Frame Dynamics is a Strong Tracker." CVPRW (2025).
  [[paper](https://arxiv.org/abs/2505.04917)] 
  [[code](https://github.com/facias914/A-Simple-Detector-is-a-Strong-Tracker)]
  

### ICML 2025

- **MPT:** Jie Zhao, Xin Chen, Yongsheng Yuan, Michael Felsberg, Dong Wang, Huchuan Lu.<br />
  "Efficient Motion Prompt Learning for Robust Visual Tracking." ICML (2025).
  [[paper](https://arxiv.org/abs/2505.16321)] 
  [[code](https://github.com/zj5559/Motion-Prompt-Tracking)]

- **CSTrack:** Xiaokun Feng, Dailing Zhang, Shiyu Hu, Xuchen Li, Meiqi Wu, Jing Zhang, Xiaotang Chen, Kaiqi Huang.<br />
  "CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features." ICML (2025).
  [[paper](https://arxiv.org/abs/2505.19434)] 
  [[code](https://github.com/XiaokunFeng/CSTrack)]
  


### IJCAI 2025

- **GDSTrack:** Shenglan Li, Rui Yao, Yong Zhou, Hancheng Zhu, Kunyang Sun, Bing Liu, Zhiwen Shao, Jiaqi Zhao.<br />
  "Modality-Guided Dynamic Graph Fusion and Temporal Diffusion for Self-Supervised RGB-T Tracking." IJCAI (2025).
  [[paper](https://arxiv.org/abs/2505.03507)] 
  [[code](https://github.com/LiShenglana/GDSTrack)]


### AAAI 2025

- **STTrack:** Xiantao Hu, Ying Tai, Xu Zhao, Chen Zhao, Zhenyu Zhang, Jun Li, Bineng Zhong, Jian Yang.<br />
  "Exploiting Multimodal Spatial-temporal Patterns for Video Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.15691)] 
  [[code](https://github.com/NJU-PCALab/STTrack)]

- **SUTrack:** Xin Chen, Ben Kang, Wanting Geng, Jiawen Zhu, Yi Liu, Dong Wang, Huchuan Lu.<br />
  "SUTrack: Towards Simple and Unified Single Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.19138)] 
  [[code](https://github.com/chenxin-dlut/SUTrack)]

- **MIMTrack:** Xingmei Wang, Guohao Nie, Jiaxiang Meng, Zining Yan.<br />
  "MIMTrack: In-Context Tracking via Masked Image Modeling." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32860)] 
  [[code](https://github.com/chenxin-dlut/SUTrack)]
  
- **AINet:** Andong Lu, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "RGBT Tracking via All-layer Multimodal Interactions with Progressive Fusion Mamba." AAAI (2025).
  [[paper](https://arxiv.org/abs/2408.08827)] 
  [[code]( )]

- **CMS:** Xinyu Xiang, Qinglong Yan, Hao Zhang, Jianfeng Ding, Han Xu, Zhongyuan Wang, Jiayi Ma.<br />
  "Cross-Modal Stealth: A Coarse-to-Fine Attack Framework for RGB-T Tracker ." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32931)] 
  [[code](https://github.com/Xinyu-Xiang/CMS)]
  
- **CAFormer:** Yun Xiao, Jiacong Zhao, Andong Lu, Chenglong Li, Yin Lin, Bing Yin, Cong Liu.<br />
  "Cross-modulated Attention Transformer for RGBT Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2408.02222)] 
  [[code]( )]
  
- **TemTrack:** Jinxia Xie, Bineng Zhong, Qihua Liang, Ning Li, Zhiyi Mo, Shuxiang Song.<br />
  "Robust Tracking via Mamba-based Context-aware Token Learning." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.13611)] 
  [[code](https://github.com/GXNU-ZhongLab/TemTrack)]

- **LMTrack:** Chenlong Xu, Bineng Zhong, Qihua Liang, Yaozong Zheng, Guorong Li, Shuxiang Song.<br />
  "Less is More: Token Context-aware Learning for Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2501.00758)] 
  [[code](https://github.com/XuChenLong/LMTrack)]
  
- **MambaLCT:** Xiaohai Li, Bineng Zhong, Qihua Liang, Guorong Li, Zhiyi Mo, Shuxiang Song.<br />
  "MambaLCT: Boosting Tracking via Long-term Context State Space Model." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.13615)] 
  [[code](https://github.com/GXNU-ZhongLab/MambaLCT)]

- **SSTrack:** Yaozong Zheng , Bineng Zhong, Qihua Liang, Ning Li, Shuxiang Song.<br />
  "Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33155)] 
  [[code](https://github.com/GXNU-ZhongLab/SSTrack)]
  
- **MCITrack:** Ben Kang, Xin Chen, Simiao Lai, Yang Liu, Yi Liu, Dong Wang.<br />
  "Exploring Enhanced Contextual Information for Video-Level Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.11023)] 
  [[code](https://github.com/kangben258/MCITrack/)]
  
- **AsymTrack:** Jiawen Zhu, Huayi Tang, Xin Chen, Xinying Wang, Dong Wang, Huchuan Lu.<br />
  "Two-stream Beats One-stream: Asymmetric Siamese Network for Efficient Visual Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2503.00516)] 
  [[code](https://github.com/jiawen-zhu/AsymTrack)]

- **LVPTrack:** Hongjing Wu, Siyuan Yao, Feng Huang, Shu Wang, Linchao Zhang, Zhuoran Zheng, Wenqi Ren.<br />
  "LVPTrack: High Performance Domain Adaptive UAV Tracking with Label Aligned Visual Prompt Tuning." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32906)] 
  [[code]( )]

- **MM-Tracker:** Mufeng Yao, Jinlong Peng, Qingdong He, Bo Peng, Hao Chen, Mingmin Chi, Chao Liu.<br />
  "MM-Tracker: Motion Mamba for UAV-platform Multiple Object Tracking." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33019)] 
  [[code](https://github.com/YaoMufeng/MMTracker)]
  
- **PSOT:** Zhangbin Li, Jinxing Zhou, Jing Zhang, Shengeng Tang, Kun Li, Dan Guo.<br />
  "Patch-level Sounding Object Tracking for Audio-Visual Question Answering." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.10749)] 
  [[code](https://github.com/jiawen-zhu/AsymTrack)]
  

### ICASSP 2025

- **MFDA:** Zhiheng Li, Weng Zhimin, Yuehuan Wang.<br />
  "Multi-view Feature Discrepancy Attack for Single Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10889698)] 
  [[code]( )]

- **CGTrack:** Weihong Li, Xiaoqiong Liu, Heng Fan, Libo Zhang.<br />
  "CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking." ICRA (2025).
  [[paper](https://arxiv.org/abs/2505.05936)] 
  [[code](https://github.com/Nightwatch-Fox11/CGTrack)]

- **CLTrack:** Bin Chen, Shenglong Hu, Gang Dong, Lingyan Liang, Dongchao Wen, Kaihua Zhang.<br />
  "Continuously Learning Video-level Object Tokens for Robust UAV tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10887950)] 
  [[code]( )]
  
- **LunarTracking:** Mohammed Leo, Ding Zhang, Hai-Tao Zheng, Haiye Lin.<br />
  "Lunar Tracking: A New Benchmark For Nighttime Tiny Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10890681)] 
  [[code](https://github.com/kk123321x/LunarTracking)]

- **EHDA:** Qiao Li, Kanlun Tan, Qiao Liu, Di Yuan, Xin Li, Yunpeng Liu.<br />
  "Efficient Hierarchical Domain Adaptive Thermal Infrared Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10890354)] 
  [[code]( )]

- **PDTrack:** Yeqiang Liu, Weiran Li, Yanhao Ding, Zhenbo Li.<br />
  "PDTrack: Progressive Distance Association for Multiple Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10888323)] 
  [[code]( )]
  
- **RSM:** Riran Cheng, Xupeng Wang, Ferdous Sohel, Hang Lei.<br />
  "RSM: Refined Saliency Map For Explainable 3D Object Tracking." ICASSP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10887798)] 
  [[code]( )]

- **LRPD:** Qingkuo Hu, Yichen Li, Wenbin Yu.<br />
  "Exploiting Multimodal Prompt Learning and Distillation for RGB-T Tracking." ICMR (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3731715.3733332)] 
  [[code]( )]

- **VSS:** Pengfei Wei, Liu Qiao, Zhenyu He, Di Yuan.<br />
  "A Multi-Stream Visual-Spectral-Spatial Adaptive Hyperspectral Object Tracking." ICMR (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3731715.3733262)] 
  [[code]( )]
  
- **DARTer:** Xuzhao Li, Xuchen Li, Shiyu Hu.<br />
  "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking." ICMR (2025).
  [[paper](https://arxiv.org/abs/2505.00752)] 
  [[code]( )]
  


### ArXiv 2025

- **HIEVT:** Kui Wu, Hao Chen, Churan Wang, Fakhri Karray, Zhoujun Li, Yizhou Wang, Fangwei Zhong.<br />
  "Hierarchical Instruction-aware Embodied Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12606)] 
  [[code](https://sites.google.com/view/hievt)]

- **EVTRA:** Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong.<br />
  "VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.20718)] 
  [[code](https://sites.google.com/view/evt-recovery-assistant)]

- **TrackVLA:** Shaoan Wang, Jiazhao Zhang, Minghan Li, Jiahang Liu, Anqi Li, Kui Wu, Fangwei Zhong, Junzhi Yu, Zhizheng Zhang, He Wang.<br />
  "TrackVLA: Embodied Visual Tracking in the Wild." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.23189)] 
  [[code](https://pku-epic.github.io/TrackVLA-web)]

- **TPDOT:** Zhongping Dong, Liming Chen, Mohand Tahar Kechadi.<br />
  "Trajectory Prediction in Dynamic Object Tracking: A Critical Study." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.19341)] 
  [[code]( )]

- **R1-Track:** Biao Wang, Wenwen Li.<br />
  "R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.21980)] 
  [[code](https://github.com/Wangbiao2/R1-Track)]
  
- **MVTD:** Ahsan Baidar Bakht, Muhayy Ud Din, Sajid Javed, Irfan Hussain.<br />
  "MVTD: A Benchmark Dataset for Maritime Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.02866)] 
  [[code](https://github.com/AhsanBaidar/MVTD)]

- **Diff-MM:** Shiyu Xuan, Zechao Li, Jinhui Tang.<br />
  "Diff-MM: Exploring Pre-trained Text-to-Image Generation Model for Unified Multi-modal Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12606)] 
  [[code]( )]

- **VPTT:** Jiaming Liu, Yue Wu, Qiguang Miao, Maoguo Gong, Linghe Kong.<br />
  "Revisiting Siamese-based 3D Single Object Tracking with a Versatile Transformer." TPAMI (2025).
  [[paper](https://ieeexplore.ieee.org/document/11045222)] 
  [[code]( )]

- **DyHiT:** Ben Kang, Xin Chen, Jie Zhao, Chunjuan Bo, Dong Wang, Huchuan Lu.<br />
  "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking." IJCV (2025).
  [[paper](https://arxiv.org/abs/2506.20381)] 
  [[code](https://github.com/kangben258/HiT)]

- **VMDA:** Xiantao Hu, Bineng Zhong, Qihua Liang, Zhiyi Mo, Liangtao Shi, Ying Tai, Jian Yang.<br />
  "Visual and Memory Dual Adapter for Multi-Modal Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.23972)] 
  [[code](https://github.com/xuboyue1999/mmtrack)]

- **APTrack:** Xiantao Hu, Bineng Zhong, Qihua Liang, Zhiyi Mo, Liangtao Shi, Ying Tai, Jian Yang.<br />
  "Adaptive Perception for Unified Visual Multi-modal Object Tracking." TAI (2025).
  [[paper](https://arxiv.org/abs/2502.06583)] 
  [[code]( )]

- **QuadFusion:** Andong Lu, Mai Wen, Jinhu Wang, Yuanzhi Guo, Chenglong Li, Jin Tang, Bin Luo.<br />
  "Towards General Multimodal Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.11218)] 
  [[code]( )]

- **PFA:** Andong Lu, Yuanzhi Guo, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "Breaking Shallow Limits: Task-Driven Pixel Fusion for Gap-free RGBT Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.11247)] 
  [[code]( )]

- **DT-Training:** Jack Hong, Shilin Yan, Zehao Xiao, Jiayin Cai, Xiaolong Jiang, Yao Hu, Henghui Ding.<br />
  "Progressive Scaling Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.19990)] 
  [[code]( )]

- **SMMT:** Shang Zhang, Huanbin Zhang, Dali Feng, Yujie Cui, Ruoyan Xiong, Cen He.<br />
  "SMMT: Siamese Motion Mamba with Self-attention for Thermal Infrared Target Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.04088)] 
  [[code]( )]
  
- **TrackingMiM:** Bingxi Liu, Calvin Chen, Junhao Li, Guyang Yu, Haoqian Song, Xuchen Liu, Jinqiang Cui, Hong Zhang.<br />
  "TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.01535)] 
  [[code]( )]

- **FocusTrack:** Ying Wang, Tingfa Xu, Jianan Li.<br />
  "FocusTrack: A Self-Adaptive Local Sampling Algorithm for Efficient Anti-UAV Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.13604)] 
  [[code](https://github.com/vero1925/FocusTrack)]

- **CM3AE:** Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu.<br />
  "CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.12576)] 
  [[code](https://github.com/Event-AHU/CM3AE)]
  
- **SonarT165:** Yunfeng Li, Bo Wang, Jiahao Wan, Xueyi Wu, Ye Li.<br />
  "SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.15609)] 
  [[code](https://github.com/LiYunfengLYF/SonarT165)]

- **LightFC-X:** Yunfeng Li, Bo Wang, Ye Li.<br />
  "LightFC-X: Lightweight Convolutional Tracker for RGB-X Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.18143)] 
  [[code](https://github.com/LiYunfengLYF/LightFC-X)]

- **UASTrack:** He Wang, Tianyang Xu, Zhangyong Tang, Xiao-Jun Wu, Josef Kittler.<br />
  "UASTrack: A Unified Adaptive Selection Framework with Modality-Customization in Single Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.18220)] 
  [[code](https://github.com/wanghe/UASTrack)]

- **ProTracker:** Tingyang Zhang, Chen Wang, Zhiyang Dou, Qingzhe Gao, Jiahui Lei, Baoquan Chen, Lingjie Liu.<br />
  "ProTracker: Probabilistic Integration for Robust and Accurate Point Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2501.03220)] 
  [[code](https://michaelszj.github.io/protracker)]

- **HMAD:** Boyue Xu, Yi Xu, Ruichao Hou, Jia Bei, Tongwei Ren, Gangshan Wu.<br />
  "RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.17595)] 
  [[code]( )]

- **BTMTrack:** Zhongxuan Zhang, Bi Zeng, Xinyu Ni, Yimin Du.<br />
  "BTMTrack: Robust RGB-T Tracking via Dual-template Bridging and Temporal-Modal Candidate Elimination." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2501.03616)] 
  [[code]( )]

- **Mamba-FETrack V2:** Shiao Wang, Ju Huang, Qingchuan Ma, Jinfeng Gao, Chunyi Xu, Xiao Wang, Lan Chen, Bo Jiang.<br />
  "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.23783)] 
  [[code](https://github.com/Event-AHU/Mamba_FETrack)]

- **SpikeFET:** Jingjun Yang, Liangwei Fan, Jinpu Zhang, Xiangkai Lian, Hui Shen, Dewen Hu.<br />
  "Fully Spiking Neural Networks for Unified Frame-Event Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.20834)] 
  [[code]( )]

- **SDTrack:** Yimeng Shan, Zhenbang Ren, Haodi Wu, Wenjie Wei, Rui-Jie Zhu, Shuai Wang, Dehao Zhang, Yichen Xiao, Jieyuan Zhang, Kexin Shi, Jingzhinan Wang, Jason K. Eshraghian, Haicheng Qu, Jiqing Zhang, Malu Zhang, Yang Yang.<br />
  "SDTrack: A Baseline for Event-based Tracking via Spiking Neural Networks." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.08703)] 
  [[code]( )]

- **DiffDf:** Long Xu, Peng Gao, Wen-Jia Tang, Fei Wang, Ru-Yue Yuan.<br />
  "Towards Effective and Efficient Adversarial Defense with Diffusion Models for Robust Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.00325)] 
  [[code](https://github.com/pgao-lab/DiffDf)]

- **AMGA:** Wei-Long Tian, Peng Gao, Xiao Liu, Long Xu, Hamido Fujita, Hanan Aljuai, Mao-Li Wang.<br />
  "Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.08999)] 
  [[code](https://github.com/pgao-lab/AMGA)]

- **SFTrack:** Shiao Wang, Xiao Wang, Liye Jin, Bo Jiang, Lin Zhu, Lan Chen, Yonghong Tian, Bin Luo.<br />
  "Towards Low-Latency Event Stream-based Visual Object Tracking: A Slow-Fast Approach." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12903)] 
  [[code](https://github.com/Event-AHU/SlowFast_Event_Track)]

- **Attack4RGBE:** Qiang Chen, Xiao Wang, Haowen Wang, Bo Jiang, Lin Zhu, Dawei Zhang, Yonghong Tian, Jin Tang.<br />
  "Adversarial Attack for RGB-Event based Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.08703)] 
  [[code](https://github.com/Event-AHU/Adversarial_Attack_Defense)]

- **DMP:** Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang.<br />
  "Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.21692)] 
  [[code]( )]

- **DRCT:** Xiantong Zhao, Xiuping Liu, Shengjing Tian, Yinan Han.<br />
  "Robust Single Object Tracking in LiDAR Point Clouds under Adverse Weather Conditions." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2501.07133)] 
  [[code]( )]
  
- **CMDTrack:** Tianlu Zhang, Qiang Zhang, Kurt Debattista, Jungong Han.<br />
  "Cross-Modality Distillation for Multi-modal Tracking." TPAMI (2025).
  [[paper](https://ieeexplore.ieee.org/document/10943265)] 
  [[code](https://github.com/Tianlu-Zhang/TransCMD)]

- **DIFTracker:** Pha Nguyen, Rishi Madhok, Bhiksha Raj, Khoa Luu.<br />
  "Autoregressive Temporal Modeling for Advanced Tracking-by-Diffusion." IJCV (2025).
  [[paper](https://link.springer.com/article/10.1007/s11263-025-02439-x)] 
  [[code]( )]

- **DMD:** Yufan Hu, Zekai Shao, Bin Fan, Hongmin Liu.<br />
  "Dual-level Modality De-biasing for RGB-T Tracking." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/10975100)] 
  [[code]( )]

- **UncTrack:** Siyuan Yao, Yang Guo, Yanyang Yan, Wenqi Ren, Xiaochun Cao.<br />
  "UncTrack: Reliable Visual Object Tracking with Uncertainty-Aware Prototype Memory Network." TIP (2025).
  [[paper](https://arxiv.org/abs/2503.12888)] 
  [[code](https://github.com/ManOfStory/UncTrack)]

- **SNNTrack:** Jiqing Zhang, Malu Zhang, Yuanchen Wang, Qianhui Liu, Baocai Yin, Haizhou Li.<br />
  "Spiking Neural Networks with Adaptive Membrane Time Constant for Event-Based Tracking." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/10857949)] 
  [[code]( )]

- **HPL:** Mianzhao Wang, Fan Shi, Xu Cheng, Shengyong Chen.<br />
  "Prior Knowledge-Driven Hybrid Prompter Learning for RGB-Event Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10962221)] 
  [[code]( )]
  
- **AETrack:** Zhiruo Zhu, Bineng Zhong, Qihua Liang, Hongtao Yang, Yaozong Zheng, Ning Li.<br />
  "Adaptive Expert Decision for RGB-T Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10973112)] 
  [[code]( )]
  
- **LINR:** Yao Chen, Guancheng Jia, Yufei Zha, Peng Zhang, Yanning Zhang.<br />
  "LINR: A Plug-and-Play Local Implicit Neural Representation Module for Visual Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11030729)] 
  [[code](https://github.com/Xiaochen918/LINR)]

- **MPIT:** Wuwei Wang, Meibo Lv, Lin Zhu, Tuo Han, Yi Zhang, Yuanqing Li.<br />
  "Siamese Visual Tracking with Multi-Parallel Interactive Transformers." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11003183)] 
  [[code](https://github.com/wangwuwei/MPIT)]

- **PTrMA:** Binxin Luo, Dongxu Liu, Xianrong Peng, Haorui Zuo, Jianlin Zhang, Meihui Li.<br />
  "Progressive Transformer with Multi-modality Adaptation for RGB-T Tracking." TIM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11023155)] 
  [[code]( )]
  
- **DyTrack:** Jiawen Zhu, Xin Chen, Haiwen Diao, Shuai Li, Jun-Yan He, Chenyang Li, Bin Luo, Dong Wang, Huchuan Lu.<br />
  "Exploring Dynamic Transformer for Efficient Object Tracking." TNNLS (2025).
  [[paper](https://ieeexplore.ieee.org/document/10947615)] 
  [[code]( )]

- **MHITrack:** Lei Lei, Xianxian Li.<br />
  "Multi-modal Hybrid Interaction Vision-language Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10980446)] 
  [[code]( )]

- **HotMoE:** Wenfang Sun, Yuedong Tan, Jingyuan Li, Shuwei Hou, Xiaobo Li, Yingzhao Shao.<br />
  "HotMoE: Exploring Sparse Mixture-of-Experts for Hyperspectral Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10855488)] 
  [[code](https://github.com/supertyd/hotmoe)]

- **TLH:** Xiaoyan Yang, Licheng Jiao, Yangyang Li, Xu Liu, Lingling Li, Puhua Chen.<br />
  "Tracking Like Human: Dynamic Scene Learning Reasoning Tracker in Satellite Videos." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11000100)] 
  [[code]( )]

- **SiamTITP:** Jiawei Zhou, Yanni Dong, Bo Du.<br />
  "SiamTITP: Incorporating Temporal Information and Trajectory Prediction Siamese Network for Satellite Video Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/11051136)] 
  [[code](https://github.com/jiawei-zhou/SiamTITP)]
  
- **PUTrack:** Qiuyang Zhang, Wei Song, Cong Liu, Minghua Zhang.<br />
  "PUTrack: Improved Underwater Object Tracking via Progressive Prompting." TII (2025).
  [[paper](https://ieeexplore.ieee.org/document/10892342)] 
  [[code](https://github.com/faicaiwawa/PUTrack)]

- **MGTrack:** Shaoyang Ma, Yao Yang, Kai Zhang, Gang Chen.<br />
  "Transformer-Based Memory Guided Thermal Infrared Target Tracking Framework for Traffic Assistance." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11005508)] 
  [[code]( )]
  
- **NOT-156:** Chen Sun, Xinyu Wang, Shenghua Fan, Xiaobing Dai, Yuting Wan, Xiao Jiang.<br />
  "NOT-156: Night Object Tracking using Low-light and Thermal Infrared: From Multi-modal Common-aperture Camera to Benchmark Datasets." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/10938642)] 
  [[code](http://rsidea.whu.edu.cn/NOT156_dataset.htm)]

- **SP-HST:** Gang He, Long Gao, Langkun Chen, Yan Jiang, Weiying Xie, Yunsong Li.<br />
  "Hyperspectral Object Tracking with Spectral Information Prompt." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11029092)] 
  [[code](https://github.com/lgao001/SP-HST)]

- **CCTrack:** Ye Wang, Shaohui Mei, Mingyang Ma, Yuheng Liu, Tao Gao, Huiyang Han.<br />
  "Hyperspectral Object Tracking With Context-Aware Learning and Category Consistency." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/10928989)] 
  [[code]( )]

- **UBSTrack:** Mohammad Aminul Islam, Jun Zhou, Wangzhi Xing, Yongsheng Gao, Kuldip K. Paliwal.<br />
  "UBSTrack: Unified Band Selection and Multi-Model Ensemble for Hyperspectral Object Tracking." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11007116)] 
  [[code](https://github.com/aamin0102/UBSTrack)]

- **ProFiT:** Yuzeng Chen, Qiangqiang Yuan, Yuqi Tang, Xin Wang, Yi Xiao, Jiang He, Ziyang Lihe, Xianyu Jin.<br />
  "ProFiT: A Prompt-guided Frequency-aware Filtering and Template-enhanced Interaction Framework for Hyperspectral Video Tracking." ISPRS, (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0924271625001893)] 
  [[code](https://github.com/YZCU/ProFiT)]
  
- **SpectralTrack:** Yuzeng Chen, Qiangqiang Yuan, Hong Xie, Yuqi Tang, Yi Xiao, Jiang He.<br />
  "Hyperspectral Video Tracking with Spectral-Spatial Fusion and Memory Enhancement." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/document/11007172)] 
  [[code](https://github.com/YZCU/SpectralTrack)]

- **HOPL:** Lu Zhang, Rui Yao, Yuhong Zhang, Yong Zhou, Fuyuan Hu, Jiaqi Zhao, Zhiwen Shao.<br />
  "Historical Object-Aware Prompt Learning for Universal Hyperspectral Object Tracking." TOMM (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3736581)] 
  [[code](https://github.com/rayyao/HOPL)]
  
- **HyA-T:** Long Gao, Yunhe Zhang, Langkun Chen, Yan Jiang, Weiying Xie, Yunsong Li.<br />
  "Hyperspectral Adapter for Object Tracking based on Hyperspectral Video." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.22199)] 
  [[code](https://github.com/lgao001/HyA-T)]

- **COST:** Chunhui Zhang, Li Liu, Jialin Gao, Xin Sun, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang.<br />
  "COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.01321)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking/tree/main/VL-SOT500)]

- **ATSTrack:** Yihao Zhen, Qiang Wang, Yu Qiao, Liangqiong Qu, Huijie Fan.<br />
  "ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.00454)] 
  [[code]( )]
  
- **SIEVL-Track:** Ning Li, Bineng Zhong, Qihua Liang, Zhiyi Mo, Jian Nong, Shuxiang Song.<br />
  "SIEVL-Track: Exploring Semantic Information Enhancement for Visual-Language Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10845881)] 
  [[code]( )]

- **SATrack:** Yuyang Tang, Yinchao Ma, Tianzhu Zhang.<br />
  "Semantic-aware Network for Natural Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10973162)] 
  [[code]( )]
  
- **ProVLT:** Chengao Zong, Jie Zhao; Xin Chen; Huchuan Lu; Dong Wang.<br />
  "Learning Language Prompt for Vision-Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10947500)] 
  [[code]( )]

- **MAVLT:** Liangtao Shi, Bineng Zhong, Qihua Liang, Xiantao Hu, Zhiyi Mo, Shuxiang Song.<br />
  "Mamba Adapter: Efficient Multi-Modal Fusion for Vision-Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10948517)] 
  [[code](https://github.com/GXNU-ZhongLab/MAVLT)]

- **AVLTrack:** Yuanliang Xue, Bineng Zhong, Guodong Jin, Tao Shen, Lining Tan, Ning Li.<br />
  "AVLTrack: Dynamic Sparse Learning for Aerial Vision-Language Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10922151)] 
  [[code](https://github.com/xyl-507/AVLTrack)]

- **FFTR:** Donghai Liao, Xiu Shu, Zhihui Li, Qiao Liu, Di Yuan, Xiaojun Chang.<br />
  "Fine-grained Feature and Template Reconstruction for TIR Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10946152)] 
  [[code]( )]

- **ATCTrack:** Xudong Luo, Di Yuan, Xiu Shu, Qiao Liu, Xiaojun Chang, Zhenyu He.<br />
  "Adaptive Trajectory Correction for Underwater Object Tracking." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/10900462)] 
  [[code]( )]
  
- **HarNet:** Si Chen, Rui Xu, Yan Yan, Yang Hua, Da-Han Wang, Shunzhi Zhu.<br />
  "Hierarchical Attention-Enhanced Correlation Refinement for Robust Visual Tracking." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11023144)] 
  [[code]( )]

- **CorPN:** Qun Li, Haijun Zhang, Kai Yang, Wei Dai, Jianghong Ma, Yuping Liu.<br />
  "CorPN: Corner Prediction Network for Visual Tracking." TCE (2025).
  [[paper](https://ieeexplore.ieee.org/document/10891175)] 
  [[code]( )]

- **CasCenter:** Qun Li, Haijun Zhang, Kai Yang, Yong-Guo Shi, Deqiang Zeng, Wun-She Yap.<br />
  "CasCenter: A Cascaded Center Network for Visual Tracking." TCE (2025).
  [[paper](https://ieeexplore.ieee.org/document/10909718)] 
  [[code]( )]

- **AMLAA:** Sihang Ma, Yuanfang Chen, Xing Fang, Xiaohan Chen, Muhammad Alam.<br />
  "Metaverse Target-Tracking Security: A Study on Adaptive Metalearning Adversarial Attack Methods." MSMC (2025).
  [[paper](https://ieeexplore.ieee.org/document/10970385)] 
  [[code]( )]

- **AGA:** Rui Yao, Anqi Zhang, Yong Zhou, Jiaqi Zhao, Bing Liu, Abdulmotaleb El Saddik.<br />
  "Adversarial Geometric Attacks for 3D Point Cloud Object Tracking." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10948328)] 
  [[code](https://github.com/betselot/TATrack)]

- **MSTIC:** Xiaoyu Ni, Liang Yuan, Yongming Han.<br />
  "Multiscale Spatio-Temporal Information Cascade Single-Object Visual Tracker." TIM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10972015)] 
  [[code]( )]

- **TA-Track:** Betselot Yewulu Reta, Wei Xia.<br />
  "3D Single Object Tracking with Temporal-Aware and Attention Mechanism." TIM (2025).
  [[paper](https://ieeexplore.ieee.org/document/10912766)] 
  [[code](https://github.com/betselot/TATrack)]

- **CCETrack:** Yushi Yang, Wei Li, Ying Yao, Bo Zhou, Baojie Fan.<br />
  "3D Single Object Tracking With Cross-Modal Fusion Conflict Elimination." RAL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10930556)] 
  [[code]( )]
  
- **RSTrack:** Juntao Liang, Jiaqi Zhou, Wei Li, Yong Wang, Tianjiang Hu, Qi Wu.<br />
  "Reconstructed and Simulated Dataset for Aerial RGBD Tracking." RAL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10829654)] 
  [[code](https://github.com/TonikLeung/RSTrack)]

- **DSTrack:** Zhixing Wang, Kai Wang, Chuanming Tang, Xiang Li, Jianlin Zhang, Lianli Gao.<br />
  "DSTrack: Diffusion-based Sequence Learning for Visual Object Tracking." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325003541)] 
  [[code]( )]

- **VCGDD:** Shaochuan Zhao, Tianyang Xu, Hui Li, Xiao-Jun Wu, Josef Kittler.<br />
  "Visual Complexity Guided Diffusion Defender for Video Object Tracking and Recognition." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325005278)] 
  [[code](https://github.com/DjangoChaogh/VCGDD)]
  
- **GCR:** Kuiran Wang, Xuehui Yu, Wenwen Yu, Guorong Li, Xiangyuan Lan, Qixiang Ye, Jianbin Jiao, Zhenjun Han.<br />
  "ClickTrack: Towards Real-time Interactive Single Object Tracking." PR (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320324009622)] 
  [[code]( )]

- **ATOTrack:** Sixian Chan, Xianpeng Zeng, Zhoujian Wu, Yu Wang, Xiaolong Zhou, Tinglong Tang, Jie Hu.<br />
  "Adaptive Target Oriented Tracking." TIST (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3732785)] 
  [[code]( )]
  
- **DFDT:** Zhengjun Xu, Detian Huang, Hang Liu, Huihui Wang, Mingxin Lin, Miaohua Ruan.<br />
  "Dual-Frequency Domain Transformer for Thermal Infrared Object Tracking." INFPHY (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S135044952500266X)] 
  [[code](https://github.com/faith1689/DFDT)]

- **CLDTracker:** Mohamad Alansari, Sajid Javed, Iyyakutti Iyappan Ganapathi, Sara Alansari, Muzammal Naseer.<br />
  "CLDTracker: A Comprehensive Language Description for Visual Tracking." INFFUS (2025).
  [[paper](https://arxiv.org/abs/2505.23704)] 
  [[code](https://github.com/HamadYA/CLDTracker)]

- **MAT:** He Wang, Tianyang Xu, Zhangyong Tang, Xiao-Jun Wu, Josef Kittler.<br />
  "Multi-modal Adapter for RGB-T Tracking." INFFUS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1566253525000132)] 
  [[code](https://github.com/ouha1998/MAT)]
  
- **TMTR:** Guocai Du, Peiyong Zhou, Nurbiya Yadikar, Alimjan Aysa, Kurban Ubul.<br />
  "Toward a Dynamic Tree-Mamba Encoder for UAV Tracking with Vision-Language." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125007774)] 
  [[code]( )]

- **TUFNet:** Yisong Liu, Zhao Gao, Yang Cao, Dongming Zhou.<br />
  "Two-stage Unidirectional Fusion Network for RGBT tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125000310)] 
  [[code]( )]

- **RDT-TEF:** Long Gao, Yuze Ke, Wanlin Zhao, Yang Zhang, Yan Jiang, Gang He, Yunsong Li.<br />
  "RGB-D Visual Object Tracking with Transformer-based Multi-modal Feature Fusion." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125005775)] 
  [[code]( )]

- **TVTracker:** Fang Gao, Wenjie Wu, Yan Jin, Jingfeng Tang, Hanbo Zheng, Shengheng Ma.<br />
  "TVTracker: Target-Adaptive Text-Guided Visual Fusion for Multi-Modal RGB-T Tracking." IOTJ (2025).
  [[paper](https://ieeexplore.ieee.org/document/10948521)] 
  [[code]( )]

- **IAMTrack:** Huiwei Shi, Xiaodong Mu, Hao He, Chengliang Zhong, Bo Zhang, Peng Zhao.<br />
  "IAMTrack: Interframe Appearance and Mdality Tokens Propagation with Temporal Modeling for RGBT Tracking." APIN (2025).
  [[paper](https://link.springer.com/article/10.1007/s10489-025-06438-w)] 
  [[code]( )]
  
- **HFFTrack:** Sugang Ma, Zhen Wan, Licheng Zhang, Bin Hu, Jinyu Zhang, Xiangmo Zhao.<br />
  "HFFTrack: Transformer Tracking via Hybrid Frequency Features." NUENET (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0893608025001480)] 
  [[code](https://github.com/ElliottZhen/HFFTrack)]

- **DSC:** Yuanming Zhang, Hao Sun.<br />
  "Decoding Split-frequency Representation for Cross-scale Tracking." NUENET (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0893608025004678)] 
  [[code](https://github.com/pellab/DSC)]
  
- **AIFTrack:** Junze Shi, Jian Shi, Haibo Luo.<br />
  "Adaptive Information Flow Propagation for Visual Tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125008743)] 
  [[code]( )]

- **TBIM:** Huanlong Zhang, Weiqiang Fu, Rui Qi, Bineng Zhong, Xin Wang, Yanfeng Wang.<br />
  "Target-background Interaction Modeling Transformer for Object Tracking." KBS (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705125002771)] 
  [[code]( )]
  
- **ASTrack:** Zhi Chen, Lijun Liu, Yu Zhen.<br />
  "Transformer Tracking with Auxiliary Search Token." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425005329)] 
  [[code]( )]

- **Anti-MUAV15:** Shihan Liu, Tianyang Xu, Xue-Feng Zhu, Xiao-Jun Wu, Josef Kittler.<br />
  "Learning Adaptive Detection and Tracking Collaborations with Augmented UAV Synthesis for Accurate Anti-UAV System." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425013016)] 
  [[code](https://github.com/Shihan0325/Anti-MUAV15)]

- **VOTReview:** Zeshi Chen, Caiping Peng, Shuai Liu, Weiping Ding.<br />
  "Visual Object Tracking: Review and Challenges." ASOC (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S156849462500451X)] 
  [[code]( )]
  
- **A-CLIP:** Hong Zhu, Qingyang Lu, Lei Xue, Guanglin Yuan, Kaihua Zhang.<br />
  "Joint Feature Extraction and Alignment in Object Tracking with Vision-Language Model." EAAI (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0952197625007870)] 
  [[code]( )]

- **ECTTrack:** Liang Xu, Zhiqing Guo, Liejun Wang.<br />
  "Efficient hybrid linear self-attention based visual object tracking with LoRA." NUECOM (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0925231225010070)] 
  [[code](https://github.com/mrlonely426/ECTTrack)]

- **MFNet:** Fanghua Hong, Wanyu Wang, Andong Lu, Lei Liu, Qunjing Wang.<br />
  "Efficient RGBT Tracking via Multi-Path Mamba Fusion Network." SPL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10971948)] 
  [[code]( )]

- **M3Track:** Zhangyong Tang, Tianyang Xu, Xiao-jun Wu, Josef Kittler.<br />
  "M3Track: Meta-Prompt for Multi-Modal Tracking." SPL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10949728)] 
  [[code](https://github.com/Zhangyong-Tang/M3Track)]

- **AdaMoT:** Yongjun Wang, Xiaohui Hao.<br />
  "AdaMoT: Adaptive Motion-Aware Transformer for Efficient Visual Tracking." SPL (2025).
  [[paper](https://ieeexplore.ieee.org/document/10935672)] 
  [[code]( )]

- **EMTrack:** Xianda Xu, Shilong Jing, Zeshu Zhang, Chao Chen, Guangsha Guo, Hengyi Lv.<br />
  "EMTrack: Event-guide Multimodal Transformer for Challenging Single Object Tracking." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11026009)] 
  [[code](https://github.com/lpsg555/EMTrack)]

- **FAEFTrack:** Xilong Shang, Zhaoyuan Zeng, Xiaopeng Li, Cien Fan, Weizheng Jin.<br />
  "Improving Object Tracking Performances with Frequency Learning for Event Cameras." JSEN (2025).
  [[paper](https://ieeexplore.ieee.org/document/10994255)] 
  [[code]( )]
  
- **TGTrack:** Junze Shi, Yang Yu, Bin Hui, Jian Shi, Haibo Luo.<br />
  "Historical States Modeling for Visual Tracking." NCAA (2025).
  [[paper](https://arxiv.org/abs/2501.03616)] 
  [[code]( )]

- **TAAT:** Zhangyong Tang, Tianyang Xu, Xiao-Jun Wu, Josef Kittler.<br />
  "Temporal Aggregation for Real-time RGBT Tracking via Fast Decision-level Fusion." PRL (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0167865525001229)] 
  [[code](https://github.com/Zhangyong-Tang/TAAT-PRL)]

- **TADMT:** Guocai Du, Peiyong Zhou, Nurbiya Yadikar, Alimjan Aysa, Kurban Ubul.<br />
  "Mamba Meets Tracker: Exploiting Token Aggregation and Diffusion for Robust Unmanned Aerial Vehicles Tracking." CAIS (2025).
  [[paper](https://link.springer.com/article/10.1007/s40747-025-01821-z)] 
  [[code]( )]

- **FCSurvey:** Wenqi Zhang, Xinqiang Li, Xingyu Liu, Shiteng Lu, Huanling Tang.<br />
  "Facing Challenges: A Survey of Object Tracking." DSP (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1051200425001046)] 
  [[code]( )]
  
- **BFTrans:** Xinglong Sun, Haijiang Sun, Shan Jiang, Jiacheng Wang, Jiasong Wang.<br />
  "Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.09951)] 
  [[code]( )]

- **CFTrack:** Juntao Liang, Jun Hou, Weijun Zhang, Yong Wang.<br />
  "CFTrack: Enhancing Lightweight Visual Tracking through Contrastive Learning and Feature Matching." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.19705)] 
  [[code]( )]
  
  
  
### NeurIPS 2024

- **ChatTracker:** Yiming Sun, Fan Yu, Shaoxiang Chen, Yu Zhang, Junwei Huang, Chenhui Li, Yang Li, Changbo Wang.<br />
  "ChatTracker: Enhancing Visual Tracking Performance via Chatting with Multimodal Large Language Model." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2411.01756)] 
  [[code]( )]

- **WebUOT-1M:** Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2405.19818)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]

- **VastTrack:** Liang Peng, Junyuan Gao, Xinran Liu, Weihong Li, Shaohua Dong, Zhipeng Zhang, Heng Fan, Libo Zhang.<br />
  "VastTrack: Vast Category Visual Object Tracking." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2403.03493)] 
  [[code](https://github.com/HengLan/VastTrack)]

- **DeTrack:** Xinyu Zhou, Jinglun Li, Lingyi Hong, Kaixun Jiang, Pinxue Guo, Weifeng Ge, Wenqiang Zhang.<br />
  "DeTrack: In-model Latent Denoising Learning for Visual Object Tracking." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2501.02467)] 
  [[code]( )]

- **CSAM:** Tianlu Zhang, Kurt Debattista, Qiang Zhang, Guiguang Ding, Jungong Han.<br />
  "Revisiting Motion Information for RGB-Event Tracking with MOT Philosophy." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=bzGAELYOyL)] 
  [[code]( )]

- **DINTR:** Pha Nguyen, Ngan Le, Jackson Cothren, Alper Yilmaz, Khoa Luu.<br />
  "DINTR: Tracking via Diffusion-based Interpolation." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2410.10053)] 
  [[code]( )]

- **UAV3D:** Hui Ye, Rajshekhar Sunderraman, Shihao Ji.<br />
  "UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial  Vehicles." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2410.11125)] 
  [[code](https://huiyegit.github.io/UAV3D_Benchmark/)]
  
- **MemVLT:** Xiaokun Feng, Xuchen Li, Shiyu Hu, Dailing Zhang, Meiqi Wu, Xiaotang Chen, Kaiqi Huang.<br />
  "MemVLT: Vision-Language Tracking with Adaptive Memory-based Prompts." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=ZK1CZXKgG5)] 
  [[code](https://github.com/XiaokunFeng/MemVLT)]

- **CPDTrack:** Dailing Zhang, Shiyu Hu, Xiaokun Feng, Xuchen Li, Meiqi Wu, Kaiqi Huang.<br />
  "Beyond Accuracy: Tracking more like Human via Visual Search." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=LezAEImfoc)] 
  [[code](https://github.com/ZhangDailing8/CPDTrack)]


### ECCV 2024

- **Diff-Tracker:** Zhengbo Zhang, Li Xu, Duo Peng, Hossein Rahmani, Jun Liu.<br />
  "Diff-Tracker: Text-to-Image Diffusion Models are Unsupervised Trackers." ECCV (2024).
  [[paper](https://arxiv.org/abs/2407.08394)] 
  [[code]( )]

- **LoRAT:** Liting Lin, Heng Fan, Zhipeng Zhang, Yaowei Wang, Yong Xu, Haibin Ling.<br />
  "Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.05231)] 
  [[code](https://github.com/LitingLin/LoRAT)]

- **BenSMOT:** Yunhao Li, Hao Wang, Xue Ma, Jiali Yao, Shaohua Dong, Heng Fan, Libo Zhang.<br />
  "Beyond MOT: Semantic Multi-Object Tracking." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.05021)] 
  [[code](https://github.com/HengLan/SMOT)]

- **VideoMamba:** Kunchang Li, Xinhao Li, Yi Wang, Yinan He, Yali Wang, Limin Wang, Yu Qiao.<br />
  "VideoMamba: State Space Model for Efficient Video Understanding." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.06977)] 
  [[code](https://huggingface.co/OpenGVLab/VideoMamba)]

- **DINO-Tracker:** Narek Tumanyan, Assaf Singer, Shai Bagon, Tali Dekel.<br />
  "DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.14548v1)] 
  [[code](https://dino-tracker.github.io/)]

- **DecoMotion:** Rui Li, Dong Liu.<br />
  "Decomposition Betters Tracking Everything Everywhere." ECCV (2024).
  [[paper](https://arxiv.org/abs/2407.06531)] 
  [[code](https://github.com/qianduoduolr/DecoMotion)]

- **Elysium:** Han Wang, Yanjie Wang, Yongjie Ye, Yuxiang Nie, Can Huang.<br />
  "Elysium: Exploring Object-level Perception in Videos via MLLM." ECCV (2024).
  [[paper](https://arxiv.org/abs/2408.02049)] 
  [[code](https://github.com/Hon-Wong/Elysium)]
  
- **HVTrack:** Qiao Wu, Kun Sun, Pei An, Mathieu Salzmann, Yanning Zhang, Jiaqi Yang.<br />
  "3D Single-object Tracking in Point Clouds with High Temporal Variation." ECCV (2024).
  [[paper](https://arxiv.org/abs/2408.02049)] 
  [[code]( )]

- **AADN:** Zhewei Wu, Ruilong Yu, Qihe Liu, Shuying Cheng, Shilin Qiu, Shijie Zhou.<br />
  "Enhancing Tracking Robustness with Auxiliary Adversarial Defense Networks." ECCV (2024).
  [[paper](https://arxiv.org/abs/2402.17976)] 
  [[code](https://github.com/)]
  

### CVPR 2024

- **MASA:** Siyuan Li, Lei Ke, Martin Danelljan, Luigi Piccinelli, Mattia Segu, Luc Van Gool, Fisher Yu.<br />
  "Matching Anything by Segmenting Anything." CVPR (2024).
  [[paper](https://arxiv.org/abs/2406.04221)] 
  [[code](https://matchinganything.github.io/)]

- **OneTracker:** Lingyi Hong, Shilin Yan, Renrui Zhang, Wanyun Li, Xinyu Zhou, Pinxue Guo, Kaixun Jiang, Yiting Cheng, Jinglun Li, Zhaoyu Chen, Wenqiang Zhang.<br />
  "OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.09634)] 
  [[code](https://)]

- **ARTrackV2:** Yifan Bai, Zeyang Zhao, Yihong Gong, Xing Wei.<br />
  "ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to Describe." CVPR (2024).
  [[paper](https://arxiv.org/abs/2312.17133)] 
  [[code](https://artrackv2.github.io/)]

- **DiffusionTrack:** Fei Xie, Zhongdao Wang, Chao Ma.<br />
  "DiffusionTrack: Point Set Diffusion Model for Visual Object Tracking." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xie_DiffusionTrack_Point_Set_Diffusion_Model_for_Visual_Object_Tracking_CVPR_2024_paper.html)] 
  [[code](https://github.com/VISION-SJTU/DiffusionTrack)]

- **RTracker:** Yuqing Huang, Xin Li, Zikun Zhou, Yaowei Wang, Zhenyu He, Ming-Hsuan Yang.<br />
  "RTracker: Recoverable Tracking via PN Tree Structured Memory." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.19242)] 
  [[code](https://github.com/NorahGreen/RTracker)]

- **NetTrack:** Guangze Zheng, Shijie Lin, Haobo Zuo, Changhong Fu, Jia Pan.<br />
  "NetTrack: Tracking Highly Dynamic Objects with a Net." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.11186)] 
  [[code](https://george-zhuang.github.io/nettrack/)]

- **LMOT:** Xinzhe Wang, Kang Ma, Qiankun Liu, Yunhao Zou, Ying Fu.<br />
  "Multi-Object Tracking in the Dark." CVPR (2024).
  [[paper](https://arxiv.org/abs/2405.06600)] 
  [[code](https://github.com/ying-fu/LMOT)]

- **DeconfuseTrack:** Cheng Huang, Shoudong Han, Mengyu He, Wenbo Zheng, Yuhao Wei.<br />
  "DeconfuseTrack: Dealing with Confusion for Multi-Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.02767)] 
  [[code]( )]

- **DiffMOT:** Weiyi Lv, Yuhang Huang, Ning Zhang, Ruei-Sung Lin, Mei Han, Dan Zeng.<br />
  "DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.02075)] 
  [[code](https://diffmot.github.io/)]

- **GeneralTrack:** Zheng Qin, Le Wang, Sanping Zhou, Panpan Fu, Gang Hua, Wei Tang.<br />
  "Towards Generalizable Multi-Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2406.00429)] 
  [[code](https://github.com/qinzheng2000/GeneralTrack.git)]

- **TLTDMOT:** Sijia Chen, En Yu, Jinyang Li, Wenbing Tao.<br />
  "Delving into the Trajectory Long-tail Distribution for Muti-object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.04700)] 
  [[code](https://github.com/chen-si-jia/Trajectory-Long-tail-Distribution-for-MOT)]
  
- **Un-Track:** Zongwei Wu, Jilai Zheng, Xiangxuan Ren, Florin-Alexandru Vasluianu, Chao Ma, Danda Pani Paudel, Luc Van Gool, Radu Timofte.<br />
  "Single-Model and Any-Modality for Video Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2311.15851)] 
  [[code](https://github.com/Zongwei97/UnTrack)]

- **HIPTrack:** Wenrui Cai, Qingjie Liu, Yunhong Wang.<br />
  "HIPTrack: Visual Tracking with Historical Prompts." CVPR (2024).
  [[paper](https://arxiv.org/abs/2311.02072)] 
  [[code](https://github.com/WenRuiCai/HIPTrack)]

- **AQATrack:** Jinxia Xie, Bineng Zhong, Zhiyi Mo, Shengping Zhang, Liangtao Shi, Shuxiang Song, Rongrong Ji.<br />
  "Autoregressive Queries for Adaptive Tracking with Spatio-Temporal Transformers." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Autoregressive_Queries_for_Adaptive_Tracking_with_Spatio-Temporal_Transformers_CVPR_2024_paper.html)] 
  [[code](https://github.com/GXNU-ZhongLab/AQATrack)]

- **MMA:** Lingxiao Yang, Ru-Yuan Zhang, Yanchen Wang, Xiaohua Xie.<br />
  "MMA: Multi-Modal Adapter for Vision-Language Models." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_MMA_Multi-Modal_Adapter_for_Vision-Language_Models_CVPR_2024_paper.html)] 
  [[code](https://github.com/ZjjConan/Multi-Modal-Adapter)]

- **SDSTrack:** Xiaojun Hou, Jiazheng Xing, Yijie Qian, Yaowei Guo, Shuo Xin, Junhao Chen, Kai Tang, Mengmeng Wang, Zhengkai Jiang, Liang Liu, Yong Liu.<br />
  "SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.16002)] 
  [[code](https://github.com/hoqolo/SDSTrack)]

- **SpatialTracker:** Yuxi Xiao, Qianqian Wang, Shangzhan Zhang, Nan Xue, Sida Peng, Yujun Shen, Xiaowei Zhou.<br />
  "SpatialTracker: Tracking Any 2D Pixels in 3D Space." CVPR (2024).
  [[paper](https://arxiv.org/abs/2404.04319)] 
  [[code](https://henry123-boy.github.io/SpaTracker/)]

- **RALF:** Jooyeon Kim, Eulrang Cho, Sehyung Kim, Hyunwoo J. Kim.<br />
  "Retrieval-Augmented Open-Vocabulary Object Detection." CVPR (2024).
  [[paper](https://arxiv.org/abs/2404.05687)] 
  [[code](https://github.com/mlvlab/RALF)]

- **HDETrack:** Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang.<br />
  "Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline." CVPR (2024).
  [[paper](https://arxiv.org/abs/2309.14611)] 
  [[code](https://github.com/Event-AHU/EventVOT_Benchmark)]

- **CAI:** Yanyan Shao, Shuting He, Qi Ye, Yuchao Feng, Wenhan Luo, Jiming Chen.<br />
  "Context-Aware Integration of Language and Visual References for Natural Language Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.19975)] 
  [[code](https://github.com/twotwo2/QueryNLT)]

- **DTLLM-VLT:** Xuchen Li, Xiaokun Feng, Shiyu Hu, Meiqi Wu, Dailing Zhang, Jing Zhang, Kaiqi Huang.<br />
  "DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on LLM." CVPRW (2024).
  [[paper](https://arxiv.org/abs/2405.12139)] 
  [[code]( )]
  
- **MTMMC:** Sanghyun Woo, Kwanyong Park, Inkyu Shin, Myungchul Kim, In So Kweon.<br />
  "MTMMC: A Large-Scale Real-World Multi-Modal Camera Tracking Benchmark." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.20225)] 
  [[code](https://sites.google.com/view/mtmmc)]

- **ResampleTrack:** Xuhong Ren, Jianlang Chen, Yue Cao, Wanli Xue, Qing Guo, Lei Ma, Jianjun Zhao, Shenyong Chen.<br />
  "ResampleTrack: Online Resampling for Adversarially Robust Visual Tracking." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Ren_ResampleTrack_Online_Resampling_for_Adversarially_Robust_Visual_Tracking_CVPRW_2024_paper.html)] 
  [[code]( )]
  

### WACV 2024

- **ContrasTR:** Pierre-François De Plaen, Nicola Marinello, Marc Proesmans, Tinne Tuytelaars, Luc Van Gool.<br />
  "Contrastive Learning for Multi-Object Tracking With Transformers." WACV (2024).
  [[paper](https://openaccess.thecvf.com/content/WACV2024/papers/De_Plaen_Contrastive_Learning_for_Multi-Object_Tracking_With_Transformers_WACV_2024_paper.pdf)] 
  [[code]()]

- **LaGOT:** Christoph Mayer, Martin Danelljan, Ming-Hsuan Yang, Vittorio Ferrari, Luc Van Gool, Alina Kuznetsova.<br />
  "Beyond SOT: It's Time to Track Multiple Generic Objects at Once." WACV (2024).
  [[paper](https://arxiv.org/abs/2212.11920)] 
  [[code](https://github.com/visionml/pytracking)]

- **SiamABC:** Ram Zaveri, Shivang Patel, Yu Gu, Gianfranco Doretto.<br />
  "Improving Accuracy and Generalization for Efficient Visual Tracking." WACV (2025).
  [[paper](https://arxiv.org/abs/2411.18855)] 
  [[code](https://wvuvl.github.io/SiamABC/)]

- **SMAT:** Goutam Yelluru Gopal, Maria A. Amer.<br />
  "Separable Self and Mixed Attention Transformers for Efficient Object Tracking." WACV (2024).
  [[paper](https://arxiv.org/abs/2309.03979)] 
  [[code](https://github.com/goutamyg/SMAT)]
  
- **DATr:** Jie Zhao, Johan Edstedt, Michael Felsberg, Dong Wang, Huchuan Lu.<br />
  "Leveraging the Power of Data Augmentation for Transformer-based Tracking." WACV (2024).
  [[paper](https://arxiv.org/abs/2309.08264)] 
  [[code](https://github.com/zj5559/DATr)]
  
### AAAI 2024

- **GMMT:** Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Xiao-Jun Wu, Josef Kittler.<br />
  "Generative-based Fusion Mechanism for Multi-Modal Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2309.01728)] 
  [[code](https://github.com/Zhangyong-Tang/GMMT)]

- **ODTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Zhiyi Mo, Shengping Zhang, Xianxian Li.<br />
  "ODTrack: Online Dense Temporal Token Learning for Visual Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.01686)] 
  [[code](https://github.com/GXNU-ZhongLab/ODTrack)]

 - **EVPTrack:** Liangtao Shi, Bineng Zhong, Qihua Liang, Ning Li, Shengping Zhang, Xianxian Li.<br />
  "Explicit Visual Prompts for Visual Object Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.03142)] 
  [[code](https://github.com/GXNU-ZhongLab/EVPTrack)] 

- **UVLTrack:** Yinchao Ma, Yuyang Tang, Wenfei Yang, Tianzhu Zhang, Jinpeng Zhang, Mengxue Kang.<br />
  "Unifying Visual and Vision-Language Tracking via Contrastive Learning." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.11228)] 
  [[code](https://github.com/OpenSpaceAI/UVLTrack)]
  
 - **STCFormer:** Kun Hu, Wenjing Yang, Wanrong Huang, Xianchen Zhou, Mingyu Cao, Jing Ren, Huibin Tan.<br />
  "Sequential Fusion Based Multi-Granularity Consistency for Space-Time Transformer Tracking." AAAI (2024).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29145)] 
  [[code]( )]

- **BAT:** Bing Cao, Junliang Guo, Pengfei Zhu, Qinghua Hu.<br />
  "Bi-directional Adapter for Multimodal Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2312.10611)] 
  [[code](https://github.com/SparkTempest/BAT)]

- **TATrack:** Hongyu Wang, Xiaotao Liu, Yifan Li, Meng Sun, Dian Yuan, Jing Liu.<br />
  "Temporal Adaptive RGBT Tracking with Modality Prompt." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.01244)] 
  [[code]()]

- **Hybrid-SORT:** Mingzhan Yang, Guangxin Han, Bin Yan, Wenhua Zhang, Jinqing Qi, Huchuan Lu, Dong Wang.<br />
  "Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2308.00783)] 
  [[code](https://github.com/ymzis69/HybirdSORT)]

- **SR-Track:** Zepeng Li, Dongxiang Zhang, Sai Wu, Mingli Song, Gang Chen.<br />
  "Sampling-Resilient Multi-Object Tracking." AAAI (2024).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/28115)] 
  [[code]( )]

- **USTrack:** Jianqiang Xia, DianXi Shi, Ke Song, Linna Song, XiaoLei Wang, Songchang Jin, Li Zhou, Yu Cheng, Lei Jin, Zheng Zhu, Jianan Li, Gang Wang, Junliang Xing, Jian Zhao.<br />
  "Unified Single-Stage Transformer Network for Efficient RGB-T Tracking." IJCAI (2024).
  [[paper](https://arxiv.org/abs/2308.13764)] 
  [[code]( )]

- **DMTrack:** Guangtong Zhang, Bineng Zhong, Qihua Liang, Zhiyi Mo, Shuxiang Song.<br />
  "Diffusion Mask-Driven Visual-language Tracking." IJCAI (2024).
  [[paper](https://www.ijcai.org/proceedings/2024/183)] 
  [[code]( )]


### ACM MM 2024

- **MambaTrack:** Changcheng Xiao, Qiong Cao, Zhigang Luo, Long Lan.<br />
  "MambaTrack: A Simple Baseline for Multiple Object Tracking with State Space Model." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2408.09178)] 
  [[code]( )]

- **CKD:** Andong Lu, Jiacong Zhao, Chenglong Li, Yun Xiao, Bin Luo.<br />
  "Breaking Modality Gap in RGBT Tracking: Coupled Knowledge Distillation." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2410.11586)] 
  [[code](https://github.com/Multi-Modality-Tracking/CKD)]

- **IIMF:** Liqiu Chen, Yuqing Huang, Hengyu Li, Zikun Zhou, Zhenyu He.<br />
  "Simplifying Cross-modal Interaction via Modality-Shared Features for RGBT Tracking." ACM MM (2024).
  [[paper](https://dl.acm.org/doi/10.1145/3664647.3681564)] 
  [[code](https://github.com/Liqiu-Chen/IIMF)]
  
- **VoxelTrack:** Yuxuan Lu, Jiahao Nie, Zhiwei He, Hongjie Gu, Xudong Lv.<br />
  "VoxelTrack: Exploring Voxel Representation for 3D Point Cloud Object Tracking." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2408.02263)] 
  [[code]( )]

- **DenseTrack:** Yi Lei, Huilin Zhu, Jingling Yuan, Guangli Xiang, Xian Zhong, Shengfeng He.<br />
  "DenseTrack: Drone-based Crowd Tracking via Density-aware Motion-appearance Synergy." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2407.17272)] 
  [[code]( )]

- **GLATrack:** Guangyao Li, Yajun Jian, Yajun Jian, Yan Yan, Yan Yan, Hanzi Wang, Hanzi Wang.<br />
  "GLATrack: Global and Local Awareness for Open-Vocabulary Multiple Object Tracking." ACM MM (2024).
  [[paper](https://dl.acm.org/doi/10.1145/3664647.3681530)] 
  [[code]( )]
  
- **X-Prompt:** Pinxue Guo, Wanyun Li, Hao Huang, Lingyi Hong, Xinyu Zhou, Zhaoyu Chen, Jinglun Li, Kaixun Jiang, Wei Zhang, Wenqiang Zhang.<br />
  "X-Prompt: Multi-modal Visual Prompt for Video Object Segmentation." ACM MM (2024).
  [[paper](https://arxiv.org/abs/2409.19342)] 
  [[code](https://github.com/PinxueGuo/X-Prompt.git)]
  
  
### Others 2024

- **CUTrack:** Jiahao Nie, Zhiwei He, Xudong Lv, Xueyi Zhou, Dong-Kyu Chae, Fei Xie.<br />
  "Towards Category Unification of 3D Single Object Tracking on Point Clouds." ICLR (2024).
  [[paper](https://arxiv.org/abs/2401.11204)] 
  [[code](https://github.com/Haooozi/CUTrack)]

- **SeqTrack3D:** Yu Lin, Zhiheng Li, Yubo Cui, Zheng Fang.<br />
  "SeqTrack3D: Exploring Sequence Information for Robust 3D Point Cloud Tracking." ICRA (2024).
  [[paper](https://arxiv.org/abs/2402.16249)] 
  [[code](https://github.com/aron-lin/seqtrack3d)]

- **VADT:** Guangtong Zhang, Qihua Liang, Zhiyi Mo, Ning Li, Bineng Zhong.<br />
  "Visual Adapt for RGBD Tracking." ICASSP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10447728)] 
  [[code]( )]

- **GFATrack:** Yanfang Deng, Canlong Zhang, Zhixin Li, Chunrong Wei, Zhiwen Wang, Shuqi Pan.<br />
  "Gradually Spatio-Temporal Feature Activation for Target Tracking." ICASSP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10447555)] 
  [[code]( )]

- **TDA-Track:** Changhong Fu, Yiheng Wang, Liangliang Yao, Guangze Zheng, Haobo Zuo, Jia Pan.<br />
  "Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking." IROS (2024).
  [[paper](https://arxiv.org/abs/2409.18533)] 
  [[code](https://github.com/vision4robotics/TDA-Track)]

- **PRL-Track:** Changhong Fu, Xiang Lei, Haobo Zuo, Liangliang Yao, Guangze Zheng, Jia Pan.<br />
  "Progressive Representation Learning for Real-Time UAV Tracking." IROS (2024).
  [[paper](https://arxiv.org/abs/2409.16652)] 
  [[code](https://github.com/vision4robotics/PRL-Track)]

- **MMG:** Baojie Fan, Zhiquan Wang, Jiajun Ai, Caiyu Zhang.<br />
  "Masked Mutual Guidance Transformer Tracking." IROS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10801735)] 
  [[code]( )]
  
- **TMTB:** Yimin Du, Bi Zeng, Qingmao Wei, Boquan Zhang, Huiting Hu.<br />
  "Transformer-Mamba-Based Trident-Branch RGB-T Tracker." PRICAI (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-96-0122-6_4)] 
  [[code]( )]

- **DepthRefiner:** Simiao Lai; Dong Wang; Huchuan Lu.<br />
  "DepthRefiner: Adapting RGB Trackers to RGBD Scenes via Depth-Fused Refinement." ICME (2024).
  [[paper](https://ieeexplore.ieee.org/document/10687717)] 
  [[code]( )]
  
- **HCV:** Liang-Chia Chen, Wei-Ta Chu.<br />
  "HCV: Lightweight Hybrid CNN-Vision Transformer for Visual Object Tracking." MMM (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-96-2061-6_4)] 
  [[code]( )]

- **DMITrack:** Zhiyi Mo, Guangtong Zhang, Jian Nong, Bineng Zhong, Zhi Li.<br />
  "Dual-stream Multi-modal Interactive Vision-language Tracking." MM Asia (2024).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3696409.3700220)] 
  [[code]( )]
  
- **3DPT:** Bocen Li, Yunzhi Zhuge, Shan Jiang, Lijun Wang, Yifan Wang, Huchuan Lu.<br />
  "3D Prompt Learning for RGB-D Tracking." ACCV (2024).
  [[paper](https://openaccess.thecvf.com/content/ACCV2024/html/Li_3D_Prompt_Learning_for_RGB-D_Tracking_ACCV_2024_paper.html)] 
  [[code]( )]

- **Depth-Attention:** Yu Liu, Arif Mahmood, Muhammad Haris Khan.<br />
  "Depth Attention for Robust RGB Tracking." ACCV (2024).
  [[paper](https://arxiv.org/abs/2410.20395)] 
  [[code](https://github.com/LiuYuML/Depth-Attention)]

- **SAM2VOT, :** Cheng-Yen Yang, Hsiang-Wei Huang, Pyong-Kun Kim, Chien-Kai Kuo, Jui-Wei Chang, Kwang-Ju Kim, Chung-I Huang, Jenq-Neng Hwang.<br />
  "Adapting SAM 2 for Visual Object Tracking: 1st Place Solution for MMVPR Challenge Multi-Modal Tracking." ICPRW (2024).
  [[paper](https://arxiv.org/abs/2505.18111)] 
  [[code]( )]

- **DTAT:** Yifan Pan, Tianyang Xu, Xue-Feng Zhu, Xiaoqing Luo, Xiao-Jun Wu, Josef Kittler.<br />
  "Learning Explicit Modulation Vectors for Disentangled Transformer Attention-Based RGB-D Visual Tracking." ICPR (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-78444-6_22)] 
  [[code]( )]

- **VISTAC:** Asfak Ali, Arya Pandit, Shirshendu Mandal, Srinjan Bhattacharjee, Sauptik Maiti, Suvojit Acharjee, Ram Sarkar, Sos S. Agaian, Khalifa Djemal.<br />
  "VISual Tracking in Adverse Conditions." ICPR (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-80139-6_7)] 
  [[code](https://sites.google.com/view/ju-nvisot/home)]
  
- **RADA:** Avinash Chouhan, Mayank Chandak, Arijit Sur, Dibyajyoti Chutia, Shiv Prasad Aggarwal .<br />
  "RADA: Reconstruction Assisted Domain Adaptation for Nighttime Aerial Tracking." ICPR (2024).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-78192-6_21)] 
  [[code](https://github.com/chouhan-avinash/RADA)]
  
- **NT-VOT211:** Yu Liu, Arif Mahmood, Muhammad Haris Khan.<br />
  "NT-VOT211: A Large-Scale Benchmark for Night-time Visual Object Tracking." ACCV (2024).
  [[paper](https://arxiv.org/abs/2410.20421)] 
  [[code](https://github.com/LiuYuML/NV-VOT211)]

  
### ArXiv 2024

- **TBSI:** Bo Li, Fengguang Peng, Tianrui Hui, Xiaoming Wei, Xiaolin Wei, Lijun Zhang, Hang Shi, Si Liu.<br />
  "RGB-T Tracking with Template-Bridged Search Interaction and Target-Preserved Template Updating." TPAMI (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10706882)] 
  [[code](https://github.com/RyanHTR/TBSI)]

- **CTVLT:** Xiaokun Feng, Dailing Zhang, Shiyu Hu, Xuchen Li, Meiqi Wu, Jing Zhang, Xiaotang Chen, Kaiqi Huang.<br />
  "Enhancing Vision-Language Tracking by Effectively Converting Textual Cues into Visual Cues." ICASSP (2025).
  [[paper](https://arxiv.org/abs/2412.19648)] 
  [[code](https://github.com/XiaokunFeng/CTVLT)]
  
- **VOTReview:** Mengmeng Wang, Teli Ma, Shuo Xin, Xiaojun Hou, Jiazheng Xing, Guang Dai, Jingdong Wang, Yong Liu.<br />
  "Visual Object Tracking across Diverse Data Modalities: A Review." arXiv (2024).
  [[paper](https://arxiv.org/abs/2412.09991)] 
  [[code]( )]

- **TIRReview:** Di Yuan, Haiping Zhang, Xiu Shu, Qiao Liu, Xiaojun Chang, Zhenyu He, Guming Shi.<br />
  "Thermal Infrared Target Tracking: A Comprehensive Review." TIM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10339340)] 
  [[code]( )]

- **RGBTReview:** Haiping Zhang, Di Yuan, Xiu Shu, Zhihui Li, Qiao Liu, Xiaojun Chang, Zhenyu He, Guming Shi.<br />
  "A Comprehensive Review of RGBT Tracking." TIM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10616144)] 
  [[code]( )]
  
- **UAVReview:** Nianyi Sun, Jin Zhao, Qing Shi, Chang Liu, Peng Liu.<br />
  "Moving Target Tracking by Unmanned Aerial Vehicle: A Survey and Taxonomy." TII (2024).
  [[paper](https://ieeexplore.ieee.org/document/10445025)] 
  [[code]( )]

- **MMTrackingReview:** Pengyu Zhang, Dong Wang, Huchuan Lu.<br />
  "Multi-modal visual tracking: Review and experimental comparison ." CVM (2024).
  [[paper](https://link.springer.com/article/10.1007/s41095-023-0345-5)] 
  [[code](https://github.com/zhang-pengyu/Multimodal-Tracking-Survey)]
  
- **GLEE:** Junfeng Wu, Yi Jiang, Qihao Liu, Zehuan Yuan, Xiang Bai, Song Bai.<br />
  "General Object Foundation Model for Images and Videos at Scale." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2312.09158)] 
  [[code](https://glee-vision.github.io/)]

- **EfficientTAM:** Yunyang Xiong, Chong Zhou, Xiaoyu Xiang, Lemeng Wu, Chenchen Zhu, Zechun Liu, Saksham Suri, Balakrishnan Varadarajan, Ramya Akula, Forrest Iandola, Raghuraman Krishnamoorthi, Bilge Soran, Vikas Chandra.<br />
  "Efficient Track Anything." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.18933)] 
  [[code](https://yformer.github.io/efficient-track-anything/)]

- **DTVLT:** Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang.<br />
  "DTVLT: A Multi-modal Diverse Text Benchmark for Visual Language Tracking Based on LLM." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2410.02492)] 
  [[code](http://videocube.aitestunion.com/)]

- **COTD:** Xiaoyu Guo, Pengzhi Zhong, Hao Zhang, Ling Huang, Defeng Huang, Shuiwang Li.<br />
  "Camouflaged Object Tracking: A Benchmark." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.13877)] 
  [[code](https://github.com/openat25/HIPTrack-MLS)]

- **UW-COT:** Chunhui Zhang, Li Liu, Guanjie Huang, Zhipeng Zhang, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang.<br />
  "Underwater Camouflaged Object Tracking Meets Vision-Language SAM2." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.16902)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]

- **VLT:** Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang.<br />
  "Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.08887)] 
  [[code]( )]

- **LLOT:** Pengzhi Zhong, Xiaoyu Guo, Defeng Huang, Xiaojun Peng, Yian Li, Qijun Zhao, Shuiwang Li.<br />
  "Low-Light Object Tracking: A Benchmark." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.11463)] 
  [[code](https://github.com/OpenCodeGithub/H-DCPT)]

- **RGBEMOT:** Zhiyu Zhu, Junhui Hou, Jinjian Wu, Dapeng Wu.<br />
  "RGB-Event MOT: A Cross-Modal Benchmark for Multi-Object Tracking." ArXiv (2024).
  [[paper](https://openreview.net/forum?id=Z1Em654CSE)] 
  [[code](https://github.com/ZHU-Zhiyu/RGBEvt-MOT)]
  
- **VOVTrack:** Zekun Qian, Ruize Han, Junhui Hou, Linqi Song, Wei Feng.<br />
  "VOVTrack: Exploring the Potentiality in Videos for Open-Vocabulary Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2410.08529)] 
  [[code]( )]

- **TrackNetV4:** Arjun Raj, Lei Wang, Tom Gedeon.<br />
  "TrackNetV4: Enhancing Fast Sports Object Tracking with Motion Attention Maps." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.14543v1)] 
  [[code]( )]

- **CompressTracker:** Lingyi Hong, Jinglun Li, Xinyu Zhou, Shilin Yan, Pinxue Guo, Kaixun Jiang, Zhaoyu Chen, Shuyong Gao, Wei Zhang, Hong Lu, Wenqiang Zhang.<br />
  "General Compression Framework for Efficient Transformer Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.17564)] 
  [[code](https://github.com/LingyiHongfd/CompressTracker)]
  
- **BlinkTrack:** Yichen Shen, Yijin Li, Shuo Chen, Guanglin Li, Zhaoyang Huang, Hujun Bao, Zhaopeng Cui, Guofeng Zhang.<br />
  "BlinkTrack: Feature Tracking over 100 FPS via Events and Images." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.17981)] 
  [[code]( )]

- **MugTracker:** Hong Zhu, Pingping Zhang, Lei Xue, Guanglin Yuan.<br />
  "Multi-modal Understanding and Generation for Object Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10777574)] 
  [[code]( )]
  
- **TrackMamba:** Jiaming Zhang, Cheng Liang, Yutao Cui, Xiangbo Shu, Gangshan Wu, Limin Wang .<br />
  "TrackMamba: Mamba-Transformer Tracking." ArXiv (2024).
  [[paper](https://openreview.net/forum?id=V7QRVEZ0le)] 
  [[code]( )]

- **VLTVerse:** Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang.<br />
  "How Texts Help? A Fine-grained Evaluation to Reveal the Role of Language in Vision-Language Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.15600)] 
  [[code](http://metaverse.aitestunion.com/)]

- **CPIPTrack:** Hong Zhu, Qingyang Lu, Lei Xue, Pingping Zhang, Guanglin Yuan.<br />
  "Vision-Language Tracking With CLIP and Interactive Prompt Learning." TITS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10817474)] 
  [[code]( )]

- **PGM:** Hengyou Li, Xinyan Liu, Guorong Li, Shuhui Wang, Laiyun Qing, Qingming Huang.<br />
  "Boost Tracking by Natural Language With Prompt-Guided Grounding." TITS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10756281)] 
  [[code]( )]

- **UniMod1K:** Xue-Feng Zhu, Tianyang Xu, Zongtao Liu, Zhangyong Tang, Xiao-Jun Wu, Josef Kittler.<br />
  "UniMod1K: Towards a More Universal Large-Scale Dataset and Benchmark for Multi-modal Learning." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-01999-8)] 
  [[code](https://github.com/xuefeng-zhu5/UniMod1K)]

- **IPL:** Andong Lu, Chenglong Li, Jiacong Zhao, Jin Tang, Bin Luo.<br />
  "Modality-missing RGBT Tracking: Invertible Prompt Learning and High-quality Benchmarks ." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-02311-4)] 
  [[code](https://github.com/mmic-lcl)]
  
- **SATrack:** Yinchao Ma, Qianjin Yu, Wenfei Yang, Tianzhu Zhang, Jinpeng Zhang.<br />
  "Learning Discriminative Features for Visual Tracking via Scenario Decoupling ." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-02307-0)] 
  [[code]( )]
    
- **EMTrack:** Chang Liu, Ziqi Guan, Simiao Lai, Yang Liu, Huchuan Lu, Dong Wang.<br />
  "EMTrack: Efficient Multimodal Object Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10747517)] 
  [[code]( )]

- **PiVOT:** Shih-Fang Chen, Jun-Cheng Chen, I-Hong Jhuo, Yen-Yu Lin.<br />
  "Improving Visual Object Tracking through Visual Prompting." TMM (2024).
  [[paper](https://arxiv.org/abs/2409.18901)] 
  [[code](https://github.com/chenshihfang/GOT)]

- **SIMix:** Jinpu Zhang, Ziwen Li, Ruonan Wei, Yuehuan Wang.<br />
  "Augment One with Others: Generalizing to Unforeseen Variations for Visual Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10814671)] 
  [[code]( )]
  
- **DANet:** Yingkai Fu, Meng Li, Wenxi Liu, Yuanchen Wang, Jiqing Zhang, Baocai Yin, Xiaopeng Wei, Xin Yang.<br />
  "Distractor-Aware Event-Based Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/document/10299598)] 
  [[code]( )]

- **SiamGAT:** Yanyan Shao, Dongyan Guo, Ying Cui, Zhenhua Wang, Liyan Zhang, Jianhua Zhang<br />
  "Graph Attention Network for Context-Aware Visual Tracking." TNNLS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10693651)] 
  [[code](https://git.io/SiamGAT)]

- **SiamTADT:** Luming Li, Chenglizhao Chen, Xu Yu, Shanchen Pang; Hong Qin<br />
  "SiamTADT: A Task-Aware Drone Tracker for Aerial Autonomous Vehicles." TVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10755105)] 
  [[code](https://github.com/xl0312/SiamTADT)]
  
- **NiDR:** Xu Lei, Yan Zhang, Chang Xu, Wensheng Cheng, Wen Yang.<br />
  "NiDR: Nighttime Aerial Tracking via Decoupled Representations." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10770249)] 
  [[code]( )]

- **DAT:** Haowei Sun, Jinwu Hu, Zhirui Zhang, Haoyuan Tian, Xinze Xie, Yufeng Wang, Zhuliang Yu, Xiaohua Xie, Mingkui Tan.<br />
  "A Cross-Scene Benchmark for Open-World Drone Active Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.00744)] 
  [[code](https://dat-benchmark.framer.website/)]

- **AVTrack:** You Wu, Yongxin Li, Mengyuan Liu, Xucheng Wang, Xiangyang Yang, Hengzhou Ye, Dan Zeng, Qijun Zhao, Shuiwang Li.<br />
  "Learning Adaptive and View-Invariant Vision Transformer with Multi-Teacher Knowledge Distillation for Real-Time UAV Tracking." ArXiv (2024).
  [[icml](https://openreview.net/pdf?id=eaNLvrP8n1)] 
  [[paper](https://arxiv.org/abs/2412.20002)] 
  [[code](https://github.com/wuyou3474/AVTrack)]

- **MambaNUT:** You Wu, Xiangyang Yang, Xucheng Wang, Hengzhou Ye, Dan Zeng, Shuiwang Li.<br />
  "MambaNUT: Nighttime UAV Tracking via Mamba and Adaptive Curriculum Learning." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.00626)] 
  [[code]( )]
  
- **DaDiff:** Haobo Zuo, Changhong Fu, Guangze Zheng, Liangliang Yao, Kunhan Lu, Jia Pan.<br />
  "DaDiff: Domain-aware Diffusion Model for Nighttime UAV Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2410.12270)] 
  [[code](https://github.com/vision4robotics/DaDiff)]

- **LDEnhancer:** Liangliang Yao, Changhong Fu, Yiheng Wang, Haobo Zuo, Kunhan Lu.<br />
  "Enhancing Nighttime UAV Tracking with Light Distribution Suppression." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.16631)] 
  [[code](https://github.com/vision4robotics/LDEnhancer)]

- **BihoT:** Hanzheng Wang, Wei Li, Xiang-Gen Xia, Qian Du.<br />
  "BihoT: A Large-Scale Dataset and Benchmark for Hyperspectral Camouflaged Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.12232)] 
  [[code]( )]

- **DDFNet:** Chenglong Li, Tao Wang, Zhaodong Ding, Yun Xiao, Jin Tang.<br />
  "Dynamic Disentangled Fusion Network for RGBT Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.08441)] 
  [[code]( )]

- **DS-MESA:** Pengcheng Shao, Tianyang Xu, Xuefeng Zhu, Xiaojun Wu, Josef Kittler.<br />
  "Dynamic Subframe Splitting and Spatio-Temporal Motion Entangled Sparse Attention for RGB-E Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2409.17560)] 
  [[code]( )]

- **MambaTrack:** Chunhui Zhang, Li Liu, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "MambaTrack: Exploiting Dual-Enhancement for Night UAV Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2411.15761)] 
  [[code]( )]

- **MambaEVT:** Xiao Wang, Chao wang, Shiao Wang, Xixi Wang, Zhicheng Zhao, Lin Zhu, Bo Jiang.<br />
  "MambaEVT: Event Stream based Visual Object Tracking using State Space Model." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.10487)] 
  [[code](https://github.com/Event-AHU/MambaEVT)]

- **MambaVT:** Simiao Lai, Chang Liu, Jiawen Zhu, Ben Kang, Yang Liu, Dong Wang, Huchuan Lu.<br />
  "MambaVT: Spatio-Temporal Contextual Modeling for robust RGB-T Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.07889)] 
  [[code]( )]

- **TrackingMamba:** Qingwang Wang, Liyao Zhou, Pengcheng Jin, Xin Qu, Hangwei Zhong, Haochen Song, Tao Shen.<br />
  "TrackingMamba: Visual State Space Model for Object Tracking." JSTAR (2024).
  [[paper](https://ieeexplore.ieee.org/document/10678881)] 
  [[code](https://github.com/KustTeamWQW/TrackingMamba)]
  
- **FocTrack:** Jian Tao, Sixian Chan, Zhenchao Shi, Cong Bai, Shengyong Chen.<br />
  "FocTrack: Focus Attention for Visual Tracking." PR (2024).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320324008793)] 
  [[code]( )]

- **UniRTL:** Lian Zhang, Lingxue Wang, Yuzhen Wu, Mingkun Chen, Dezhi Zheng, Liangcai Cao, Bangze Zeng, Yi Cai.<br />
  "UniRTL: A Universal RGBT and Low-light Benchmark for Object Tracking." PR (2024).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320324007350)] 
  [[code](https://github.com/Liamzh0331/Unismot)]

- **CVT-Track:** Jianan Li, Xiaoying Yuan, Haolin Qin, Ying Wang, Xincong Liu, Tingfa Xu.<br />
  "CVT-Track: Concentrating on Valid Tokens for One-Stream Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10659749)] 
  [[code]( )]

- **MFDSTrack:** Yamin Han, Mingyu Cai, Jie Wu, Zhixuan Bai, Tao Zhuo, Hongming Zhang.<br />
  "Visual Object Tracking with Multi-Frame Distractor Suppression." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10741210)] 
  [[code]( )]

- **AMATrack:** Ping Ye, Gang Xiao, Jun Liu.<br />
  "AMATrack: A Unified Network With Asymmetric Multimodal Mixed Attention for RGBD Tracking." TIM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10623547)] 
  [[code]( )]

- **LDLC:** Jun Yu, Zhongpeng Cai, Yihao Li, Lei Wang, Fang Gao, Ye Yu.<br />
  "Language-guided Dual-modal Local Correspondence for Single Object Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10659157)] 
  [[code]( )]
  
- **MGTrack:** Jiabing Xiong, Qiang Ling.<br />
  "Mask-Guided Siamese Tracking with a Frequency-Spatial Hybrid Network." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10662977)] 
  [[code](https://github.com/jiabingxiing/MGTrack)]
  
- **KSTrack:** Yuhang He, Zhiheng Ma, Xing Wei, Yihong Gong.<br />
  "Knowledge Synergy Learning for Multi-Modal Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10388341)] 
  [[code]( )]

- **SiamSRT:** Bo Huang, Zeyang Dou, Junjie Chen, Jianan Li, Ning Shen, Ying Wang.<br />
  "Searching Region-Free and Template-Free Siamese Network for Tracking Drones in TIR Videos." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10352116)] 
  [[code]( )]

- **SATDark:** Jialei Pan, Yanfeng Gu, Guoming Gao, Qiang Wang, Shaochuan Wu.<br />
  "SATDark: A Satellite Video Low-light Tracking Benchmark for Dark and Weak Vehicles." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10741334)] 
  [[code]( )]

- **HDSP:** Rui Yao, Lu Zhang, Yong Zhou, Hancheng Zhu, Jiaqi Zhao, Zhiwen Shao.<br />
  "Hyperspectral Object Tracking with Dual-Stream Prompt." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10798510)] 
  [[code](https://github.com/rayyao/HDSP)]

- **PHTrack:** Yuzeng Chen, Yuqi Tang, Xin Su, Jie Li, Yi Xiao, Jiang He, Qiangqiang Yuan.<br />
  "PHTrack: Prompting for Hyperspectral Video Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10680554)] 
  [[code](https://github.com/YZCU/PHTrack)]

- **LGSAT:** Langkun Chen, Long Gao, Yan Jiang, Yunsong Li, Gang He, Jifeng Ning.<br />
  "Local-Global Self-Attention for Transformer-based Object Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/document/10613604)] 
  [[code](https://github.com/lgao001/LGSAT)]

- **GSOT3D:** Yifan Jiao, Yunhao Li, Junhua Ding, Qing Yang, Song Fu, Heng Fan, Libo Zhang.<br />
  "GSOT3D: Towards Generic 3D Single Object Tracking in the Wild." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.02129)] 
  [[code](https://github.com/ailovejinx/GSOT3D)]

- **MVCTrack:** Zhaofeng Hu, Sifan Zhou, Shibo Zhao, Zhihang Yuan.<br />
  "MVCTrack: Boosting 3D Point Cloud Tracking via Multimodal-Guided Virtual Cues." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2412.02734)] 
  [[code](https://github.com/StiphyJay/MVCTrack)]
  
- **SiamMo:** Yuxiang Yang, Yingqi Deng, Jing Zhang, Hongjie Gu, Zhekang Don.<br />
  "SiamMo: Siamese Motion-Centric 3D Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2408.01688)] 
  [[code](https://github.com/HDU-VRLab/SiamMo)]

- **TP2N:** Basit Alawode, Sajid Javed, Arif Mahmood, Jiri Matas.<br />
  "Predicting the Best of N Visual Trackers." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2407.15707)] 
  [[code](https://github.com/BasitAlawode/Best_of_N_Trackers)]

- **PDAT:** Qiao Li, Kanlun Tan, Qiao Liu, Di Yuan, Xin Li, Yunpeng Liu.<br />
  "Progressive Domain Adaptation for Thermal Infrared Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2407.19430)] 
  [[code]( )]
  
- **FDTrack:** Zhao Gao, Dongming Zhou, Jinde Cao, Yisong Liu, Qingqing Shan.<br />
  "FDTrack: A Dual-head Focus Tracking Network with Frequency Enhancement." JSEN (2024).
  [[paper](https://ieeexplore.ieee.org/document/10778233)] 
  [[code]( )]

- **LMINet:** Jiatian Mei, Juxiang Zhou, Jun Wang, Jia Hao, Dongming Zhou, Jinde Cao.<br />
  "Learning Multi-frequency Integration Network for RGBT Tracking." JSEN (2024).
  [[paper](https://ieeexplore.ieee.org/document/10458005)] 
  [[code](https://github.com/mjt1312/Lminet)]

- **ETIT:** Weisheng Li, Shunping Chen, Yuhao Fang, Yidong Peng.<br />
  "Efficient Thermal Infrared Tracking via Multi-enhancement and Spatial Shift Pyramid." JSEN (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10630644)] 
  [[code]( )]

- **STNet:** Yidi Li, Hong Liu, Bing Yang.<br />
  "STNet: Deep Audio-Visual Fusion Network for Robust Speaker Tracking." TMM (2024).
  [[paper](https://arxiv.org/abs/2410.05964)] 
  [[code](https://github.com/liyidi/STNet)]

- **MATrack:** Guotian Zeng, Bi Zeng, Qingmao Wei, Huiting Hu, Hong Zhang.<br />
  "Visual Object Tracking with Mutual Affinity Aligned to Human Intuition." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10539277)] 
  [[code]( )]

- **CGBA:** Xingsen Huang, Deshui Miao, Hongpeng Wang, Yaowei Wang, Xin Li.<br />
  "Context-Guided Black-Box Attack for Visual Tracking." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/document/10489919)] 
  [[code]( )]
  
- **OTETrack:** Li Shen, Xuyi Fan, Hongguang Li.<br />
  "Overlapped Trajectory-Enhanced Visual Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10630872)] 
  [[code](https://github.com/OrigamiSL/OTETrack)]

- **VLCTrack:** Jiahao Wang, Fang Liu, Licheng Jiao, Yingjia Gao, Hao Wang, Shuo Li, Lingling Li, Puhua Chen, Xu Liu.<br />
  "Visual and Language Collaborative Learning for RGBT Object Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10620225)] 
  [[code]( )]

- **STMT:** Dengdi Sun, Yajie Pan, Andong Lu, Chenglong Li, Bin Luo.<br />
  "Transformer RGBT Tracking With Spatio-Temporal Multimodal Tokens." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10589660)] 
  [[code](https://github.com/yinghaidada/STMT)]

- **TGTrack:** Liang Chen, Bineng Zhong, Qihua Liang, Yaozong Zheng, Zhiyi Mo, Shuxiang Song.<br />
  "Top-down Cross-modal Guidance for Robust RGB-T Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10614652)] 
  [[code]( )]

- **MELT:** Zhangyong Tang, Tianyang Xu, Xiao-Jun Wu, Josef Kittler.<br />
  "Multi-Level Fusion for Robust RGBT Tracking via Enhanced Thermal Representation." TOMM (2024).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3678176)] 
  [[code](https://github.com/Zhangyong-Tang/MELT)]

- **S2OTFormer:** Shenglan Li, Rui Yao, Yong Zhou, Hancheng Zhu, Jiaqi Zhao, Zhiwen Shao, Abdulmotaleb El Saddik.<br />
  "Motion-aware Self-supervised RGBT Tracking with Multi-modality Hierarchical Transformers." TOMM (2024).
  [[paper](https://dl.acm.org/doi/10.1145/3698399)] 
  [[code](https://github.com/LiShenglana/S2OTFormer)]

- **MCTrack:** Shilei Wang, Zhenhua Wang, Qianqian Sun, Gong Cheng, Jifeng Ning.<br />
  "Modelling of Multiple Spatial-Temporal Relations for Robust Visual Object Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10670064)] 
  [[code]( )]

- **MMSTC:** Tianlu Zhang, Qiang Jiao, Qiang Zhang, Jungong Han.<br />
  "Exploring Multi-modal Spatial-Temporal Contexts for High-performance RGB-T Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10605602)] 
  [[code]( )]

- **LMANet:** Yabin Zhu, Xingle Zhao, Chenglong Li, Jin Tang, Zhixiang Huang.<br />
  "Long-term Motion Assisted Remote Sensing Object Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10601232)] 
  [[code](https://github.com/zhaoxingle/LMANet)]
  
- **ADSF:** Jingjing Wu, Xi Zhou, Xiaohong Li, Hao Liu, Meibin Qi, Richang Hong.<br />
  "Asymmetric Deformable Spatio-temporal Framework for Infrared Object Tracking." TOMM (2024).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3678882)] 
  [[code]( )]
  
- **ReFocus:** Simiao Lai, Chang Liu, Dong Wang, Huchuan Lu.<br />
  "Refocus the Attention for Parameter-Efficient Thermal Infrared Object Tracking." TNNLS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10601348)] 
  [[code](https://github.com/laisimiao/ReFocus_TIRTracking)]
  
- **FRTT:** Tianyang Xu, Yifan Pan, Zhenhua Feng, Xuefeng Zhu, Chunyang Cheng, Xiao-Jun Wu, Josef Kittler.<br />
  "Learning Feature Restoration Transformer for Robust Dehazing Visual Object Tracking." IJCV (2024).
  [[paper](https://link.springer.com/article/10.1007/s11263-024-02182-9)] 
  [[code]( )]

- **BDTrack:** You Wu, Xucheng Wang, Dan Zeng, Hengzhou Ye, Xiaolan Xie, Qijun Zhao, Shuiwang Li.<br />
  "Learning Motion Blur Robust Vision Transformers with Dynamic Early Exit for Real-Time UAV Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.05383)] 
  [[code](https://github.com/wuyou3474/BDTrack)]

- **NLMTrack:** Miao Yan, Ping Zhang, Haofei Zhang, Ruqian Hao, Juanxiu Liu, Xiaoyang Wang, Lin Liu.<br />
  "Enhancing Thermal Infrared Tracking with Natural Language Modeling and Coordinate Sequence Generation." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.08265)] 
  [[code](https://github.com/ELOESZHANG/NLMTrack)]

- **TRO:** Xiaoyu Guo, Pengzhi Zhong, Lizhi Lin, Hao Zhang, Ling Huang, Shuiwang Li.<br />
  "Tracking Reflected Objects: A Benchmark." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.05235)] 
  [[code](https://github.com/OpenCodeGithub/HIP-HaTrack)]

- **eMoE-Tracker:** Yucheng Chen, Lin Wang.<br />
  "eMoE-Tracker: Environmental MoE-based Transformer for Robust Event-guided Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.20024)] 
  [[code](https://vlislab22.github.io/eMoE-Tracker/)]
  
- **P2P:** Jiahao Nie, Fei Xie, Xueyi Zhou, Sifan Zhou, Zhiwei He, Dong-Kyu Chae.<br />
  "P2P: Part-to-Part Motion Cues Guide a Strong Tracking Framework for LiDAR Point Clouds." arxiv (2024).
  [[paper](https://arxiv.org/abs/2407.05238)] 
  [[code](https://github.com/haooozi/P2P)]
  
- **MDETrack:** Zhenyu Wei, Yujie He, Zhanchuan Cai.<br />
  "Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation Learning." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.14195)] 
  [[code](https://anonymous.4open.science/r/MDETrack)]

- **RGBS50:** Yunfeng Li, Bo Wang, Jiuran Sun, Xueyi Wu, Ye Li.<br />
  "RGB-Sonar Tracking Benchmark and Spatial Cross-Attention Transformer Tracker." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.07189)] 
  [[code](https://github.com/LiYunfengLYF/RGBS50)]

- **ViDSOD-100:** Junhao Lin, Lei Zhu, Jiaxing Shen, Huazhu Fu, Qing Zhang, Liansheng Wang.<br />
  "ViDSOD-100: A New Dataset and a Baseline Model for RGB-D Video Salient Object Detection." IJCV (2024).
  [[paper](https://arxiv.org/abs/2406.07189)] 
  [[code](https://github.com/jhl-Det/RGBD_Video_SOD)]

- **RGBT-Tiny:** Xinyi Ying, Chao Xiao, Ruojing Li, Xu He, Boyang Li, Zhaoxu Li, Yingqian Wang, Mingyuan Hu, Qingyu Xu, Zaiping Lin, Miao Li, Shilin Zhou, Wei An, Weidong Sheng, Li Liu.<br />
  "Visible-Thermal Tiny Object Detection: A Benchmark Dataset and Baselines." TPAMI (2025).
  [[paper](https://arxiv.org/abs/2406.14482)] 
  [[code](https://github.com/XinyiYing24/RGBT-Tiny)]

- **HGTM:** Qingyu Xu, Longguang Wang, Weidong Sheng, Yingqian Wang, Chao Xiao, Chao Ma, Wei An.<br />
  "Heterogeneous Graph Transformer for Multiple Tiny Object Tracking in RGB-T Videos." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10531011)] 
  [[code](https://github.com/xuqingyu26/HGTM)]
  
- **HSOD-BIT:** Haolin Qin, Tingfa Xu, Peifu Liu, Jingxuan Xu, Jianan Li.<br />
  "DMSSN: Distilled Mixed Spectral–Spatial Network for Hyperspectral Salient Object Detection." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10475351)] 
  [[code](https://github.com/anonymous0519/HSOD-BIT)]

- **QSFNet:** Liuxin Bao, Xiaofei Zhou, Xiankai Lu, Yaoqi Sun, Haibing Yin, Zhenghui Hu, Jiyong Zhang, Chenggang Yan.<br />
  "Quality-aware Selective Fusion Network for V-D-T Salient Object Detection." TIP (2024).
  [[paper](https://arxiv.org/abs/2405.07655)] 
  [[code](https://github.com/Lx-Bao/QSFNet)]

- **DWFPRNet:** Yi Luo, Feng Shao, Baoyang Mu, Hangwei Chen, Zhuo Li, Qiuping Jiang.<br />
  "Dynamic Weighted Fusion and Progressive Refinement Network for Visible-Depth-Thermal Salient Object Detection." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10556617)] 
  [[code]( )]
  
- **CRM:** Yuanliang Xue, Guodong Jin, Tao Shen, Lining Tan, Nian Wang, Jing Gao, Lianfeng Wang.<br />
  "Consistent Representation Mining for Multi-Drone Single Object Tracking." arxiv (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10551855)] 
  [[code](https://github.com/xyl-507/CRM)]
  
- **LaMOT:** Yunhao Li, Xiaoqiong Liu, Luke Liu, Heng Fan, Libo Zhang.<br />
  "LaMOT: Language-Guided Multi-Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.08324)] 
  [[code](https://github.com/Nathan-Li123/LaMOT)]

- **ABTrack:** Xiangyang Yang, Dan Zeng, Xucheng Wang, You Wu, Hengzhou Ye, Shuiwang Li.<br />
  "Adaptively Bypassing Vision Transformer Blocks for Efficient Visual Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2406.08037)] 
  [[code](https://github.com/1HykhqV3rU/ABTrack)]

- **XTrack:** Yuedong Tan, Zongwei Wu, Yuqian Fu, Zhuyun Zhou, Guolei Sun, Chao Ma, Danda Pani Paudel, Luc Van Gool, Radu Timofte.<br />
  "Towards a Generalist and Blind RGB-X Tracker." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.17773)] 
  [[code](https://github.com/supertyd/XTrack)]

- **PuTR:** Chongwei Liu, Haojie Li, Zhihui Wang, Rui Xu.<br />
  "PuTR: A Pure Transformer for Decoupled and Online Multi-Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.14119)] 
  [[code](https://github.com/chongweiliu/PuTR)]
  
- **LoReTrack:** Shaohua Dong, Yunhe Feng, Qing Yang, Yuewei Lin, Heng Fan.<br />
  "LoReTrack: Efficient and Accurate Low-Resolution Transformer Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.17660)] 
  [[code](https://github.com/ShaohuaDong2021/LoReTrack)]

- **TATrack:** Shuiwang Li, Xiangyang Yang, Xucheng Wang, Dan Zeng, Hengzhou Ye, Qijun Zhao.<br />
  "Learning Target-Aware Vision Transformers for Real-Time UAV Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10568178)] 
  [[code](https://github.com/xyyang317/TATrack)]

- **MATrack:** Guotian Zeng, Bi Zeng, Qingmao Wei, Huiting Hu, Hong Zhang.<br />
  "Visual Object Tracking with Mutual Affinity Aligned to Human Intuition." TMM (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10539277)] 
  [[code]( )]

- **SPOT:** Jilai Zheng, Wenxi Li, Chao Ma, Xiaokang Yang.<br />
  "Sparsely-Supervised Object Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10541917)] 
  [[code](https://github.com/VISION-SJTU/SPOT)]
  
- **BTSOT:** Omar Abdelaziz, Mohamed Shehata, Mohamed Mohamed.<br />
  "Beyond Traditional Single Object Tracking: A Survey." JMLC (2024).
  [[paper](https://arxiv.org/abs/2405.10439)] 
  [[code]( )]

- **RGBTSOT:** Mingzheng Feng, Jianbo Su.<br />
  "RGBT tracking: A comprehensive review." Information Fusion (2024).
  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253524002707)] 
  [[code]( )]

- **MMOT:** Chunhui Zhang, Li Liu, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "Awesome Multi-modal Object Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.14200)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]
  
- **QueryTrack:** Huijie Fan, Zhencheng Yu, Qiang Wang, Baojie Fan, Yandong Tang.<br />
  "QueryTrack: Joint-modality Query Fusion Network for RGBT Tracking." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10516307)] 
  [[code]( )]

- **AFter:** Andong Lu, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "AFter: Attention-based Fusion Router for RGBT Tracking." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.02717)] 
  [[code](https://github.com/Alexadlu/AFter)]
  
- **MoETrack:** Zhangyong Tang, Tianyang Xu, Zhenhua Feng, Xuefeng Zhu, He Wang, Pengcheng Shao, Chunyang Cheng, Xiao-Jun Wu, Muhammad Awais, Sara Atito, Josef Kittler.<br />
  "Revisiting RGBT Tracking Benchmarks from the Perspective of Modality Validity: A New Benchmark, Problem, and Method." arxiv (2024).
  [[paper](https://arxiv.org/abs/2405.00168)] 
  [[code](https://github.com/Zhangyong-Tang/MoETrack)]
  
- **PromptVT:** Minghua Zhang, Qiuyang Zhang, Wei Song, Dongmei Huang, Qi He.<br />
  "PromptVT: Prompting for Efficient and Accurate Visual Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10468656)] 
  [[code](https://github.com/faicaiwawa/PromptVT)]

- **MobileSiam-LT:** Xin Yang, Jinxiang Huang, Yizhao Liao, Yong Song, Ya Zhou, Jinqi Yang.<br />
  "Light Siamese Network for Long-term Onboard Aerial Tracking." TGRS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10521630)] 
  [[code](https://github.com/YoungZnBIT/PySOT-trial)]
  
- **CrossEI:** Zhiwen Chen, Jinjian Wu, Weisheng Dong, Leida Li, Guangming Shi.<br />
  "CrossEI: Boosting Motion-oriented Object Tracking with An Event Camera." TIP (2024).
  [[paper](https://ieeexplore.ieee.org/document/10776574)] 
  [[code]( )]

- **Mamba-FETrack:** Ju Huang, Shiao Wang, Shuai Wang, Zhe Wu, Xiao Wang, Bo Jiang.<br />
  "Mamba-FETrack: Frame-Event Tracking via State Space Model." arxiv (2024).
  [[paper](https://arxiv.org/abs/2404.18174)] 
  [[code](https://github.com/Event-AHU/Mamba_FETrack)]

- **AttMOT:** Yunhao Li, Zhen Xiao, Lin Yang, Dan Meng, Xin Zhou, Heng Fan, Libo Zhang.<br />
  "AttMOT: Improving Multiple-Object Tracking by Introducing Auxiliary Pedestrian Attributes." TNNLS (2024).
  [[paper](https://arxiv.org/abs/2308.07537)] 
  [[code]()]

- **PillarTrack:** Weisheng Xu, Sifan Zhou, Zhihang Yuan.<br />
  "PillarTrack: Redesigning Pillar-based Transformer Network for Single Object Tracking on Point Clouds." arxiv (2024).
  [[paper](https://arxiv.org/abs/2404.07495)] 
  [[code](https://github.com/StiphyJay/PillarTrack)]

- **EasyTrack:** Baojie Fan, Wuyang Zhou, Kai Wang, Shijun Zhou, Fengyu Xu, Jiandong Tian.<br />
  "EasyTrack: Efficient and Compact One-stream 3D Point Clouds Tracker." arxiv (2024).
  [[paper](https://arxiv.org/abs/2404.05960)] 
  [[code](https://github.com/KnightApple427/Easytrack)]

- **Anti-UAV410:** Bo Huang, Jianan Li, Junjie Chen, Gang Wang, Jian Zhao, Tingfa Xu.<br />
  "Anti-UAV410: A Thermal Infrared Benchmark and Customized Scheme for Tracking Drones in the Wild." TPAMI (2024).
  [[paper](https://ieeexplore.ieee.org/document/10325629)] 
  [[code](https://github.com/HwangBo94/Anti-UAV410)]

- **RTSformer:** Fengwei Gu, Jun Lu, Chengtao Cai, Qidan Zhu, Zhaojie Ju.<br />
  "RTSformer: A Robust Toroidal Transformer With Spatiotemporal Features for Visual Tracking." THMS (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10474210)] 
  [[code]( )]

- **TSF-SiamMU:** Weijie Yan, Guohua Gu, Yunkai Xu, Xiaofang Kong, Ajun Shao, Qian Chen.<br />
  "Twofold Structured Features-Based Siamese Network for Infrared Target Tracking." TCSS (2024).
  [[paper](https://ieeexplore.ieee.org/document/10530921)] 
  [[code]( )]

- **GAA:** Mingyang Lei, Hong Song, Jingfan Fan, Deqiang Xiao, Danni Ai, Ying Gu, Jian Yang.<br />
  "GAA: Ghost Adversarial Attack for Object Tracking." TETCI (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10466775)] 
  [[code]( )]

- **Sigma:** Zifu Wan, Yuhao Wang, Silong Yong, Pingping Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie.<br />
  "Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2404.04256)] 
  [[code](https://github.com/zifuwan/Sigma)]

- **CaDeX++:** Yunzhou Song, Jiahui Lei, Ziyun Wang, Lingjie Liu, Kostas Daniilidis.<br />
  "Track Everything Everywhere Fast and Robustly." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.17931)] 
  [[code](https://timsong412.github.io/FastOmniTrack/)]
  
- **MPLKD:** Yang Luo, Xiqing Guo, Hao Li.<br />
  "From Two Stream to One Stream: Efficient RGB-T Tracking via Mutual Prompt Learning and Knowledge Distillation." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.16834)] 
  [[code](https://github.com/)]

- **MAPNet:** Xinglong Sun, Haijiang Sun, Shan Jiang, Jiacheng Wang, Xilai Wei, Zhonghe Hu.<br />
  "Multi-attention Associate Prediction Network for Visual Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.16395)] 
  [[code]( )]
  
- **ACTrack:** Yushan Han, Kaer Huang.<br />
  "ACTrack: Adding Spatio-Temporal Condition for Visual Object Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2403.07914)] 
  [[code]( )]
  
- **MT-Track :** Xiaoying Yuan, Tingfa Xu, Xincong Liu, Ying Wang, Haolin Qin, Yuqiang Fang, Jianan Li.<br />
  "Multi-step Temporal Modeling for UAV Tracking." TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/document/10464358/)] 
  [[code]( )]

- **OIFTrack:** Janani Kugarajeevan, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando.<br />
  "Optimized Information Flow for Transformer Tracking." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2402.08195)] 
  [[code](https://github.com/JananiKugaa/OIFTrack)]

- **SuperSBT:** Fei Xie, Wankou Yang, Chunyu Wang, Lei Chu, Yue Cao, Chao Ma, Wenjun Zeng.<br />
  "Correlation-Embedded Transformer Tracking: A Single-Branch Framework." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2401.12743)] 
  [[code](https://github.com/phiphiphi31/SBT)]
  

### NeurIPS 2023

- **MixFormerV2:** Yutao Cui, Tianhui Song, Gangshan Wu, Limin Wang.<br />
  "MixFormerV2: Efficient Fully Transformer Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2305.15896)] 
  [[code](https://github.com/MCG-NJU/MixFormerV2)]

- **RFGM:** Xinyu Zhou, Pinxue Guo, Lingyi Hong, Jinglun Li, Wei Zhang, Weifeng Ge, Wenqiang Zhang.<br />
  "Reading Relevant Feature from Global Representation Memory for Visual Object Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2402.14392)] 
  [[code]( )]
  
- **BadTrack:** Bin Huang, Jiaqian Yu, Yiwei Chen, Siyang Pan, Qiang Wang, Zhi Wang.<br />
  "BadTrack: A Poison-Only Backdoor Attack on Visual Object Tracking." NeurIPS (2023).
  [[paper](https://proceedings.neurips.cc//paper_files/paper/2023/hash/828bb8f42d4ab15322b9315151959c61-Abstract-Conference.html)] 
  [[code]( )]

- **ZoomTrack:** Yutong Kou, Jin Gao, Bing Li, Gang Wang, Weiming Hu, Yizheng Wang, Liang Li.<br />
  "ZoomTrack: Target-aware Non-uniform Resizing for Efficient Visual Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2310.10071)] 
  [[code](https://github.com/Kou-99/ZoomTrack)]

- **Type-to-Track:** Pha Nguyen, Kha Gia Quach, Kris Kitani, Khoa Luu.<br />
  "Type-to-Track: Retrieve Any Object via Prompt-based Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2305.13495)] 
  [[code](https://uark-cviu.github.io/Type-to-Track)]

- **MGIT:** Shiyu Hu, Dailin Zhang, Meiqi Wu, Xiaokun Feng, Xuchen Li, Xin Zhao, Kaiqi Huang.<br />
  "A Multi-modal Global Instance Tracking Benchmark (MGIT): Better Locating Target in Complex Spatio-temporal and Causal Relationship." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/xxxxx.xx)] 
  [[code](http://videocube.aitestunion.com/)]


### ICCV 2023

- **VTDNet:** Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu.<br />
  "Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving." ICCV (2023).
  [[paper](https://arxiv.org/abs/2309.04422)] 
  [[code](https://www.vis.xyz/pub/vtd)]
  
- **HiT:** Ben Kang, Xin Chen, Dong Wang, Houwen Peng, Huchuan Lu.<br />
  "Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.06904)] 
  [[code](https://github.com/kangben258/HiT)]

- **ROMTrack:** Yidong Cai, Jie Liu, Jie Tang, Gangshan Wu.<br />
  "Robust Object Modeling for Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.05140)] 
  [[code](https://github.com/dawnyc/ROMTrack)]

- **F-BDMTrack:** Dawei Yang, Jianfeng He, Yinchao Ma, Qianjin Yu, Tianzhu Zhang.<br />
  "Foreground-Background Distribution Modeling Transformer for Visual Object Tracking." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf)] 
  [[code]()]

- **MITS:** Yuanyou Xu, Zongxin Yang, Yi Yang.<br />
  "Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual Tracking and Segmentation." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/yoxu515/MITS)]

- **Aba-ViTrack:** Shuiwang Li, Yangxiang Yang, Dan Zeng, Xucheng Wang.<br />
  "Adaptive and Background-Aware Vision Transformer for Real-Time UAV Tracking." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/xyyang317/Aba-ViTrack)]
  
- **Omnimotion:** Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath Hariharan, Aleksander Holynski, Noah Snavely.<br />
  "Tracking Everything Everywhere All at Once." ICCV (2023).
  [[paper](https://arxiv.org/abs/2306.05422)] 
  [[code](https://omnimotion.github.io/)]
  
- **DEVA:** Ho Kei Cheng, Seoung Wug Oh, Brian Price, Alexander Schwing, Joon-Young Lee.<br />
  "Tracking Anything with Decoupled Video Segmentation." ICCV (2023).
  [[paper](https://arxiv.org/abs/2309.03903)] 
  [[code](https://hkchengrex.github.io/Tracking-Anything-with-DEVA)]

- **CiteTracker:** Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "CiteTracker: Correlating Image and Text for Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.11322)] 
  [[code](https://github.com/xinli/citetracker)]

- **DecoupleTNL:** Ding Ma, Xiangqian Wu.<br />
  "Tracking by Natural Language Specification with Long Short-term Context Decoupling." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf)] 
  [[code]()]
  
- **PVT++:** Bowen Li, Ziyuan Huang, Junjie Ye, Yiming Li, Sebastian Scherer, Hang Zhao, Changhong Fu.<br />
  "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework." ICCV (2023).
  [[paper](https://arxiv.org/abs/2211.11629)] 
  [[code](https://github.com/Jaraxxus-Me/PVT_pp)]

- **COHA:** Zhiyu Zhu, Junhui Hou, Dapeng Oliver Wu.<br />
  "Cross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers." ICCV (2023).
  [[paper](https://arxiv.org/abs/2307.04129)] 
  [[code](https://github.com/ZHU-Zhiyu/High-Rank_RGB-Event_Tracker)]

- **SyncTrack:** Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu.<br />
  "Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.12549)] 
  [[code](https://xxxxx)]
  
- **360VOT:** Huajian Huang, Yinzhe Xu, Yingshu Chen, Sai-Kit Yeung.<br />
  "360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2307.14630)] 
  [[code](https://360vot.hkustvgd.com/)]

- **PlanarTrack:** Xinran Liu, Xiaoqiong Liu, Ziruo Yi, Xin Zhou, Thanh Le, Libo Zhang, Yan Huang, Qing Yang, Heng Fan.<br />
  "PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2303.07625)] 
  [[code](https://hengfan2010.github.io/projects/PlanarTrack/)]
       
### CVPR 2023

- **X-Decoder:** Xueyan Zou, Zi-Yi Dou, Jianwei Yang, Zhe Gan, Linjie Li, Chunyuan Li, Xiyang Dai, Harkirat Behl, Jianfeng Wang, Lu Yuan, Nanyun Peng, Lijuan Wang, Yong Jae Lee, Jianfeng Gao.<br />
  "Generalized Decoding for Pixel, Image, and Language." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.11270)] 
  [[code](https://x-decoder-vl.github.io/)]
  
- **UNINEXT:** Bin Yan, Yi Jiang, Jiannan Wu, Dong Wang, Ping Luo, Zuhuan Yuan, Huchuan Lu.<br />
  "Universial Instance Perception as Object Discovery and Retrieval." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.06674)] 
  [[code](https://github.com/MasterBin-IIAU/UNINEXT)]
  
- **OmniTracker:** Junke Wang, Dongdong Chen, Zuxuan Wu, Chong Luo, Xiyang Dai, Lu Yuan, Yu-Gang Jiang.<br />
  "OmniTracker: Unifying Object Tracking by Tracking-with-Detection." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12079)] 
  [[code](https://github.com/)]

- **SUSHI:** Orcun Cetintas, Guillem Brasó, Laura Leal-Taixé.<br />
  "Unifying Short and Long-Term Tracking with Graph Hierarchies." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.03038)] 
  [[code](https://github.com/dvl-tum/SUSHI)]
  
- **DropMAE:** Qiangqiang Wu, Tianyu Yang, Ziquan Liu, Baoyuan Wu, Ying Shan, Antoni B. Chan.<br />
  "DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.00571)] 
  [[code](https://github.com/jimmy-dq/DropMAE)]
  
- **VideoTrack:** Fei Xie, Lei Chu, Jiahao Li, Yan Lu, Chao Ma.<br />
  "VideoTrack: Learning to Track Objects via Video Transformer." CVPR (2023).
  [[paper](https://arxiv.org/abs/x)] 
  [[code](https://github.com/phiphiphi31/VideoTrack)]
  
- **SwinV2:** Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, Yue Cao.<br />
  "Revealing the Dark Secrets of Masked Image Modeling." CVPR (2023).
  [[paper](https://arxiv.org/abs/2205.13543)] 
  [[code](https://github.com/SwinTransformer/MIM-Depth-Estimation)]
  
- **ViPT:** Jiawen Zhu, Simiao Lai, Xin Chen, Dong Wang, Huchuan Lu.<br />
  "Visual Prompt Multi-Modal Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.10826)] 
  [[code](https://github.com/jiawen-zhu/ViPT)]
  
 - **JointNLT:** Li Zhou, Zikun Zhou, Kaige Mao, Zhenyu He.<br />
  "Joint Visual Grounding and Tracking with Natural Language Specification." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12027)] 
  [[code](https://github.com/lizhou-cs/JointNLT)]
  
 - **ARKitTrack:** Haojie Zhao, Junsong Chen, Lijun Wang, Huchuan Lu.<br />
  "ARKitTrack: A New Diverse Dataset for Tracking Using Mobile RGB-D Data." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.13885)] 
  [[code](https://arkittrack.github.io/)]
  
 - **GRM:** Shenyuan Gao, Chunluan Zhou, Jun Zhang.<br />
  "Generalized Relation Modeling for Transformer Tracking." CVPR (2023).
  [[paper](https://arxiv.org/pdf/2303.16580v1.pdf)] 
  [[code](https://github.com/Little-Podi/GRM)]
  
 - **ARTrack:** Xing Wei, Yifan Bai, Yongchao Zheng, Dahu Shi, Yihong Gong.<br />
  "Autoregressive Visual Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/MIV-XJTU/ARTrack)]
  
 - **MAT:** Haojie Zhao, Dong Wang, Huchuan Lu.<br />
  "Representation Learning for Visual Object Tracking by Masked Appearance Transfer." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Representation_Learning_for_Visual_Object_Tracking_by_Masked_Appearance_Transfer_CVPR_2023_paper.html)] 
  [[code](https://github.com/difhnp/MAT)]
  
 - **EMT:** Jinyu Yang, Shang Gao, Zhe Li, Feng Zheng, Aleš Leonardis.<br />
  "Resource-Efficient RGBD Aerial Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Resource-Efficient_RGBD_Aerial_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/yjybuaa/RGBDAerialTracking)]
  
 - **TBSI:** Tianrui Hui, Zizheng Xun, Fengguang Peng, Junshi Huang, Xiaoming Wei, Xiaolin Wei, Jiao Dai, Jizhong Han, Si Liu.<br />
  "Bridging Search Region Interaction With Template for RGB-T Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hui_Bridging_Search_Region_Interaction_With_Template_for_RGB-T_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/RyanHTR/TBSI)]
  
 - **VisTracker:** Xianghui Xie, Bharat Lal Bhatnagar, Gerard Pons-Moll.<br />
  "Visibility Aware Human-Object Interaction Tracking from Single RGB Camera." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.16479v1)] 
  [[code](https://virtualhumans.mpi-inf.mpg.de/VisTracker/)]
  
 - **OVTrack:** Siyuan Li, Tobias Fischer, Lei Ke, Henghui Ding, Martin Danelljan, Fisher Yu.<br />
  "OVTrack: Open-Vocabulary Multiple Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.08408)] 
  [[code](https://www.vis.xyz/pub/ovtrack/)]
  
 - **SeqTrack:** Xin Chen, Houwen Peng, Dong Wang, Huchuan Lu, Han Hu.<br />
  "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.14394)] 
  [[code](https://github.com/microsoft/VideoX)]
  
 - **ImageBind:** Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra.<br />
  "IMAGEBIND: One Embedding Space To Bind Them All." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.05665)] 
  [[code](https://github.com/facebookresearch/ImageBind)]
  
 - **TCOW:** Basile Van Hoorick, Pavel Tokmakov, Simon Stent, Jie Li, Carl Vondrick.<br />
  "Tracking through Containers and Occluders in the Wild." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.03052)] 
  [[code](https://tcow.cs.columbia.edu/)]
  

### ACM MM 2023

- **SimOWT:** Bingyang Wang, Tanlin Li, Jiannan Wu, Yi Jiang, Huchuan Lu, You He.<br />
  "A Simple Baseline for Open-World Tracking via Self-training." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3611695)] 
  [[code](https://github.com/22109095/SimOWT)]

- **UTrack:** Jie Gao, Bineng Zhong, Yan Chen.<br />
  "Unambiguous Object Tracking by Exploiting Target Cues." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3612240)] 
  [[code]()]

- **PDST:** Jinpu Zhang, Ziwen Li, Ruonan Wei, Yuehuan Wang.<br />
  "Progressive Domain-style Translation for Nighttime Tracking." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3612305)] 
  [[code]()]
  
- **All-in-One:** Chunhui Zhang, Xin Sun, Li Liu, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang.<br />
  "All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment." ACM MM (2023).
  [[paper](https://arxiv.org/abs/2307.03373)] 
  [[code]( )]
  

### ArXiV 2023

- **LaTOT/MKDNet:** Yabin Zhu, Chenglong Li, Yao Liu, Xiao Wang, Jin Tang, Bin Luo, Zhixiang Huang.<br />
  "Tiny Object Tracking: A Large-scale Dataset and A Baseline." TNNLS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10035907)] 
  [[code](https://github.com/mmic-lcl/Datasets-and-benchmark-code)]

- **UPVPT:** Guangtong Zhang, Qihua Liang, Ning Li, Zhiyi Mo, Bineng Zhong.<br />
  "Robust Tracking via Unifying Pretrain-Finetuning and Visual Prompt Tuning." ACM MMAsia (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3595916.3626410)] 
  [[code]()]

- **TAO-Amodal:** Cheng-Yen Hsieh, Tarasha Khurana, Achal Dave, Deva Ramanan.<br />
  "Tracking Any Object Amodally." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2312.12433)] 
  [[code](https://tao-amodal.github.io/)]

- **HQTrack:** Jiawen Zhu, Zhenyu Chen, Zeqi Hao, Shijie Chang, Lu Zhang, Dong Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Hanyuan Chen, Chenyang Li.<br />
  "Tracking Anything in High Quality." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.13974)] 
  [[code](https://github.com/jiawen-zhu/HQTrack)]

- **SATracker:** Jiawei Ge, Xiangmei Chen, Jiuxin Cao, Xuelin Zhu, Weijia Liu, Bo Liu.<br />
  "Beyond Visual Cues: Synchronously Exploring Target-Centric Semantics for Vision-Language Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2311.17085)] 
  [[code]( )]

- **PSTM:** Zechu Zhou, Xinyu Zhou, Zhaoyu Chen, Pinxue Guo, Qian-Yu Liu, Wenqiang Zhang.<br />
  "Memory Network With Pixel-Level Spatio-Temporal Learning for Visual Object Tracking." TCSVT (2023).
  [[paper](https://ieeexplore.ieee.org/document/10114400)] 
  [[code]( )]

- **TransMDOT:** Guanlin Chen, Pengfei Zhu, Bing Cao, Xing Wang, Qinghua Hu.<br />
  "Cross-Drone Transformer Network for Robust Single Object Tracking." TCSVT (2023).
  [[paper](https://ieeexplore.ieee.org/document/10144283)] 
  [[code](https://github.com/cgjacklin/transmdot)]

- **MIA-Net:** Zhihao Liu, Yuanyuan Shang, Timing Li, Guanlin Chen, Yu Wang, Qinghua Hu.<br />
  "Robust Multi-Drone Multi-Target Tracking to Resolve Target Occlusion: A Benchmark." TMM (2023).
  [[paper](https://ieeexplore.ieee.org/document/10008047)] 
  [[code](https://github.com/VisDrone/Multi-Drone-Multi-Object-Detection-and-Tracking)]

- **PlugAtt:** Shaochuan Zhao, Tianyang Xu, Xiao-Jun Wu, Josef Kittler.<br />
  "Pluggable Attack for Visual Object Tracking." TIFS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10316262)] 
  [[code]( )]

- **FFTrack:** Xiantao Hu. Bineng Zhong. Qihua Liang. Shengping Zhang. Ning Li. Xianxian Li.<br />
  "Transformer Tracking via Frequency Fusion." TCSVT (2023).
  [[paper](https://ieeexplore.ieee.org/document/10163861)] 
  [[code]( )]

- **MMTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Guorong Li, Rongrong Ji, Xianxian Li.<br />
  "Towards Unified Token Learning for Vision-Language Tracking." TCSVT (2023).
  [[paper](https://arxiv.org/abs/2308.14103)] 
  [[code](https://github.com/Azong-HQU/MMTrack)]

- **OVLM:** Huanlong Zhang, Jingchao Wang, Jianwei Zhang, Tianzhu Zhang, Bineng Zhong.<br />
  "One-stream Vision-Language Memory Network for Object Tracking." TMM (2023).
  [[paper](https://ieeexplore.ieee.org/document/10149530)] 
  [[code]( )]
  
- **MPLT:** Yang Luo, Xiqing Guo, Hui Feng, Lei Ao.<br />
  "RGB-T Tracking via Multi-Modal Mutual Prompt Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2308.16386)] 
  [[code](https://github.com/HusterYoung/MPLT)]

- **CycleTrack:** Chuanming Tang, Kai Wang, Joost van de Weijer, Jianlin Zhang, Yongmei Huang.<br />
  "Exploiting Image-Related Inductive Biases in Single-Branch Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2310.19542)] 
  [[code](https://xxx)]
  
- **DCPT:** Jiawen Zhu, Huayi Tang, Zhi-Qi Cheng, Jun-Yan He, Bin Luo, Shihao Qiu, Shengming Li, Huchuan Lu.<br />
  "DCPT: Darkness Clue-Prompted Tracking in Nighttime UAVs." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.10491)] 
  [[code](https://xxx)]

- **SRT:** Tianpeng Liu, Jing Li, Jia Wu, Lefei Zhang, Jun Chang, Jun Wan, Lezhi Lian.<br />
  "Tracking with Saliency Region Transformer." TIP (2023).
  [[paper](https://ieeexplore.ieee.org/document/10359476)] 
  [[code](https://github.xxxxx)]

- **TATrans:** Pujian Lai, Meili Zhang, Gong Cheng, Shengyang Li, Xiankai Huang, Junwei Han.<br />
  "Target-aware Transformer for Satellite Video Object Tracking." TGRS (2023).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10342836)] 
  [[code](https://github.com/laybebe/TATrans_SVOT)]

- **STRtrack:** Shaochuan Zhao, Tianyang Xu, Xiaojun Wu, Josef Kittler.<br />
  "A Spatio-Temporal Robust Tracker with Spatial-Channel Transformer and Jitter Suppression." IJCV (2023).
  [[paper](https://link.springer.com/article/10.1007/s11263-023-01902-x)] 
  [[code](https://xxx)]

- **CoTracker:** Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht.<br />
  "CoTracker: It is Better to Track Together." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.07635)] 
  [[code](https://co-tracker.github.io/)]
  
- **LiteTrack:** Qingmao Wei, Bi Zeng, Jianqi Liu, Li He, Guotian Zeng.<br />
  "LiteTrack: Layer Pruning with Asynchronous Feature Extraction for Lightweight and Efficient Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.09249)] 
  [[code](https://github.com/TsingWei/LiteTrack)]
  
- **LightFC:** Li Yunfeng, Wang Bo, Li Ye, Liu Zhuoyan, Wu Xueyi.<br />
  "Lightweight Full-Convolutional Siamese Tracker." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2310.05392)] 
  [[code](https://github.com/LiYunfengLYF/LightFC)]

- **DETRrack:** Qingmao Wei, Bi Zeng, Guotian Zeng.<br />
  "Efficient Training for Visual Tracking with Deformable Transformer." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.02676)] 
  [[code](https:xxx)]

- **JN:** Qingmao Wei, Bi Zeng, Guotian Zeng.<br />
  "Towards Efficient Training with Negative Samples in Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.02903)] 
  [[code](hxx)]
  
- **P3DTrack:** Jiawei He, Lue Fan, Yuqi Wang, Yuntao Chen, Zehao Huang, Naiyan Wang, Zhaoxiang Zhang.<br />
  "Tracking Objects with 3D Representation from Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05416)] 
  [[code](https:/xx)]
  
- **SAM-DA:** Liangliang Yao, Haobo Zuo, Guangze Zheng, Changhong Fu, Jia Pan.<br />
  "SAM-DA: UAV Tracks Angthing at Night with SAM-Powered Domain Adaptation." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.01024)] 
  [[code](https:/github.com/vision4robotics/sam-da)]
  
- **SparseTrack:** Zelin Liu, Xinggang Wang, Cheng Wang, Wenyu Liu, Xiang Bai.<br />
  "SparseTrack: Multi-Object Tracking by Performing Scene Decomposition based on Pseudo-Depth." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05238)] 
  [[code](https://github.com/hustvl/SparseTrack)]
  
- **MACFT:** Yang Luo, Xiqing Guo, Mingtao Dong, Jin Yu.<br />
  "RGB-T Tracking Based on Mixed Attention." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.04264)] 
  [[code](https:/xx)]
  
- **AFNet:** Jiqing Zhang, Yuanchen Wang, Wenxi Liu, Meng Li, Jinpeng Bai, Baocai Yin, Xin Yang.<br />
  "Frame-Event Alignment and Fusion Network for High Frame Rate Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.15688)] 
  [[code](https:/xx)]
  
- **MFT:** Michal Neoral, Jonáš Šerých, Jiří Matas.<br />
  "MFT: Long-Term Tracking of Every Pixel." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.12998)] 
  [[code](https:/xx)]
  
- **S3Track:** Fatemeh Azimi, Fahim Mannan, Felix Heide.<br />
  "S3Track: Self-supervised Tracking with Soft Assignment Flow." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.09981)] 
  [[code](https:/xx)]
    
- **TransSOT:** Janani Thangavel, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando.<br />
  "Transformers in Single Object Tracking: An Experimental Survey." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2302.11867)] 
  [[code]()]
  
- **ProFormer:** Yabin Zhu, Chenglong Li, Xiao Wang, Jin Tang, Zhixiang Huang.<br />
  "RGBT Tracking via Progressive Fusion Transformer with Dynamically Guided Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2303.14778)] 
  [[code]()]
  
- **SiamTHN:** Jiahao Bao, Kaiqiang Chen, Xian Sun, Liangjin Zhao, Wenhui Diao, Menglong Yan.<br />
  "SiamTHN: Siamese Target Highlight Network for Visual Tracking." TCSVT (2023).
  [[paper](https://arxiv.org/abs/2303.12304)] 
  [[code]()]

- **SOTVerse:** Shiyu Hu, Xin Zhao, Kaiqi Huang.<br />
  "SOTVerse: A User-defined Task Space of Single Object Tracking." IJCV (2023).
  [[paper](https://arxiv.org/abs/2204.07414)] 
  [[code](http://metaverse.aitestunion.com/sotverse)]

- **TSMTrack:** Chuanming Tang, Qintao Hu, Gaofan Zhou, Jinzhen Yao, Jianlin Zhang, Yongmei Huang, Qixiang Ye.<br />
  "Transformer Sub-Patch Matching for High-Performance Visual Object Tracking." TITS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10101686)] 
  [[code](https:/xx)]

- **TADS:** Xin Li, Wenjie Pei, Yaowei Wang, Zhenyu He, Huchuan Lu, Ming-Hsuan Yang.<br />
  "Self-Supervised Tracking via Target-Aware Data Synthesis." TNNLS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10004981)] 
  [[code]()]
  
- **Diffusion Init:** Renjie Wang, Tianyang Xu, Shaochuan Zhao, Xiao-Jun Wu, Josef Kittler.<br />
  "Diffusion Init: Stronger Initialisation of Decision-Based Black-Box Attacks for Visual Object Tracking." ACPR (2023).
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-47637-2_28)] 
  [[code]( )]

- **TAT:** Ziyi Cheng, Baoyuan Wu, Zhenya Zhang, Jianjun Zhao.<br />
  "TAT: Targeted Backdoor Attacks Against Visual Object Tracking." PR (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320323003308?via%3Dihub)] 
  [[code](https://github.com/MisakaZipi/TAT)]

- **SRNet:** Nana Fan, Qiao Liu, Xin Li, Zikun Zhou, Zhenyu He.<br />
  "Siamese Residual Network for Efficient Visual Tracking." Information Sciences (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0020025522015778?via%3Dihub)] 
  [[code]()]

### IJCAI 2023

- **OSP2B:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Zhengyi Bao, Mingyu Gao, Jing Zhang.<br />
  "OSP2B: One-Stage Point-to-Box Network for 3D Siamese Tracking." IJCAI (2023).
  [[paper](https://arxiv.org/abs/2304.11584)] 
  [[code](https://github.com/HaozheQi/P2B)]
  
  
### ICRA 2023

- **SGDViT:** Liangliang Yao, Changhong Fu, Sihang Li, Guangze Zheng, Junjie Ye.<br />
  "SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking." ICRA (2023).
  [[paper](https://arxiv.org/abs/2303.04378v1)] 
  [[code](https://github.com/vision4robotics/SGDViT)]
  
- **ClimRT:** Changhong Fu, Mutian Cai, Sihang Li, Kunhan Lu, Haobo Zuo, Chongjun Liu.<br />
  "Continuity-Aware Latent Interframe Information Mining for Reliable UAV Tracking." ICRA (2023).
  [[paper](https://arxiv.org/abs/2303.04525v1)] 
  [[code](https://github.com/vision4robotics/ClimRT)]
  
### IROS 2023

- **TOTEM:** Kalyan Garigapati, Erik Blasch, Jie Wei, Haibin Ling.<br />
  "Transparent Object Tracking with Enhanced Fusion Module." IROS (2023).
  [[paper](https://arxiv.org/abs/2309.06701)] 
  [[code](https://github.com/kalyan0510/TOTEM)]

- **CDT:** Kunhan Lu, Changhong Fu, Yucheng Wang, Haobo Zuo, Guangze Zheng, and Jia Pan.<br />
  "Cascaded Denoising Transformer for UAV Nighttime Tracking." RAL (2023).
  [[paper](https://arxiv.org/xxxx)] 
  [[code](https://github.com/vision4robotics/CDT)]
  
- **TRTrack:** Sihang Li, Changhong Fu.<br />
  "TRTrack: Boosting UAV Object Tracking with Voxel-based Trajectory-aware Reconstruction Training." IROS (2023).
  [[paper](https://arxiv.org/abs/xxxx)] 
  [[code](https://github.com/vision4robotics/TRTrack)]
  
### WACV 2023

- **MVT:** Goutam Yelluru Gopal, Maria A. Amer.<br />
  "Mobile Vision Transformer-based Visual Object Tracking." BMVC (2023).
  [[paper](https://arxiv.org/abs/2309.05829)] 
  [[code](https://github.com/goutamyg/MVT)]
  
- **E.T.Track:** Philippe Blatter, Menelaos Kanakis, Martin Danelljan, Luc Van Gool.<br />
  "Efficient Visual Tracking with Exemplar Transformers." WACV (2023).
  [[paper](https://arxiv.org/abs/2112.09686)] 
  [[code](https://github.com/pblatter/ettrack)]
  

### AAAI 2023

- **CTTrack:** Zikai Song, Run Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Compact Transformer Tracker with Correlative Masked Modeling." AAAI (2023).
  [[paper](https://arxiv.org/abs/2301.10938)] 
  [[code](https://github.com/HUSTDML/CTTrack)]
  
- **TATrack:** Kaijie He, Canlong Zhang, Sheng Xie, Zhixin Li, Zhiwen Wang.<br />
  "Target-Aware Tracking with Long-term Context Attention." AAAI (2023).
  [[paper](https://arxiv.org/abs/2302.13840)] 
  [[code](https://github.com/hekaijie123/TATrack)]
  
- **RGBD1K:** Xue-Feng Zhu, Tianyang Xu, Zhangyong Tang, Zucheng Wu, Haodong Liu, Xiao Yang, Xiao-Jun Wu, Josef Kittler.<br />
  "RGBD1K: A Large-scale Dataset and Benchmark for RGB-D Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2208.09787)] 
  [[code](https://github.com/xuefeng-zhu5/RGBD1K)]

- **GdaTFT:** Yun Liang; Qiaoqiao Li; Fumian Long.<br />
  "Global Dilated Attention and Target Focusing Network for Robust Tracking." AAAI (2023).
  [[paper](https://underline.io/lecture/69278-global-dilated-attention-and-target-focusing-network-for-robust-tracking)] 
  [[code](https://github.com/)]
  
- **GLT-T:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Mingyu Gao, Jing Zhang.<br />
  "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds." AAAI (2023).
  [[paper](https://arxiv.org/abs/2211.10927)] 
  [[extended](https://arxiv.org/abs/2304.00242)] 
  [[code](https://github.com/haooozi/GLT-T)]
  
- **RSPT:** Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang, Yizhou Wang.<br />
  "RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2304.03623)] 
  [[code](https://sites.google.com/view/aot-rspt)]


### NeurIPS 2022

- **SwinTrack:** Liting Lin, Heng Fan, Yong Xu, Haibin Ling.<br />
  "SwinTrack: A Simple and Strong Baseline for Transformer Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2112.00995)] 
  [[code](https://github.com/LitingLin/SwinTrack)]
  
- **VLTrack:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing.<br />
  "Divert More Attention to Vision-Language Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2207.01076)] 
  [[code](https://github.com/JudasDie/SOTS)]
  
- **GKB:** Zhiyu Zhu, Junhui Hou, Xianqiang Lyu.<br />
  "Leaning Graph-embedded Key-event Back-tracing for Object Tracking in Event Clouds." NeurIPS (2022).
  [[paper](https://nips.cc/Conferences/2022/Schedule?showEvent=54651)] 
  [[code](https://github.com/ZHU-Zhiyu/Event-tracking)]
  
- **TAP-Vid:** Carl Doersch, Ankush Gupta, Larisa Markeeva, Lucas Smaira, Yusuf Aytar, Andrew Zisserman, Yi Yang.<br />
  "TAP-Vid: A Benchmark for Tracking Any Point in a Video." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2211.03726)] 
  [[code](https://github.com/deepmind/tapnet)]

  
### ECCV 2022

- **OSTrack:** Botao Ye, Hong Chang, Bingpeng Ma, Shiguang Shan.<br />
  "Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11991)] 
  [[code](https://github.com/botaoye/OSTrack)]
  
- **Unicorn:** Bin Yan, Yi Jiang, Peize Sun, Dong Wang, Zehuan Yuan, Ping Luo, Huchuan Lu.<br />
  "Unicorn: Towards Grand Unification of Object Tracking." ECCV (2022) Oral.
  [[paper](https://arxiv.org/abs/2207.07078)] 
  [[code](https://github.com/MasterBin-IIAU/Unicorn)]
  
- **SimTrack:** Boyu Chen, Peixia Li, Lei Bai, Lei Qiao, Qiuhong Shen, Bo Li, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.05328)] 
  [[code](https://github.com/LPXTT/SimTrack)]
  
- **CIA:** Zhixiong Pi, Weitao Wan, Chong Sun, Changxin Gao, Nong Sang, Chen Li.<br />
  "Hierarchical Feature Embedding for Visual Tracking." ECCV (2022).
  [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4400_ECCV_2022_paper.php)] 
  [[code](https://github.com/zxgravity/CIA)]
  
- **RTS:** Matthieu Paul,Martin Danelljan,Christoph Mayer,Luc Van Gool.<br />
  "Robust Visual Tracking by Segmentation." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11191)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **AiATrack:** Shenyuan Gao, Chunluan Zhou, Chao Ma, Xinggang Wang, Junsong Yuan.<br />
  "AiATrack: Attention in Attention for Transformer Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.09603)] 
  [[code](https://github.com/Little-Podi/AiATrack)]

- **SLTtrack:** Minji Kim, Seungkwan Lee, Jungseul Ok, Bohyung Han, Minsu Cho.<br />
  "Towards Sequence-Level Training for Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.05810)] 
  [[code](https://github.com/byminji/SLTtrack)]
  
- **FEAR:** Vasyl Borsuk, Roman Vei, Orest Kupyn, Tetiana Martyniuk, Igor Krashenyi, Jiři Matas.<br />
  "FEAR: Fast, Efficient, Accurate and Robust Visual Tracker." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2112.07957.pdf)] 
  [[code](https://xxxxxxx)]
  
- **PersonPath22:** Bing Shuai, Alessandro Bergamo, Uta Buechler, Andrew Berneshawi, Alyssa Boden, Joseph Tighe.<br />
  "Large Scale Real-World Multi-Person Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2211.02175)] 
  [[code](https://amazon-science.github.io/tracking-dataset/personpath22.html)]
  
- **STNet:** Le Hui, Lingpeng Wang, Linghua Tang, Kaihao Lan, Jin Xie, Jian Yang.<br />
  "3D Siamese Transformer Network for Single Object Tracking on Point Clouds." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.11995)] 
  [[code](https://github.com/fpthink/STNet)]
  
- **P3AFormer:** Zelin Zhao, Ze Wu, Yueqing Zhuang, Boxun Li, Jiaya Jia.<br />
  "Tracking Objects as Pixel-wise Distributions." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.05518)] 
  [[code](https://sjtuytc.github.io/zelin_pages/p3aformer.html)]
  
- **TETer:** Siyuan Li, Martin Danelljan, Henghui Ding, Thomas E. Huang, Fisher Yu.<br />
  "Tracking Every Thing in the Wild." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.12978)] 
  [[code](http://vis.xyz/pub/tet)]
  
- **ByteTrack:** Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang.<br />
  "ByteTrack: Multi-Object Tracking by Associating Every Detection Box." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2110.06864v2.pdf)] 
  [[code](https://github.com/ifzhang/ByteTrack)]

- **MOTR:** Fangao Zeng, Bin Dong, Yuang Zhang, Tiancai Wang, Xiangyu Zhang, Yichen Wei.<br />
  "MOTR: End-to-End Multiple-Object Tracking with Transformer." ECCV (2022).
  [[paper](https://arxiv.org/abs/2105.03247)] 
  [[code](https://github.com/megvii-research/MOTR)]
  
- **MTracker:** Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, Wenyu Liu.<br />
  "Robust Multi-Object Tracking by Marginal Inference." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.03727)] 
  [[code](https://xxxxxxx)]
  

  
  
### CVPR 2022

- **MixFormer:** Yutao Cui, Jiang Cheng, Limin Wang, Gangshan Wu.<br />
  "MixFormer: End-to-End Tracking with Iterative Mixed Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11082)] 
  [[code](https://github.com/MCG-NJU/MixFormer)]
  
- **OWTB:** Yang Liu, Idil Esen Zulfikar, Jonathon Luiten, Achal Dave, Deva Ramanan, Bastian Leibe, Aljoša Ošep, Laura Leal-Taixé.<br />
  "Opening up Open-World Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2104.11221)] 
  [[code](https://openworldtracking.github.io/)]
  
- **UTT:** Fan Ma, Mike Zheng Shou, Linchao Zhu, Haoqi Fan, Yilei Xu, Yi Yang, Zhicheng Yan.<br />
  "Unified Transformer Tracker for Object Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.15175)] 
  [[code](https://github.com/Flowerfan/Trackron)]
  
- **CSWinTT:** Zikai Song, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Transformer Tracking with Cyclic Shifting Window Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2205.03806)] 
  [[code](https://github.com/SkyeSong38/CSWinTT)]
  
- **ToMP:** Christoph Mayer, Martin Danelljan, Goutam Bhat, Matthieu Paul, Danda Pani Paudel, Fisher Yu, Luc Van Gool.<br />
  "Transforming Model Prediction for Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11192)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **TCTrack:** Ziang Cao, Ziyuan Huang, Liang Pan, Shiwei Zhang, Ziwei Liu, Changhong Fu.<br />
  "TCTrack: Temporal Contexts for Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01885)] 
  [[code](https://github.com/vision4robotics/TCTrack)]
  
- **SBT:** Fei Xie, Chunyu Wang, Guangting Wang, Yue Cao, Wankou Yang, Wenjun Zeng.<br />
  "Correlation-Aware Deep Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01666)] 
  [[code](https://github.com/phiphiphi31/SuperSBT)]
  
- **AdaRS:** Yihao Li, Jun Yu, Zhongpeng Cai, Yuwen Pan.<br />
  "Cross-Modal Target Retrieval for Tracking by Natural Language." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/html/Li_Cross-Modal_Target_Retrieval_for_Tracking_by_Natural_Language_CVPRW_2022_paper.html)] 
  [[code](xxxx)]
  
- **STNet:** Jiqing Zhang, Bo Dong, Haiwei Zhang, Jianchuan Ding, Felix Heide, Baocai Yin, Xin Yang.<br />
  "Spiking Transformers for Event-based Single Object Tracking." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html)] 
  [[code](https://github.com/Jee-King/CVPR2022_STNet)]
  
- **VTUAV:** Pengyu Zhang, Jie Zhao, Dong Wang, Huchuan Lu, Xiang Ruan.<br />
  "Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.04120)] 
  [[code](https://zhang-pengyu.github.io/DUT-VTUAV/)]
  
- **UAVMOT:** Shuai Liu, Xin Li, Huchuan Lu, You He.<br />
  "Multi-Object Tracking Meets Moving UAV." CVPR (2022).
  [[paper](https://arxiv.org/abs/xxxx.xxxx)] 
  [[code](https://github.com/LiuShuaiyr/UAVMOT)]
  
- **GTR:** Xingyi Zhou, Tianwei Yin, Vladlen Koltun, Phillip Krähenbühl.<br />
  "Global Tracking Transformers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.13250)] 
  [[code](https://github.com/xingyizhou/GTR)]
  
- **GTELT:** Zikun Zhou, Jianqiu Chen, Wenjie Pei, Kaige Mao, Hongpeng Wang, Zhenyu He.<br />
  "Global Tracking via Ensemble of Local Trackers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.16092)] 
  [[code](https://github.com/ZikunZhou/GTELT)]
  
- **RBO:** Feng Tang, Qiang Ling.<br />
  "Ranking-based Siamese Visual Tracking." CVPR (2022).
  [[paper](https://arxiv.org/pdf/2205.11761.pdf)] 
  [[code](https://github.com/sansanfree/RBO)]
  
- **ULAST:** Qiuhong Shen, Lei Qiao, Jinyang Guo, Peixia Li, Xin Li, Bo Li, Weitao Feng, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Unsupervised Learning of Accurate Siamese Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.01475)] 
  [[code](https://github.com/FlorinShum/ULAST)]
  
- **UDAT:** Junjie Ye, Changhong Fu, Guangze Zheng, Danda Pani Paudel, Guang Chen.<br />
  "Unsupervised Domain Adaptation for Nighttime Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.10541)] 
  [[code](https://github.com/vision4robotics/UDAT)]
  
- **M2Track:** Chaoda Zheng, Xu Yan, Haiming Zhang, Baoyuan Wang, Shenghui Cheng, Shuguang Cui, Zhen Li.<br />
  "Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01730)] 
  [[code](https://github.com/Ghostish/Open3DSOT)]
  

### IJCAI 2022

- **InBN:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing, Yilin Lyu, Bing Li, Weiming Hu.<br />
  "Learning Target-aware Representation for Visual Tracking via Informative Interactions." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2201.02526)] 
  [[code](https://xxxxxxx)]
  
- **SparseTT:** Zhihong Fu, Zehua Fu, Qingjie Liu, Zehua Fu, Yunhong Wang.<br />
  "SparseTT: Visual Tracking with Sparse Transformers." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.03776)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
- **HybTransT:** Ilchae Jung, Minji Kim, Eunhyeok Park, Bohyung Han.<br />
  "Online Hybrid Lightweight Representations Learning: Its Application to Visual Tracking." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.11179)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
  
### MICCAI 2022

- **TLT:** Wen Tang, Han Kang, Haoyue Zhang, Pengxin Yu, Corey W. Arnold, Rongguo Zhang.<br />
  "Transformer Lesion Tracker." MICCAI (2022).
  [[paper](https://arxiv.org/abs/2206.06252)] 
  [[code](https://github.com/TangWen920812/TLT)]
  
  
### ArXiv 2022
 
- **VisDrone:** Pengfei Zhu, Longyin Wen, Dawei Du, Xiao Bian, Heng Fan, Qinghua Hu, Haibin Ling.<br />
  "Detection and Tracking Meet Drones Challenge." TPAMI (2022).
  [[paper](https://arxiv.org/abs/2001.06303)] 
  [[code](https://github.com/VisDrone/VisDrone-Dataset)]

- **GIT:** Shiyu Hu, Xin Zhao, Lianghua Huang, Kaiqi Huang.<br />
  "Global Instance Tracking: Locating Target More Like Humans." IEEE TPAMI (2022).
  [[paper](https://arxiv.org/pdf/2202.13073.pdf)] 
  [[code](http://videocube.aitestunion.com/)]

- **ProTrack:** Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Prompting for Multi-Modal Tracking." ACM MM (2022).
  [[paper](https://arxiv.org/abs/2207.14571)] 
  [[code]( )]

- **QuadTreeCapsule:** Ding Ma, Xiangqian Wu.<br />
  "QuadTreeCapsule: QuadTree Capsules for Deep Regression Tracking." ACM MM (2022).
  [[paper](https://dl.acm.org/doi/10.1145/3503161.3548236)] 
  [[code]( )]
  
- **GATransT:** Libo Wang, Si Chen, Zhen Wang, Da-Han Wang, Shunzhi Zhu.<br />
  "Graph Attention Transformer Network for Robust Visual Tracking." ICONIP (2022).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-99-1639-9_14)] 
  [[code]()]

- **SiamTDN:** Yanjie Liang, Penghui Zhao, Yifei Hao, Hanzi Wang.<br />
  "Siamese Template Diffusion Networks for Robust Visual Tracking." ICME (2022).
  [[paper](https://ieeexplore.ieee.org/document/9859929)] 
  [[code]()]
  
- **TAT:** Kaihao Lan, Haobo Jiang, Jin Xie.<br />
  "Temporal-aware Siamese Tracker: Integrate Temporal Context for 3D Object Tracking." ACCV (2022).
  [[paper](https://openaccess.thecvf.com/content/ACCV2022/html/Lan_Temporal-aware_Siamese_Tracker_Integrate_Temporal_Context_for_3D_Object_Tracking_ACCV_2022_paper.html)] 
  [[code](https://github.com/tqsdyy/TAT)]
  
- **EgoTracks:** Hao Tang, Kevin Liang, Kristen Grauman, Matt Feiszli, Weiyao Wang.<br />
  "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2301.03213)] 
  [[code]()]
  
 - **COESOT:** Chuanming Tang, Xiao Wang, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang, Yaowei Wang, Yonghong Tian.<br />
  "Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.11010)] 
  [[code](COESOT)]
  
- **WATB:** Fasheng Wang, Ping Cao, Fu Li, Xing Wang, Bing He, Fuming Sun.<br />
  "WATB: Wild Animal Tracking Benchmark." IJCV (2022).
  [[paper](https://link.springer.com/content/pdf/10.1007/s11263-022-01732-3.pdf?pdf=button)] 
  [[code](https://w-1995.github.io/)]
  
- **UAV2UAV:** Yong Wang, Zirong Huang, Robert Laganière, Huanlong Zhang, Lu Ding.<br />
  "A UAV to UAV tracking benchmark." KBS (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S095070512201293X)] 
  [[code](https://github.com/hapless19/UAV2UAV-dataset)]
  
- **UOT100:** K. Panetta, L. Kezebou, V. Oludare, and S. S. Agaian.<br />
  "Comprehensive Underwater Object Tracking Benchmark Dataset and Underwater Image Enhancement With GAN." IEEE JOE (2022).
  [[paper](https://ieeexplore.ieee.org/document/9499961)] 
  [[code](https://www.kaggle.com/datasets/landrykezebou/uot100-underwater-object-tracking-dataset)]
  
- **NeighborTrack:** Yu-Hsi Chen, Chien-Yao Wang, Cheng-Yun Yang, Hung-Shuo Chang, Youn-Long Lin, Yung-Yu Chuang, Hong-Yuan Mark Liao.<br />
  "NeighborTrack: Improving Single Object Tracking by Bipartite Matching with Neighbor Tracklets." ArXiv (2022).
  [[paper](https://arxiv.org/pdf/2211.06663.pdf)] 
  [[code](https   )]
  
- **MTTSiam:** Ali Sekhavati, Won-Sook Lee.<br />
  "Multi-Template Temporal Siamese Network for Long-Term Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13812)] 
  [[code](https://github.com/AliGreen0/MTTSiam)]
  
- **PruningInTracking:** Saksham Aggarwal, Taneesh Gupta, Pawan Kumar Sahu, Arnav Chavan, Rishabh Tiwari, Dilip K. Prasad, Deepak K. Gupta.<br />
  "On designing light-weight object trackers through network pruning: Use CNNs or transformers?." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13769)] 
  [[code](https   )]
  
- **ProContEXT:** Jin-Peng Lan, Zhi-Qi Cheng, Jun-Yan He, Chenyang Li, Bin Luo, Xu Bao, Wangmeng Xiang, Yifeng Geng, Xuansong Xie.<br />
  "ProContEXT: Exploring Progressive Context Transformer for Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2210.15511)] 
  [[code](https://drive.google.com/drive/folders/18kHdBNEwvbk8S4-mwHaI-mw5w6cK-pyY?usp=sharing)]
  
- **TSFMO:** Zhewen Zhang, Fuliang Wu, Yuming Qiu, Jingdong Liang, Shuiwang Li.<br />
  "Tracking Small and Fast Moving Objects: A Benchmark." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2209.04284)] 
  [[code](https://github.com/CodeOfGithub/S-KeepTrack)]
  
- **SFTransT:** Chuanming Tang, Xiao Wang, Yuanchao Bai, Zhe Wu, Jianlin Zhang, Yongmei Huang.<br />
  "Learning Spatial-Frequency Transformer for Visual Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.08829)] 
  [[code](https://github.com/Tchuanm/SFTransT.git)]
  
- **DMTracker:** Shang Gao, Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Learning Dual-Fused Modality-Aware Representations for RGBD Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.03055)] 
  [[code](https://github.com/ShangGaoG/DMTracker)]
  
- **AVisT:** Mubashir Noman, Wafa Al Ghallabi, Daniya Najiha, Christoph Mayer, Akshay Dudhane, Martin Danelljan, Hisham Cholakkal, Salman Khan, Luc Van Gool, Fahad Shahbaz Khan.<br />
  "AVisT: A Benchmark for Visual Object Tracking in Adverse Visibility." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.06888)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **RGBDReview:** Jinyu Yang, Zhe Li, Song Yan, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen, Ling Shao.<br />
  "RGBD Object Tracking: An In-depth Review." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.14134)] 
  [[code](https://github.com/memoryunreal/RGBD-tracking-review)]
  
- **WebUAV-3M:** Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Yuxuan Zhang, Xiang Wan, Shiming Ge.<br />
  "WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.07425)] 
  [[code](https://github.com/983632847/WebUAV-3M)]
  
- **SiamTracking4UAV:** Changhong Fu, Kunhan Lu, Guangze Zheng, Junjie Ye, Ziang Cao, Bowen Li.<br />
  "Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2205.04281)] 
  [[code](https://github.com/vision4robotics/SiameseTracking4UAV)]
  
- **SOTSurvey:** Zahra Soleimanitaleb, Mohammad Ali Keyvanrad.<br />
  "Single Object Tracking: A Survey of Methods, Datasets, and Evaluation Metrics." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.13066)] 
  
- **SOTRearch:** Ruize Han, Wei Feng, Qing Guo, Qinghua Hu.<br />
  "Single Object Tracking Research: A Survey." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.11410)] 
  
- **VOTSurvey:** Fei Chen, Xiaodong Wang, Yunxiang Zhao, Shaohe Lv, Xin Niu.<br />
  "Visual object tracking: A survey." CVIU (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1077314222001011?dgcid=author)] 
    
- **HCAT:** Xin Chen, Dong Wang, Dongdong Li, Huchuan Lu.<br />
  "Efficient Visual Tracking via Hierarchical Cross-Attention Transformer." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13537)] 
  [[code](https://github.com/chenxin-dlut/HCAT)]
  
- **TransT-M:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Huchuan Lu.<br />
  "High-Performance Transformer Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13533)] 
  [[code](https://github.com/chenxin-dlut/TransT-M)]
   
- **GUSOT:** Zhiruo Zhou, Hongyu Fu, Suya You, C. -C. Jay Kuo.<br />
  "GUSOT: Green and Unsupervised Single Object Tracking for Long Video Sequences" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.07629)] 
  [[code](https://github.com/xxxxxx)]
  
- **SiamAttack:** Zhenbang Li, Yaya Shi, Jin Gao, Shaoru Wang, Bing Li, Pengpeng Liang.<br />
  "A Simple and Strong Baseline for Universal Targeted Attacks on Siamese Visual Tracking" IEEE TCSVT (2022).
  [[paper](https://ieeexplore.ieee.org/document/9576540)] 
  [[code](https://github.com/lizhenbang56/SiamAttack)]

- **SRRT:** Jiawen Zhu, Xin Chen, Dong Wang, Wenda Zhao, Huchuan Lu.<br />
  "SRRT: Exploring Search Region Regulation for Visual Object Tracking" IEEE TCSVT (2024).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10549949)] 
  [[code]( )]
  
- **DIMBA:** Xiangyu Yin, Wenjie Ruan, Jonathan Fieldsend.<br />
  "DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.08044)] 
  [[code](https://github.com/xxxxxxxx)]
  
- **P-SiamFC++:** Xucheng Wang, Dan Zeng, Qijun Zhao, Shuiwang Li.<br />
  "Rank-Based Filter Pruning for Real-Time UAV Tracking" ArXiv (2022).
  [[paper](https://arxiv.org/abs/2207.01768)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **SkeleVision:** Nilaksh Das, Sheng-Yun Peng, Duen Horng Chau.<br />
  "SkeleVision: Towards Adversarial Resiliency of Person Tracking with Multi-Task Learning." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.00734)] 
  [[code](https://github.com/nilakshdas/SkeleVision)]
  
- **CAJMU:** Qiuhong Shen, Xin Li, Fanyang Meng, Yongsheng Liang.<br />
  "Context-aware Visual Tracking with Joint Meta-updating." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.01513)] 
  [[code](https://github.com/xxxxxxxx)]
  
- **ResamplingNet:** Haobo Zuo, Changhong Fu, Sihang Li, Junjie Ye, and Guangze Zheng.<br />
  "ResamplingNet: End-to-End Adaptive Feature Resampling Network for Real-Time Aerial Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/ResamplingNet)]
  
- **LPAT:** Changhong Fu, Weiyu Peng, Sihang Li, Junjie Ye, and Ziang Cao.<br />
  "Local Perception-Aware Transformer for Aerial Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.00662)] 
  [[code](https://github.com/vision4robotics/LPAT)]
  
- **AFRT:** Haobo Zuo, Changhong Fu, Sihang Li, Junjie Ye, and Guangze Zheng.<br />
  "End-to-End Feature Decontaminated Network for UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/FDNT)]
  
- **FDT:** Changhong Fu, Haobo Zuo, Guangze Zheng, Junjie Ye, and Bowen Li.<br />
  "Feature-Distilled Transformer for UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/FDT-tracker)]
  
- **HighlightNet:** Changhong Fu, Haolin Dong.<br />
  "HighlightNet: Highlighting Low-Light Potential Features for Real-Time UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/HighlightNet)]
  
- **LAE-PVT:** Bowen Li, Yiming Li, Junjie Ye, Changhong Fu, and Hang Zhao.<br />
  "Predictive Visual Tracking: A New Benchmark and Baseline Approach." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/LAE-PVT-master)]
  
- **SiamPSA:** Guangze Zheng, Changhong Fu, Junjie Ye, Bowen Li, Geng Lu, and Jia Pan.<br />
  "SiamPSA: Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention." ArXiv (2022).
  [[paper](https://arxiv.org/abs/xxxxxxxx)] 
  [[code](https://github.com/vision4robotics/SiamPSA)]
  
- **AdaptiveSiam:** Madhu Kiran, Le Thanh Nguyen-Meidine, Rajat Sahay, Rafael Menelau Oliveira E Cruz, Louis-Antoine Blais-Morin, Eric Granger.<br />
  "Generative Target Update for Adaptive Siamese Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2202.09938)] 
  [[code](https://anonymous.4open.science/r/AdaptiveSiamese-CE78/)]
  
- **DST:** Yao Sui, Guanghui Wang, Li Zhang.<br />
  "In Defense of Subspace Tracker: Orthogonal Embedding for Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.07927)] 
  [[code](https://xxxxxxx)]
  
- **SiamLA:** Jiahao Nie, Han Wu, Zhiwei He, Yuxiang Yang, Mingyu Gao, Zhekang Dong.<br />
  "Learning Localization-aware Target Confidence for Siamese Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.14093)] 
  [[code](https://xxxxxxx/)]
  
- **DUT-Anti-UAV:** Jie Zhao, Jingshu Zhang, Dongdong Li, Dong Wang.<br />
  "Vision-based Anti-UAV Detection and Tracking." TITS (2022).
  [[paper](https://arxiv.org/abs/2205.10851)] 
  [[code](https://github.com/wangdongdut/DUT-Anti-UAV)]
  
- **CoCoLoT:** Matteo Dunnhofer, Christian Micheloni.<br />
  "CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking." ICPR (2022).
  [[paper](https://arxiv.org/abs/2205.04261)] 
  [[code](https://xxxxxxx)]
  
- **EUSA:** Siao Liu, Zhaoyu Chen, Wei Li, Jiwei Zhu, Jiafeng Wang, Wenqiang Zhang, Zhongxue Gan.<br />
  "Efficient universal shuffle attack for visual object tracking." ICASSP (2022).
  [[paper](https://arxiv.org/abs/2203.06898)] 
  [[code](https://xxxxxxx)]
  
- **ITB:** Xin Li, Qiao Liu, Wenjie Pei, Qiuhong Shen, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "An Informative Tracking Benchmark." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2112.06467)] 
  [[code](https://github.com/XinLi-zn/Informative-tracking-benchmark)]
  
- **VisEvent:** Xiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li, Yaowei Wang, Yonghong Tian, Feng Wu.<br />
  "VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2108.05015)] 
  [[code](https://sites.google.com/view/viseventtrack/)]
  
- **RPT++:** Ziang Ma, Haitao Zhang, Linyuan Wang, Jun Yin.<br />
  "RPT++: Customized Feature Representation for Siamese Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.12194)] 
  [[code](https://xxxxxxx/)]
  
- **IAT:** Mengmeng Wang, Xiaoqian Yang, Yong Liu.<br />
  "Explicitly Modeling the Discriminability for Instance-Aware Visual Object Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.13259)] 
  [[code](https://xxxxxxx/)]
  
- **ALT:** Di Yuan, Xiaojun Chang, Qiao Liu, Dehua Wang, Zhenyu He.<br />
  "Active Learning for Deep Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2110.15030)] 
  [[code](https://xxxxxxx/)]
  
- **FSLT:** Jinghao Zhou, Bo Li, Peng Wang, Peixia Li, Weihao Gan, Wei Wu, Junjie Yan, Wanli Ouyang.<br />
  "Real-Time Visual Object Tracking via Few-Shot Learning." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2103.10130.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **DML:** Jinghao Zhou, Bo Li, Lei Qiao, Peng Wang, Weihao Gan, Wei Wu, Junjie Yan, Wanli Ouyang.<br />
  "Higher Performance Visual Tracking with Dual-Modal Localization." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2103.10089.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **TREG:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Target Transformed Regression for Accurate Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2104.00403.pdf)] 
  [[code](https://github.com/MCG-NJU/TREG)]
  
- **SiamSTM:** Jinpu Zhang, Yuehuan Wang.<br />
  "Spatio-Temporal Matching for Siamese Visual Tracking." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.02408.pdf)] 
  [[code](https://xxxxxxx/)]
  
- **TrTr:** Moju Zhao, Kei Okada, Masayuki Inaba.<br />
  "TrTr: Visual Tracking with Transformer." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.03817.pdf)] 
  [[code](https://github.com/tongtybj/TrTr)]

- **TS-RCN:** Ning Zhang, Jingen Liu, Ke Wang, Dan Zeng, Tao Mei.<br />
  "Robust Visual Object Tracking with Two-Stream Residual Convolutional Networks." ArXiv (2020).
  [[paper](https://arxiv.org/pdf/2005.06536.pdf)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **DMV:** Gunhee Nam, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "DMV: Visual Object Tracking via Part-level Dense Memory and Voting-based Retrieval." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2003.09171v1)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **FCOT:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Fully Convolutional Online Tracking." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2004.07109)] 
  [[code](https://github.com/MCG-NJU/FCOT)]
  
  
### AAAI 2022

- **HDN:** Xinrui Zhan, Yueran Liu, jianke Zhu, Yang Li.<br />
  "Homography Decomposition Networks for Planar Object Tracking." AAAI (2022).
  [[paper](https://arxiv.org/pdf/2112.07909.pdf)] 
  [[code](https://github.com/zhanxinrui/HDN)]

- **MArMOT:** Chenglong Li, Tianhao Zhu, Lei Liu, Xiaonan Si, Zilin Fan, Sulan Zhai.<br />
  "Cross-Modal Object Tracking: Modality-Aware Representations and a Unified Benchmark." AAAI (2022).
  [[paper](https://arxiv.org/abs/2111.04264)] 
  [[code](https://github.com/xxxxx/MArMOT)]

- **APFNet:** Yun Xiao, Mengmeng Yang, Chenglong Li, Lei Liu, Jin Tang.<br />
  "Attribute-based Progressive Fusion Network for RGBT Tracking." AAAI (2022).
  [[paper](https://github.com/yangmengmeng1997/APFNet/tree/main/Paper)] 
  [[code](https://github.com/yangmengmeng1997/APFNet)]

- **TAV:** Tahar Allouche, Jerome Lang, Florian Yger.<br />
  "Truth-Tracking via Approval Voting: Size Matters." AAAI (2022).
  [[paper](https://arxiv.org/abs/2112.04387)] 
  [[code](https://github.com/zhanxinrui/HDN)]
  
  
### ICLR 2022

- **FSBA:** Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia.<br />
  "Few-Shot Backdoor Attacks on Visual Object Tracking." ICLR (2022).
  [[paper](https://openreview.net/pdf?id=qSV5CuSaK_a)] 
  [[code](https://www.dropbox.com/s/nfg7en8azc1cvz3/codes_FSBA_ICLR22.zip?dl=0)]
  
  
### ICRA 2022

- **Ad2Attack:** Changhong Fu, Sihang Li, Xinnan Yuan, Junjie Ye, Ziang Cao, Fangqiang Ding.<br />
  "Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking." ICRA (2022).
  [[paper](https://arxiv.org/abs/2203.01516)] 
  [[code](https://github.com/vision4robotics/Ad2Attack)]
 
- **SCT:** Junjie Ye, Changhong Fu, Ziang Cao, Shan An, Guangze Zheng, Bowen Li.<br />
  "Tracker Meets Night: A Transformer Enhancer for UAV Tracking." ICRA/RAL (2022).
  [[paper](https://ieeexplore.ieee.org/document/9696362)] 
  [[code](https://github.com/vision4robotics/SCT)]

- **SiamX:** Huajian Huang, Sai-Kit Yeung.<br />
  "SiamX: An Efficient Long-term Tracker Using Cross-level Feature Correlation and Adaptive Tracking Scheme." ICRA (2022).
  [[paper](https://huajianup.github.io/research/SiamX/SiamX_ICRA2022_final.pdf)] 
  [[code](https://huajianup.github.io/research/SiamX/)]
 
 
### WACV 2022

- **SiamTPN:** Daitao Xing, Nikolaos Evangeliou, Athanasios Tsoukalas, Anthony Tzes.<br />
  "Siamese Transformer Pyramid Networks for Real-Time UAV Tracking." WACV (2022).
  [[paper](https://arxiv.org/pdf/2110.08822.pdf)] 
  [[code](https://github.com/RISC-NYUAD/SiamTPNTracker)]
  
### ICCV 2021

- **STARK:** Bin Yan, Houwen Peng, Jianlong Fu, Dong Wang, Huchuan Lu.<br />
  "Learning Spatio-Temporal Transformer for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2103.17154.pdf)] 
  [[code](https://github.com/researchmm/Stark)]
  
- **AutoMatch:**  Zhang Zhipeng, Liu Yihao, Wang Xiao, Li Bing, Hu Weiming. <br />
  "Learn to Match: Automatic Matching Network Design for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00803.pdf)]
  [[code](https://github.com/JudasDie/SOTS)]
  
- **DDT:** Bin Yu, Ming Tang, Linyu Zheng, Guibo Zhu, Jinqiao Wang.<br />
  "High-Performance Discriminative Tracking with Transformers." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.pdf)] 
  [[code](https://github.com/xxxx/xxxx)]
  
- **HiFT:**  Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li. <br />
  "HiFT: Hierarchical Feature Transformer for Aerial Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00202.pdf)]
  [[code](https://github.com/vision4robotics/HiFT)]
  
- **DualTFR:**  Fei Xie, Chunyu Wang, Guangting Wang, Wankou Yang, Wenjun Zeng. <br />
  "Learning Tracking Representations via Dual-Branch Fully Transformer Networks." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2112.02571)]
  [[code](https://github.com/phiphiphi31/DualTFR)]
  
- **DMB:**  Fei Xie, Wankou Yang, Kaihua Zhang, Bo Liu, Wanli Xue, Wangmeng Zuo. <br /> 
  "Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking." ICCVW (2021).
  [[paper](https://arxiv.org/pdf/2009.09669.pdf)]
  [[code](https://github.com/phiphiphi31/DMB)]

- **KeepTrack:** Christoph Mayer, Martin Danelljan, Danda Pani Paudel, Luc Van Gool.<br />
  "Learning Target Candidate Association to Keep Track of What Not to Track." ICCV (2021).
  [[paper](https://arxiv.org/abs/2103.16556)] 
  [[code](https://github.com/visionml/pytracking)]

- **SAOT:** Zikun Zhou, Wenjie Pei, Xin Li, Hongpeng Wang, Feng Zheng, Zhenyu He. <br />
  "Saliency-Associated Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03637.pdf)]
  [[code](https://github.com/ZikunZhou/SAOT)]
 
- **MLVSNet:** Zhoutao Wang, Qian Xie, Yu-Kun Lai, Jing Wu, Kun Long , Jun Wang. <br />
  "MLVSNet: Multi-level Voting Siamese Network for 3D Visual Tracking." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_MLVSNet_Multi-Level_Voting_Siamese_Network_for_3D_Visual_Tracking_ICCV_2021_paper.pdf)]
  [[code](https://github.com/CodeWZT/MLVSNet)]
  
 - **EFTrack:** Jiqing Zhang, Xin Yang, Yingkai Fu, Xiaopeng Wei, Baocai Yin, Bo Dong. <br />
  "Object Tracking by Jointly Exploiting Frame and Event Domain." ICCV (2021).
  [[paper](https://arxiv.org/abs/2109.09052)]
  [[code](https://github.com/Jee-King/ICCV2021_Event_Frame_Tracking)]
  
 - **Box2Mask:** Bin Zhao, Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Generating Masks from Boxes by Mining Spatio-Temporal Consistencies in Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2101.02196)]
  [[code](https://github.com/visionml/pytracking)]
  
- **DepthTrack:** Song Yan, Jinyu Yang, Jani Käpylä, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen. <br />
  "DepthTrack : Unveiling the Power of RGBD Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.13962)]
  [[code](https://github.com/xiaozai/DeT)]
  
- **USOT:** Jilai Zheng, Chao Ma, Houwen Peng, Xiaokang Yang. <br />
  "Learning to Track Objects from Unlabeled Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.12711)]
  [[code](https://github.com/VISION-SJTU/USOT)]
  
- **TOTB:** Heng Fan, Halady Akhilesha Miththanthaya, Harshit, Siranjiv Ramana Rajan, Xiaoqiong Liu, Zhilin Zou, Yuewei Lin, Haibin Ling. <br />
  "Transparent Object Tracking Benchmark." ICCV (2021).
  [[paper](https://arxiv.org/abs/2011.10875)]
  [[code](https://hengfan2010.github.io/projects/TOTB/)]
  
- **TREK-150:** Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, Christian Micheloni. <br />
  "Is First Person Vision Challenging for Object Tracking?." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2108.13665)]
  [[code](https://machinelearning.uniud.it/datasets/trek150/)]
  [[toolkit](https://github.com/matteo-dunnhofer/TREK-150-toolkit)]
  
- **VASR:** Kenan Dai, Jie Zhao, Lijun Wang, Dong Wang, Jianhua Li, Huchuan Lu, Xuesheng Qian, Xiaoyun Yang. <br />
  "Video Annotation for Visual Tracking via Selection and Refinement." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03821.pdf)]
  [[code](https://github.com/Daikenan/VASR)]
  
- **BAT:** Chaoda Zheng, Xu Yan, Jiantao Gao, Weibing Zhao, Wei Zhang, Zhen Li, Shuguang Cui. <br />
  "Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.04728.pdf)]
  [[code](https://github.com/Ghostish/BAT)]
  
- **ABA:** Qing Guo, Ziyi Cheng, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yang Liu, Jianjun Zhao. <br />
  "Learning to Adversarially Blur Visual Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2107.12085)]
  [[code](https://github.com/tsingqguo/ABA)]
  
  
### CVPR 2021

- **TransT:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun yang, Huchuan Lu. <br />
  "Transformer Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.15436)]
  [[code](https://github.com/chenxin-dlut/TransT)]
  
- **Alpha-Refine:** Bin Yan, Xinyu Zhang, Dong Wang, Huchuan Lu, Xiaoyun Yang. <br />
  "Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation." CVPR (2021).
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)]
  [[code](https://github.com/MasterBin-IIAU/AlphaRefine)]
  
- **LightTrack:** Bin Yan, Houwen Peng, Kan Wu, Dong Wang, Jianlong Fu, Huchuan Lu. <br />
  "LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.14545)]
  [[code](https://github.com/cvpr-2021/lighttrack)]
  
- **TrTrack:** Ning Wang, Wengang Zhou, Jie Wang, Houqiang Li. <br />
  "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.11681.pdf)]
  [[code](https://github.com/594422814/TransformerTrack)]
  
- **STMTrack:** Zhihong Fu, Qingjie Liu, Zehua Fu, Yunhong Wang. <br />
  "STMTrack: Template-free Visual Tracking with Space-time Memory Networks." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00324)]
  [[code](https://github.com/fzh0917/STMTrack)]
  
- **SiamGAT:** Dongyan Guo, Yanyan Shao, Ying Cui, Zhenhua Wang, Liyan Zhang, Chunhua Shen.<br />
  "Graph Attention Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2011.11204)] 
  [[code](https://github.com/ohhhyeahhh/SiamGAT)]
  
- **SiamACM:** Wencheng Han, Xingping Dong, Fahad Shahbaz Khan, Ling Shao, Jianbing Shen.<br />
  "Learning to Fuse Asymmetric Feature Maps in Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2012.02776.pdf)] 
  [[code](https://github.com/wencheng256/SiamBAN-ACM)]
  
- **PST:** Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "Polygonal Point Set Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.pdf)] 
  [[code](https://github.com/PST)]
  
- **PUL:** Qiangqiang Wu, Jia Wan, Antoni B. Chan. <br />
  "Progressive Unsupervised Learning for Visual Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.pdf)]
  [[code](https://github.com/PUL)]
  
- **CapsuleRRT:** Ding Ma, Xiangqian Wu. <br />
  "CapsuleRRT: Relationships-Aware Regression Tracking via Capsules." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.pdf)]
  [[code](https://github.com/CapsuleRRT)]
  
- **Semi-Track:** Yang Fu, Sifei Liu, Umar Iqbal, Shalini De Mello, Humphrey Shi, Jan Kautz.<br />
  "Learning to Track Instances without Video Annotations." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2104.00287.pdf)] 
  [[code](https://oasisyang.github.io/projects/semi-track/index.html)]

- **RE-Siam:** Deepak K. Gupta, Devanshu Arya, Efstratios Gavves. <br />
  "Rotation Equivariant Siamese Networks for Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2012.13078)]
  [[code](https://github.com/dkgupta90/re-siamnet)]
  
- **SiamNLP:** Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff. <br />
  "Siamese Natural Language Tracker: Tracking by Natural Language Descriptions with Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/abs/1912.02048v2)]
  [[code](https://github.com/fredfung007/snlt)]
  
- **LangTrackBenchmark:** Xiao Wang, Xiujun Shu, Zhipeng Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu. <br />
  "Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.16746.pdf)]
  [[code](https://sites.google.com/view/langtrackbenchmark/)]
  
- **DroneCrowd:** Longyin Wen, Dawei Du, Pengfei Zhu, Qinghua Hu, Qilong Wang, Liefeng Bo, Siwei Lyu. <br />
  "Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2105.02440.pdf)]
  [[code](https://github.com/VisDrone/DroneCrowd)]
  
- **DMTrack:** Zikai Zhang, Bineng Zhong, Shengping Zhang, Zhenjun Tang, Xin Liu, Zhaoxiang Zhang. <br />
  "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.12041)]
  [[code](https://github.com/hqucv/dmtrack)]
  
- **LF-Siam:** Siyuan Cheng, Bineng Zhong, Guorong Li, Xin Liu, Zhenjun Tang, Xianxian Li, Jing Wang. <br />
  "Learning to Filter: Siamese Relation Network for Robust Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00829)]
  [[code](https://github.com/hqucv/siamrn)]
  
- **IoU Attack:** Shuai Jia, Yibing Song, Chao Ma, Xiaokang Yang. <br />
  "IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.14938)]
  [[code](https://github.com/VISION-SJTU/IoUattack)]
  
- **MeanShift++:** Jennifer Jang, Heinrich Jiang. <br />
  "MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.pdf)]
  [[code](https://github.com/MeanShift++)]
  
  
### IROS 2021

- **CRACT:** Heng Fan, Haibin Ling.<br />
  "CRACT: Cascaded Regression-Align-Classification for Robust Visual Tracking." IROS (2020).
  [[paper](https://arxiv.org/abs/2011.12483)] 

- **SiamAPN++:** Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li.<br />
  "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2106.08816.pdf)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]

- **DarkLighter:** Junjie Ye, Changhong Fu, Guangze Zheng, Ziang Cao, Bowen Li.<br />
  "DarkLighter: Light Up the Darkness for UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2107.14389.pdf)] 
  [[code](https://github.com/vision4robotics/DarkLighter)]
  
- **PTT:** Jiayao Shan, Sifan Zhou, Zheng Fang, Yubo Cui.<br />
  "PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds." IROS (2021).
  [[paper](https://arxiv.org/abs/2108.06455)] 
  [[code](https://github.com/shanjiayao/PTT)]
  
  
### NeurIPS 2021

- **PathTrack:** Drew Linsley, Girik Malik, Junkyung Kim, Lakshmi Narasimhan Govindarajan, Ennio Mingolla, Thomas Serre.<br />
  "Tracking Without Re-recognition in Humans and Machines." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/a2557a7b2e94197ff767970b67041697-Abstract.html)] 
  [[code](http://bit.ly/InTcircuit)]
  
- **UniTrack:** Zhongdao Wang, Hengshuang Zhao, Ya-Li Li, Shengjin Wang, Philip Torr, Luca Bertinetto.<br />
  "Do Different Tracking Tasks Require Different Appearance Models?." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/06997f04a7db92466a2baa6ebc8b872d-Abstract.html)] 
  [[code](https://zhongdao.github.io/UniTrack/)]

  
### WACV 2021

- **MART:** Heng Fan, Haibin Ling.<br />
  "MART: Motion-Aware Recurrent Neural Network for Robust Visual Tracking." WACV (2021).
  [[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Fan_MART_Motion-Aware_Recurrent_Neural_Network_for_Robust_Visual_Tracking_WACV_2021_paper.pdf)] 
  [[code](https://hengfan2010.github.io/projects/MART/MART.htm)]
  
- **SiamSE:** Ivan Sosnovik, Artem Moskalev, Arnold Smeulders.<br />
  "Scale Equivariance Improves Siamese Tracking." WACV (2021).
  [[paper](https://arxiv.org/pdf/2007.09115.pdf)] 
  [[code](https://github.com/ISosnovik/SiamSE)]
  
- **TracKlinic:** Heng Fan, Fan Yang, Peng Chu, Yuewei Lin, Lin Yuan, Haibin Ling. <br />
  "TracKlinic: Diagnosis of Challenge Factors in Visual Tracking." WACV (2021).
  [[paper](https://arxiv.org/abs/1911.07959)]
  [[code](https://hengfan2010.github.io/projects/TracKlinic/TracKlinic.htm.)]
  
  
### AAAI 2021

- **MUG:** Lijun Zhou, Antoine Ledent, Qintao Hu, Ting Liu, Jianlin Zhang, Marius Kloft.<br />
  "Model Uncertainty Guides Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16473)] 
  
- **UPA:** Li Ding, Yongwei Wang, Kaiwen Yuan, Minyang Jiang, Ping Wang, Hua Huang, Z. Jane Wang. <br />
  "Towards Universal Physical Attacks on Single Object Tracking." AAAI (2021).
  [[paper](https://www.aaai.org/AAAI21Papers/AAAI-2606.DingL.pdf)]

- **PACNet:** Dawei Zhang, Zhonglong Zheng, Riheng Jia, Minglu Li.<br />
  "Visual Tracking via Hierarchical Deep Reinforcement Learning." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16443)] 
  
- **MSANet:** Xuesong Chen, Canmiao Fu, Feng Zheng, Yong Zhao, Hongsheng Li, Ping Luo, Guo-Jun Qi. <br />
  "A Unified Multi-Scenario Attacking Network for Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16195)]
  

### Others 2021

- **SiamAPN:** Changhong Fu, Ziang Cao, Yiming Li, Junjie Ye, Chen Feng.<br />
  "Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network." IEEE TGRS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9477413)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]
  
- **SiamGAN:** Yifei Zhou, Jing Li, Jun Chang, Yafu Xiao, Jun Wan, Hang Sun.<br />
  "Siamese Guided Anchoring Network for Visual Tracking." IEEE IJCNN (2021).
  [[paper](https://ieeexplore.ieee.org/document/9533985)] 
  [[code](https://github.com/xxxxx.xx)]
  
- **τ:** Matteo Dunnhofer, Kristian Simonato, Christian Micheloni.<br />
  "Combining complementary trackers for enhanced long-term visual object tracking." IVC (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0262885622000774?via%3Dihub)] 
  [[code](https://github.com/xxxxx.xx)]
  
- **CCR:** Shiming Ge, Chunhui Zhang, Shikun Li, Dan Zeng, Dacheng Tao.<br />
  "Cascaded Correlation Refinement for Robust Deep Tracking." IEEE TNNLS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9069312)] 
  [[code](https://github.com/983632847/CCR)]
  
- **PCDHV:** Ying Wang, Tingfa Xu, Jianan Li, Shenwang Jiang, Junjie Chen.<br />
  "Pyramid Correlation based Deep Hough Voting for Visual Object Tracking." ACML (2021).
  [[paper](https://arxiv.org/abs/2110.07994)] 
  
- **TrackMLP:** Tianyu Zhu, Rongkai Ma, Mehrtash Harandi, Tom Drummond. <br />
  "Learning Online for Unified Segmentation and Tracking Models." IJCNN (2021).
  [[paper](https://arxiv.org/abs/2111.06994)]

- **TAPL:** Wei han, Hantao Huang, Xiaoxi Yu.<br />
  "TAPL: Dynamic Part-based Visual Tracking via Attention-guided Part Localization." BMVC (2021).
  [[paper](https://arxiv.org/abs/2110.13027)] 
 
- **CHASE:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Li Cheng, Hossein Ghanei-Yakhdan, Shohreh Kasaei.<br />
  "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search." BMVC (2021).
  [[paper](https://arxiv.org/abs/2107.03463)] 
  
### ECCV 2020

- **Ocean:** Zhipeng Zhang, Houwen Peng, Jianlong Fu, Bing Li, Weiming Hu. <br />
  "Ocean: Object-aware Anchor-free Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2006.10721.pdf)]
  [[code](https://github.com/researchmm/TracKit)]
  
- **KYS:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Know Your Surroundings: Exploiting Scene Information for Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2003.11014v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]
  
- **PGNet:** Bingyan Liao, Chenye Wang, Yayun Wang, Yaonong Wang, Jun Yin. <br />
  "PG-Net: Pixel to Global Matching Network for Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2003.11014)]
  
- **STN:** Yuan Liu, Ruoteng Li, Yu Cheng, Robby T.Tan, Xiubao Sui. <br />
  "Object Tracking using Spatio-Temporal Networks for Future Prediction Location." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670001.pdf)]
  
- **RPT:** Ziang Ma, Linyuan Wang, Haitao Zhang, Wei Lu, Jun Yin. <br />
  "RPT: Learning Point Set Representation for Siamese Visual Tracking." ECCVW (2020).
  [[paper](https://arxiv.org/abs/2008.03467)]
  [[code](https://github.com/zhanght021/RPT)]
  
- **CenterTrack:** Xingyi Zhou, Vladlen Koltun, and Philipp Krahenbuhl. <br />
  "Tracking objects as points." ECCV (2020).
  [[paper](https://arxiv.org/abs/2004.01177)]
  [[code](https://github.com/xingyizhou/CenterTrack)]
  
- **PointTracker:** Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen, Errui Ding, Liusheng Huang. <br />
  "Segment as Points for Efficient Online Multi-Object Tracking and Segmentation." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.01550)]
  [[code](https://github.com/detectRecog/PointTrack)]
  
- **DCFST:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Learning Feature Embeddings for Discriminant Model based Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/1906.10414)]
  [[code](https://github.com/noneUmbrella/DCFST)]
  
- **CLNet:** Xingping Dong, Jianbing Shen, Ling Shao, Fatih Porikli. <br />
  "CLNet: A Compact Latent Network for Fast Adjusting Siamese Tracker." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650375.pdf)]
  [[code](https://github.com/xingpingdong/CLNet-tracking)]
  
- **RTAA:** Shuai Jia, Chao Ma, Yibing Song, Xiaokang Yang. <br />
  "Robust Tracking against Adversarial Attacks." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.09919)]
  [[code](https://github.com/joshuajss/RTAA)]
  
- **EAA:** Siyuan Liang, Xingxing Wei, Siyuan Yao, Xiaochun Cao. <br />
  "Efficient Adversarial Attacks for Visual Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2008.00217)]

- **SPARK:** Qing Guo, Xiaofei Xie, Felix Juefei-Xu, Lei Ma, Zhongguo Li, Wanli Xue, Wei Feng, Yang Liu. <br />
  "SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1910.08681.pdf)]
  
- **CAT:** Chenglong Li, Lei Liu, Andong Lu, Qing Ji, Jin Tang. <br />
  "Challenge-Aware RGBT Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.13143)]

- **JDE:** Zhongdao Wang, Liang Zheng, Yixuan Liu, Shengjin Wang. <br />
  "Towards Real-Time Multi-Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1909.12605v1.pdf)]
  [[code](https://gitee.com/mat026/Towards-Realtime-MOT)]
  
- **Chained-Tracker:** Jinlong Peng, Changan Wang, Fangbin Wan, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yanwei Fu. <br />
  "Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2007.14557.pdf)]
  [[code](https://github.com/pjl1995/CTracker)]
  
- **TAO:** Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan. <br />
  "TAO: A Large-scale Benchmark for Tracking Any Object." ECCV (2020).
  [[paper](https://arxiv.org/abs/2005.10356)]
  [[code](http://taodataset.org/)]

### CVPR2020

* **MAML:** Guangting Wang, Chong Luo, Xiaoyan Sun, Zhiwei Xiong, Wenjun Zeng.<br />
  "Tracking by Instance Detection: A Meta-Learning Approach." CVPR (2020 **Oral**).
  [[paper](https://arxiv.org/pdf/2004.00830v1.pdf)]

* **Siam R-CNN:** Paul Voigtlaender, Jonathon Luiten, Philip H.S. Torr, Bastian Leibe.<br />
  "Siam R-CNN: Visual Tracking by Re-Detection." CVPR (2020).
  [[BoLTVOS](https://arxiv.org/pdf/1904.04552.pdf)] 
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)] 
  [[code](https://www.vision.rwth-aachen.de/page/siamrcnn)]

* **D3S:** Alan Lukežič, Jiří Matas, Matej Kristan.<br />
  "D3S – A Discriminative Single Shot Segmentation Tracker." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/alanlukezic/d3s)]

* **PrDiMP:** Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Probabilistic Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12565v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **ROAM:** Tianyu Yang, Pengfei Xu, Runbo Hu, Hua Chai, Antoni B. Chan.<br />
  "ROAM: Recurrently Optimizing Tracking Model." CVPR (2020).
  [[paper](https://arxiv.org/pdf/1907.12006v3.pdf)]
  [[code](https://github.com/skyoung/ROAM)]

* **AutoTrack:** Yiming Li, Changhong Fu, Fangqiang Ding, Ziyuan Huang, Geng Lu.<br />
  "AutoTrack: Towards High-Performance Visual Tracking for UAV with Automatic Spatio-Temporal Regularization." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12949.pdf)]
  [[code](https://github.com/vision4robotics/AutoTrack)]

* **SiamBAN:** Zedu Chen, Bineng Zhong, Guorong Li, Shengping Zhang, Rongrong Ji.<br />
  "Siamese Box Adaptive Network for Visual Tracking." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/hqucv/siamban)]

* **SiamCAR:** Dongyan Guo, Jun Wang, Ying Cui, Zhenhua Wang, Shengyong Chen.<br />
  "SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/abs/1911.07241)]
  [[code](https://github.com/ohhhyeahhh/SiamCAR)]

* **SiamAttn:** Yuechen Yu, Yilei Xiong, Weilin Huang, Matthew R. Scott. <br />
  "Deformable Siamese Attention Networks for Visual Object Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2004.06711v1.pdf)]
  
* **CSA:** Bin Yan, Dong Wang, Huchuan Lu, Xiaoyun Yang.<br />
  "Cooling-Shrinking Attack: Blinding the Tracker with Imperceptible Noises." CVPR (2020).
  [[paper](https://arxiv.org/abs/2003.09595)]
  [[code](https://github.com/MasterBin-IIAU/CSA)]

* **LTMU:** Kenan Dai, Yunhua Zhang, Dong Wang, Jianhua Li, Huchuan Lu, Xiaoyun Yang.<br />
  "High-Performance Long-Term Tracking with Meta-Updater." CVPR (2020).
  [[paper](https://arxiv.org/abs/2004.00305)]
  [[code](https://github.com/Daikenan/LTMU)]
  
* **MAST:** Zihang Lai, Erika Lu, Weidi Xie.<br />
  "MAST: A Memory-Augmented Self-supervised Tracker." CVPR (2020).
  [[paper](https://arxiv.org/abs/2002.07793)]
  [[code](https://github.com/zlai0/MAST)]
  
* **CGACD:** Fei Du, Peng Liu, Wei Zhao, Xianglong Tang.<br />
  "Correlation-Guided Attention for Corner Detection Based Visual Tracking." CVPR (2020).
  [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Du_Correlation-Guided_Attention_for_Corner_Detection_Based_Visual_Tracking_CVPR_2020_paper.pdf)]
  [[code](https://github.com/feiaxyt/CGACD)]

### IJCAI 2020

- **TLPG-Tracker:** Siyuan Li, Zhi Zhang, Ziyu Liu, Anna Wang, Linglong Qiu, Feng Du. <br />
  "TLPG-Tracker: Joint Learning of Target Localization and Proposal Generation for Visual Tracking." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/99)]
  
- **E3SN:** Meng Lan, Yipeng Zhang, Qinning Xu, Lefei Zhang. <br />
  "E3SN: Efficient End-to-End Siamese Network for Video Object Segmentation." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/98)]
  
### AAAI 2020

- **SiamFC++:** Yinda Xu, Zeyu Wang, Zuoxin Li, Ye Yuan, Gang Yu. <br />
  "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1911.06188v4.pdf)]
  [[code](https://github.com/MegviiDetection/video_analyst)]
  
- **DROL:** Jinghao Zhou, Peng Wang, Haoyang Sun. <br />
  "Discriminative and Robust Online Learning for Siamese Visual Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1909.02959)]
  [[code](https://github.com/shallowtoil/DROL)]
  
- **POST:** Ning Wang, Wengang Zhou, Guojun Qi, Houqiang Li. <br />
  "POST: POlicy-Based Switch Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6899)]
  
- **SPS:** Qintao Hu, Lijun Zhou, Xiaoxiao Wang, Yao Mao, Jianlin Zhang, Qixiang Ye. <br />
  "SPSTracker: Sub-Peak Suppression of Response Map for Robust Object Tracking." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1912.00597.pdf)]
  [[code](https://www.ctolib.com/https://github.com/TrackerLB/SPSTracker)]
  
- **RPOT:** Yifan Yang, Guorong Li, Yuankai Qi, Qingming Huang. <br />
  "Release the Power of Online-Training for Robust Visual Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6956)]
  
- **MetaRTT:** Ilchae Jung, Kihyun You, Hyeonwoo Noh, Minsu Cho, Bohyung Han. <br />
  "Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6779)]
  
- **GlobalTrack:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1912.08531)]
  [[code](https://github.com/huanglianghua/GlobalTrack)]

### Others 2020

* **VTT:** Tianling Bian, Yang Hua, Tao Song, Zhengui Xue, Ruhui Ma, Neil Robertson, Haibing Guan.<br />
  "VTT: Long-term Visual Tracking with Transformers." ICPR 2020. 
  [[paper](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **COMET:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Hossein Ghanei-Yakhdan, Shohreh Kasaei, and Li Cheng.<br />
  "COMET: Context-aware iOu-guided network for sMall objEct Tracking." ACCV 2020. 
  [[paper](https://arxiv.org/pdf/2006.02597.pdf)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **SiamKPN:** Qiang Li, Zekui Qin, Wenbo Zhang, Wen Zheng.<br />
  "Siamese Keypoint Prediction Network for Visual Object Tracking." ArXiv 2020. 
  [[paper](https://arxiv.org/abs/2006.04078)]
  [[code](https://github.com/ZekuiQin/SiamKPN)]

* **SiamCAN:** Wenzhang Zhou, Longyin Wen, Libo Zhang, Dawei Du, Tiejian Luo, Yanjun Wu. <br />
  "SiamMan: Siamese Motion-aware Network for Visual Tracking." TIP 2020. 
  [[paper](https://arxiv.org/abs/1912.05515v2)]
  [[paper_new](https://arxiv.org/abs/1912.05515v2)]
  [[code](https://isrc.iscas.ac.cn/gitlab/research/siamcan)]
  
### ICCV 2019

* **DiMP:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Learning Discriminative Model Prediction for Tracking." ICCV (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Bhat_Learning_Discriminative_Model_Prediction_for_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **GradNet:** Peixia Li, Boyu Chen, Wanli Ouyang, Dong Wang, Xiaoyun Yang, Huchuan Lu. <br />
  "GradNet: Gradient-Guided Network for Visual Object Tracking." ICCV (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_GradNet_Gradient-Guided_Network_for_Visual_Object_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/LPXTT/GradNet-Tensorflow)]

* **MLT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. <br />
  "Deep Meta Learning for Real-Time Target-Aware Visual Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Choi_Deep_Meta_Learning_for_Real-Time_Target-Aware_Visual_Tracking_ICCV_2019_paper.pdf)]

* **SPLT:** Bin Yan, Haojie Zhao, Dong Wang, Huchuan Lu, Xiaoyun Yang <br />
  "'Skimming-Perusal' Tracking: A Framework for Real-Time and Robust Long-Term Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yan_Skimming-Perusal_Tracking_A_Framework_for_Real-Time_and_Robust_Long-Term_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/iiau-tracker/SPLT)]

* **ARCF:** Ziyuan Huang, Changhong Fu, Yiming Li, Fuling Lin, Peng Lu. <br />
  "Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Learning_Aberrance_Repressed_Correlation_Filters_for_Real-Time_UAV_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/vision4robotics/ARCF-tracker)]

* **BGDT:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "Bridging the Gap Between Detection and Tracking: A Unified Approach." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Bridging_the_Gap_Between_Detection_and_Tracking_A_Unified_Approach_ICCV_2019_paper.pdf)]

* **PAT:** Rey Reza Wiyatno, Anqi Xu. <br />
  "Physical Adversarial Textures That Fool Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wiyatno_Physical_Adversarial_Textures_That_Fool_Visual_Object_Tracking_ICCV_2019_paper.pdf)]

* **GFS-DCF:** Tianyang Xu, Zhen-Hua Feng, Xiao-Jun Wu, Josef Kittler. <br />
  "Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Joint_Group_Feature_Selection_and_Discriminative_Filter_Learning_for_Robust_ICCV_2019_paper.pdf)]
  [[code](https://github.com/XU-TIANYANG/GFS-DCF)]

* **CDTB:** Alan Lukežič, Ugur Kart, Jani Käpylä, Ahmed Durmush, Joni-Kristian Kämäräinen, Jiří Matas, Matej Kristan. <br />
  "CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Lukezic_CDTB_A_Color_and_Depth_Visual_Object_Tracking_Dataset_and_ICCV_2019_paper.pdf)]
  
* **fdKCF:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Fast-deepKCF Without Boundary Effect." ICCV (2019).
  [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zheng_Fast-deepKCF_Without_Boundary_Effect_ICCV_2019_paper.pdf)]

* **VOT2019:** Kristan, Matej, et al.<br />
  "The Seventh Visual Object Tracking VOT2019 Challenge Results." ICCV workshops (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCVW_2019/papers/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.pdf)]

### CVPR2019

* **SiamMask:** Qiang Wang, Li Zhang, Luca Bertinetto, Weiming Hu, Philip H.S. Torr.<br />
  "Fast Online Object Tracking and Segmentation: A Unifying Approach." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1812.05050.pdf)]
  [[project](http://www.robots.ox.ac.uk/~qwang/SiamMask/)]
  [[code](https://github.com/foolwood/SiamMask)]

* **SiamRPN++:** Bo Li, Wei Wu, Qiang Wang, Fangyi Zhang, Junliang Xing, Junjie Yan.<br />
  "SiamRPN++: Evolution of Siamese Visual Tracking with Very Deep Networks." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_SiamRPN_Evolution_of_Siamese_Visual_Tracking_With_Very_Deep_Networks_CVPR_2019_paper.pdf)]
  [[project](http://bo-li.info/SiamRPN++/)]

* **ATOM:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. <br />
  "ATOM: Accurate Tracking by Overlap Maximization." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Danelljan_ATOM_Accurate_Tracking_by_Overlap_Maximization_CVPR_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **SiamDW:** Zhipeng Zhang, Houwen Peng.<br />
  "Deeper and Wider Siamese Networks for Real-Time Visual Tracking." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **GCT:** Junyu Gao, Tianzhu Zhang, Changsheng Xu.<br />
  "Graph Convolutional Tracking." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Graph_Convolutional_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **ASRCF:** Kenan Dai, Dong Wang, Huchuan Lu, Chong Sun, Jianhua Li. <br />
  "Visual Tracking via Adaptive Spatially-Regularized Correlation Filters." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_Visual_Tracking_via_Adaptive_Spatially-Regularized_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/Daikenan/ASRCF)]

* **UDT:** Ning Wang, Yibing Song, Chao Ma, Wengang Zhou, Wei Liu, Houqiang Li.<br />
  "Unsupervised Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01828.pdf)]
  [[code](https://github.com/594422814/UDT)]

* **TADT:** Xin Li, Chao Ma, Baoyuan Wu, Zhenyu He, Ming-Hsuan Yang.<br />
  "Target-Aware Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01772.pdf)]
  [[project](https://xinli-zn.github.io/TADT-project-page/)]
  [[code](https://github.com/XinLi-zn/TADT)]

* **C-RPN:** Heng Fan, Haibin Ling.<br />
  "Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_Siamese_Cascaded_Region_Proposal_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]

* **SPM:** Guangting Wang, Chong Luo, Zhiwei Xiong, Wenjun Zeng.<br />
  "SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_SPM-Tracker_Series-Parallel_Matching_for_Real-Time_Visual_Object_Tracking_CVPR_2019_paper.pdf)]

* **OTR:** Ugur Kart, Alan Lukezic, Matej Kristan, Joni-Kristian Kamarainen, Jiri Matas. <br />
  "Object Tracking by Reconstruction with View-Specific Discriminative Correlation Filters." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/ugurkart/OTR)]

* **RPCF:** Yuxuan Sun, Chong Sun, Dong Wang, Huchuan Lu, You He. <br />
  "ROI Pooled Correlation Filters for Visual Tracking." CVPR (2019).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_ROI_Pooled_Correlation_Filters_for_Visual_Tracking_CVPR_2019_paper.pdf)]

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.<br />
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

### AAAI2019

* **LDES:** Yang Li, Jianke Zhu, Steven C.H. Hoi, Wenjie Song, Zhefeng Wang, Hantang Liu.<br />
  "Robust Estimation of Similarity Transformation for Visual Object Tracking." AAAI (2019). 
  [[paper](https://arxiv.org/pdf/1712.05231.pdf)]
  [[code](https://github.com/ihpdep/LDES)] 
  
* **ANT:** Yuankai Qi, Shengping Zhang, Weigang Zhang, Li Su, Qingming Huang, Ming-Hsuan Yang.<br />
  "Learning Attribute-Specific Representations for Visual Tracking." AAAI (2019). 
  [[paper](https://faculty.ucmerced.edu/mhyang/papers/aaai2019_tracking.pdf)]
  
* **Re2EMA:** Jianglei Huang, Wengang Zhou.<br />
  "Re2EMA: Regularized and Reinitialized Exponential Moving Average for Target Model Update in Object Tracking." AAAI (2019). 
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/4862)]

### NIPS2018

* **DAT:** Shi Pu, Yibing Song, Chao Ma, Honggang Zhang, Ming-Hsuan Yang.<br />
  "Deep Attentive Tracking via Reciprocative Learning." NIPS (2018). 
  [[paper](https://arxiv.org/pdf/1810.03851.pdf)] 
  [[project](https://ybsong00.github.io/nips18_tracking/index)] 
  [[code](https://github.com/shipubupt/NIPS2018)] 

### ECCV2018

* **UPDT:** Goutam Bhat, Joakim Johnander, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg.<br />
  "Unveiling the Power of Deep Tracking." ECCV (2018). 
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Goutam_Bhat_Unveiling_the_Power_ECCV_2018_paper.pdf)]  

* **DaSiamRPN:** Zheng Zhu, Qiang Wang, Bo Li, Wu Wei, Junjie Yan, Weiming Hu.<br />
  "Distractor-aware Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdf)]
  [[github](https://github.com/foolwood/DaSiamRPN)]
  
* **SiamMCF:** Henrique Morimitsu.<br />
  "Multiple Context Features in Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](https://link.springer.com/content/pdf/10.1007%2F978-3-030-11009-3_6.pdf)]
  [[github](https://github.com/hmorimitsu/siam-mcf)]

* **SACF:** Mengdan Zhang, Qiang Wang, Junliang Xing, Jin Gao, Peixi Peng, Weiming Hu, Steve Maybank.<br />
  "Visual Tracking via Spatially Aligned Correlation Filters Network." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/mengdan_zhang_Visual_Tracking_via_ECCV_2018_paper.pdf)]

* **RTINet:** Yingjie Yao, Xiaohe Wu, Lei Zhang, Shiguang Shan, Wangmeng Zuo.<br />
  "Joint Representation and Truncated Inference Learning for Correlation Filter based Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yingjie_Yao_Joint_Representation_and_ECCV_2018_paper.pdf)]

* **Meta-Tracker:** Eunbyung Park, Alexander C. Berg.<br />
  "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers."
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunbyung_Park_Meta-Tracker_Fast_and_ECCV_2018_paper.pdf)]
  [[github](https://github.com/silverbottlep/meta_trackers)]

* **DSLT:** Xiankai Lu, Chao Ma*, Bingbing Ni, Xiaokang Yang, Ian Reid, Ming-Hsuan Yang.<br />
  "Deep Regression Tracking with Shrinkage Loss." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiankai_Lu_Deep_Regression_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/chaoma99/DSLT)]

* **DRL-IS:** Liangliang Ren, Xin Yuan, Jiwen Lu, Ming Yang, Jie Zhou.<br />
  "Deep Reinforcement Learning with Iterative Shift for Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Liangliang_Ren_Deep_Reinforcement_Learning_ECCV_2018_paper.pdf)]

* **RT-MDNet:** Ilchae Jung, Jeany Son, Mooyeol Baek, Bohyung Han.<br />
  "Real-Time MDNet." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Ilchae_Jung_Real-Time_MDNet_ECCV_2018_paper.pdf)]

* **ACT:** Boyu Chen, Dong Wang, Peixia Li, Huchuan Lu.<br />
  "Real-time 'Actor-Critic' Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Boyu_Chen_Real-time_Actor-Critic_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/bychen515/ACT)]

* **StructSiam:** Yunhua Zhang, Lijun Wang, Dong Wang, Mengyang Feng, Huchuan Lu, Jinqing Qi.<br />
  "Structured Siamese Network for Real-Time Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yunhua_Zhang_Structured_Siamese_Network_ECCV_2018_paper.pdf)]

* **MemTrack:** Tianyu Yang, Antoni B. Chan.<br />
  "Learning Dynamic Memory Networks for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianyu_Yang_Learning_Dynamic_Memory_ECCV_2018_paper.pdf)]

* **SiamFC-tri:** Xingping Dong, Jianbing Shen.<br />
  "Triplet Loss in Siamese Network for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf)]
  [[github](https://github.com/shenjianbing/TripletTracking)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Efstratios_Gavves_Long-term_Tracking_in_ECCV_2018_paper.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Matthias_Muller_TrackingNet_A_Large-Scale_ECCV_2018_paper.pdf)] 
  [[project](http://tracking-net.org/)]


### CVPR2018

* **VITAL:** Yibing Song, Chao Ma, Xiaohe Wu, Lijun Gong, Linchao Bao, Wangmeng Zuo, Chunhua Shen, Rynson Lau, and Ming-Hsuan Yang.
  "VITAL: VIsual Tracking via Adversarial Learning." CVPR (2018 **Spotlight**). 
  [[project](https://ybsong00.github.io/cvpr18_tracking/index)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.pdf)]
  [[github](https://github.com/ybsong00/Vital_release)]

* **LSART:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Learning Spatial-Aware Regressions for Visual Tracking." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.pdf)]

* **SiamRPN:** Bo Li, Wei Wu, Zheng Zhu, Junjie Yan.
  "High Performance Visual Tracking with Siamese Region Proposal Network." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf)]

* **TRACA:** Jongwon Choi, Hyung Jin Chang, Tobias Fischer, Sangdoo Yun, Kyuewang Lee, Jiyeoup Jeong, Yiannis Demiris, Jin Young Choi.
  "Context-aware Deep Feature Compression for High-speed Visual Tracking." CVPR (2018). 
  [[project](https://sites.google.com/site/jwchoivision/)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.pdf)]

* **RASNet:** Qiang Wang, Zhu Teng, Junliang Xing, Jin Gao, Weiming Hu, Stephen Maybank.
  "Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking." CVPR 2018. 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf)]

* **SA-Siam:** Anfeng He, Chong Luo, Xinmei Tian, Wenjun Zeng.
  "A Twofold Siamese Network for Real-Time Object Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf)]

* **STRCF:** Feng Li, Cheng Tian, Wangmeng Zuo, Lei Zhang, Ming-Hsuan Yang.
  "Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.pdf)]
  [[github](https://github.com/lifeng9472/STRCF)]

* **FlowTrack:** Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan.
  "End-to-end Flow Correlation Tracking with Spatial-temporal Attention." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.pdf)]

* **DEDT:** Kourosh Meshgi, Shigeyuki Oba, Shin Ishii.
  "Efficient Diverse Ensemble for Discriminative Co-Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.pdf)]

* **SINT++:** Xiao Wang, Chenglong Li, Bin Luo, Jin Tang.
  "SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf)]

* **DRT:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Correlation Tracking via Joint Discrimination and Reliability Learning." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Correlation_Tracking_via_CVPR_2018_paper.pdf)]

* **MCCT:** Ning Wang, Wengang Zhou, Qi Tian, Richang Hong, Meng Wang, Houqiang Li.
  "Multi-Cue Correlation Filters for Robust Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.pdf)]
  [[github](https://github.com/594422814/MCCT)]

* **MKCF:** Ming Tang, Bin Yu, Fan Zhang, Jinqiao Wang.
  "High-speed Tracking with Multi-kernel Correlation Filters." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Tang_High-Speed_Tracking_With_CVPR_2018_paper.pdf)]

* **HP:** Xingping Dong, Jianbing Shen, Wenguan Wang, Yu, Liu, Ling Shao, and Fatih Porikli.
  "Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.pdf)]

### NIPS2017

* **HART:** Adam R. Kosiorek, Alex Bewley, Ingmar Posner. 
  "Hierarchical Attentive Recurrent Tracking." NIPS (2017). 
  [[paper](https://papers.nips.cc/paper/6898-hierarchical-attentive-recurrent-tracking.pdf)]
  [[github](https://github.com/akosiorek/hart)]


### ICCV2017

* **CREST:** Yibing Song, Chao Ma, Lijun Gong, Jiawei Zhang, Rynson Lau, Ming-Hsuan Yang. 
  "CREST: Convolutional Residual Learning for Visual Tracking." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Song_CREST_Convolutional_Residual_ICCV_2017_paper.pdf)]
  [[project](http://www.cs.cityu.edu.hk/~yibisong/iccv17/index.html)]
  [[github](https://github.com/ybsong00/CREST-Release)]

* **EAST:** Chen Huang, Simon Lucey, Deva Ramanan.
  "Learning Policies for Adaptive Tracking with Deep Feature Cascades." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Learning_Policies_for_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Huang_Learning_Policies_for_ICCV_2017_supplemental.zip)]

* **PTAV:** Heng Fan and Haibin Ling. 
  "Parallel Tracking and Verifying: A Framework for Real-Time and High Accuracy Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Fan_Parallel_Tracking_and_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fan_Parallel_Tracking_and_ICCV_2017_supplemental.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/PTAV/ptav.htm)]
  [[code](http://www.dabi.temple.edu/~hbling/code/PTAV/serial_ptav_v1.zip)]

* **BACF:** Hamed Kiani Galoogahi, Ashton Fagg, Simon Lucey. 
  "Learning Background-Aware Correlation Filters for Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_supplemental.pdf)]
  [[code](http://www.hamedkiani.com/uploads/5/1/8/8/51882963/bacf_toupload.zip)]
  [[project](http://www.hamedkiani.com/bacf.html)]

* **TSN:** Zhu Teng, Junliang Xing, Qiang Wang, Congyan Lang, Songhe Feng and Yi Jin.
  "Robust Object Tracking based on Temporal and Spatial Deep Networks." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Teng_Robust_Object_Tracking_ICCV_2017_paper.pdf)]

* **p-tracker:** James Supančič, III; Deva Ramanan.
  "Tracking as Online Decision-Making: Learning a Policy From Streaming Videos With Reinforcement Learning." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Supancic_Tracking_as_Online_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Supancic_Tracking_as_Online_ICCV_2017_supplemental.pdf)]

* **DSiam:** Qing Guo; Wei Feng; Ce Zhou; Rui Huang; Liang Wan; Song Wang.
  "Learning Dynamic Siamese Network for Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf)]
  [[github](https://github.com/tsingqguo/DSiam)]

* **SP-KCF:** Xin Sun; Ngai-Man Cheung; Hongxun Yao; Yiluan Guo.
  "Non-Rigid Object Tracking via Deformable Patches Using Shape-Preserved KCF and Level Sets." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Sun_Non-Rigid_Object_Tracking_ICCV_2017_paper.pdf)]

* **UCT:** Zheng Zhu, Guan Huang, Wei Zou, Dalong Du, Chang Huang.
  "UCT: Learning Unified Convolutional Networks for Real-Time Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Zhu_UCT_Learning_Unified_ICCV_2017_paper.pdf)]

* Tobias Bottger, Patrick Follmann.
  "The Benefits of Evaluating Tracker Performance Using Pixel-Wise Segmentations." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Bottger_The_Benefits_of_ICCV_2017_paper.pdf)]

* **CFWCR:** Zhiqun He, Yingruo Fan, Junfei Zhuang, Yuan Dong, HongLiang Bai.
  "Correlation Filters With Weighted Convolution Responses." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/He_Correlation_Filters_With_ICCV_2017_paper.pdf)]
  [[github](https://github.com/he010103/CFWCR)]

* **IBCCF:** Feng Li, Yingjie Yao, Peihua Li, David Zhang, Wangmeng Zuo, Ming-Hsuan Yang.
  "Integrating Boundary and Center Correlation Filters for Visual Tracking With Aspect Ratio Variation." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Li_Integrating_Boundary_and_ICCV_2017_paper.pdf)]
  [[github](https://github.com/lifeng9472/IBCCF)]

* **RFL:** Tianyu Yang, Antoni B. Chan.
  "Recurrent Filter Learning for Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Yang_Recurrent_Filter_Learning_ICCV_2017_paper.pdf)]


### CVPR2017

* **ECO:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. 
  "ECO: Efficient Convolution Operators for Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Danelljan_ECO_Efficient_Convolution_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Danelljan_ECO_Efficient_Convolution_2017_CVPR_supplemental.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/ecotrack/index.html)]
  [[github](https://github.com/martin-danelljan/ECO)]

* **CFNet:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Andrea Vedaldi, Philip H. S. Torr.
  "End-to-end representation learning for Correlation Filter based tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Valmadre_End-To-End_Representation_Learning_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Valmadre_End-To-End_Representation_Learning_2017_CVPR_supplemental.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/cfnet.html)]
  [[github](https://github.com/bertinetto/cfnet)]

* **CACF:** Matthias Mueller, Neil Smith, Bernard Ghanem. 
  "Context-Aware Correlation Filter Tracking." CVPR (2017 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Mueller_Context-Aware_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Mueller_Context-Aware_Correlation_Filter_2017_CVPR_supplemental.zip)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-ca-cf-tracking.aspx)]
  [[code](https://github.com/thias15/Context-Aware-CF-Tracking)]

* **RaF:** Le Zhang, Jagannadan Varadarajan, Ponnuthurai Nagaratnam Suganthan, Narendra Ahuja and Pierre Moulin
  "Robust Visual Tracking Using Oblique Random Forests." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Robust_Visual_Tracking_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Zhang_Robust_Visual_Tracking_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/zhangleuestc/incremental-oblique-random-forest)]
  [[code](https://github.com/ZhangLeUestc/Incremental-Oblique-Random-Forest)]

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang. 
  "Multi-Task Correlation Particle Filter for Robust Object Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Multi-Task_Correlation_Particle_CVPR_2017_paper.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]

* **ACFN:** Jongwon Choi, Hyung Jin Chang, Sangdoo Yun, Tobias Fischer, Yiannis Demiris, and Jin Young Choi.
  "Attentional Correlation Filter Network for Adaptive Visual Tracking." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Choi_Attentional_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Choi_Attentional_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/acfn-1)]
  [[test code](https://drive.google.com/file/d/0B0ZkG8zaRQoLQUswbW9qSWFaU0U/view?usp=drive_web)]
  [[training code](https://drive.google.com/file/d/0B0ZkG8zaRQoLZVVranBnbHlydnM/view?usp=drive_web)]

* **LMCF:** Mengmeng Wang, Yong Liu, Zeyi Huang. 
  "Large Margin Object Tracking with Circulant Feature Maps." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Large_Margin_Object_CVPR_2017_paper.pdf)]
  [[zhihu](https://zhuanlan.zhihu.com/p/25761718)]

* **ADNet:** Sangdoo Yun, Jongwon Choi, Youngjoon Yoo, Kimin Yun, Jin Young Choi.
  "Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning." CVPR (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yun_Action-Decision_Networks_for_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Yun_Action-Decision_Networks_for_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/view/cvpr2017-adnet)]

* **CSR-DCF:** Alan Lukežič, Tomáš Vojíř, Luka Čehovin, Jiří Matas, Matej Kristan. 
  "Discriminative Correlation Filter with Channel and Spatial Reliability." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lukezic_Discriminative_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Lukezic_Discriminative_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[code](https://github.com/alanlukezic/csr-dcf)]

* **BranchOut:** Bohyung Han, Jack Sim, Hartwig Adam.
  "BranchOut: Regularization for Online Ensemble Tracking with Convolutional Neural Networks." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Han_BranchOut_Regularization_for_CVPR_2017_paper.pdf)]

* **AMCT:** Donghun Yeo, Jeany Son, Bohyung Han, Joonhee Han.
  "Superpixel-based Tracking-by-Segmentation using Markov Chains." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yeo_Superpixel-Based_Tracking-By-Segmentation_Using_CVPR_2017_paper.pdf)]

* **SANet:** Heng Fan, Haibin Ling. 
  "SANet: Structure-Aware Network for Visual Tracking." CVPRW (2017). 
  [[paper](https://arxiv.org/pdf/1611.06878.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/SANet/SANet.html)]
  [[code](http://www.dabi.temple.edu/~hbling/code/SANet/sanet_code.zip)]

### ECCV2016

* **SiameseFC:** Luca Bertinetto, Jack Valmadre, João F. Henriques, Andrea Vedaldi, Philip H.S. Torr. 
  "Fully-Convolutional Siamese Networks for Object Tracking." ECCV workshop (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1606.09549v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/siamese-fc.html)]
  [[github](https://github.com/bertinetto/siamese-fc)]

* **GOTURN:** David Held, Sebastian Thrun, Silvio Savarese. 
  "Learning to Track at 100 FPS with Deep Regression Networks." ECCV (2016). 
  [[paper](http://davheld.github.io/GOTURN/GOTURN.pdf)]
  [[project](http://davheld.github.io/GOTURN/GOTURN.html)]
  [[github](https://github.com/davheld/GOTURN)]

* **C-COT:** Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. 
  "Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking." ECCV (2016). 
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/index.html)]
  [[github](https://github.com/martin-danelljan/Continuous-ConvOp)]

* **CF+AT:** Adel Bibi, Matthias Mueller, and Bernard Ghanem. 
  "Target Response Adaptation for Correlation Filter Tracking." ECCV (2016). 
  [[paper](http://www.adelbibi.com/papers/ECCV2016/Target_Adap.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-target-response-adaptation.aspx)]
  [[github](https://github.com/adelbibi/Target-Response-Adaptation-for-Correlation-Filter-Tracking)]

* Yao Sui, Ziming Zhang,  Guanghui Wang, Yafei Tang, Li Zhang. 
  "Real-Time Visual Tracking: Promoting the Robustness of Correlation Filter Learning." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08173.pdf)]

* Yao Sui, Guanghui Wang, Yafei Tang, Li Zhang. 
  "Tracking Completion." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08171v1.pdf)]

### CVPR2016

* **MDNet:** Nam, Hyeonseob, and Bohyung Han. 
  "Learning Multi-Domain Convolutional Neural Networks for Visual Tracking." CVPR (2016).
  [[paper](http://arxiv.org/pdf/1510.07945v2.pdf)]
  [[VOT_presentation](http://votchallenge.net/vot2015/download/presentation_Hyeonseob.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/mdnet/)]
  [[github](https://github.com/HyeonseobNam/MDNet)]

* **SINT:** Ran Tao, Efstratios Gavves, Arnold W.M. Smeulders. 
  "Siamese Instance Search for Tracking." CVPR (2016).
  [[paper](https://staff.science.uva.nl/r.tao/pub/TaoCVPR2016.pdf)]
  [[project](https://staff.fnwi.uva.nl/r.tao/projects/SINT/SINT_proj.html)]

* **SCT:** Jongwon Choi, Hyung Jin Chang, Jiyeoup Jeong, Yiannis Demiris, and Jin Young Choi.
  "Visual Tracking Using Attention-Modulated Disintegration and Integration." CVPR (2016).
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Choi_Visual_Tracking_Using_CVPR_2016_paper.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/sct)]

* **STCT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu.
  "STCT: Sequentially Training Convolutional Networks for Visual Tracking." CVPR (2016).
  [[paper](http://www.ee.cuhk.edu.hk/~wlouyang/Papers/WangLJ_CVPR16.pdf)]
  [[github](https://github.com/scott89/STCT)]

* **SRDCFdecon:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking." CVPR (2016).
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/AdaptiveDecon_CVPR16.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/index.html)]

* **HDT:** Yuankai Qi, Shengping Zhang, Lei Qin, Hongxun Yao, Qingming Huang, Jongwoo Lim, Ming-Hsuan Yang. 
  "Hedged Deep Tracking." CVPR (2016). 
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr16_hedge_tracking.pdf)]
  [[project](https://sites.google.com/site/yuankiqi/hdt/)]

* **Staple:** Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip H.S. Torr. 
  "Staple: Complementary Learners for Real-Time Tracking." CVPR (2016). 
  [[paper](http://120.52.73.75/arxiv.org/pdf/1512.01355v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/staple.html)]
  [[github](https://github.com/bertinetto/staple)]

* **EBT:** Gao Zhu, Fatih Porikli, and Hongdong Li.
  "Beyond Local Search: Tracking Objects Everywhere with Instance-Specific Proposals." CVPR (2016). 
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Beyond_Local_Search_CVPR_2016_paper.pdf)]
  [[exe](http://www.votchallenge.net/vot2016/download/02_EBT.zip)]

* **DLSSVM:** Jifeng Ning, Jimei Yang, Shaojie Jiang, Lei Zhang and Ming-Hsuan Yang. 
  "Object Tracking via Dual Linear Structured SVM and Explicit Feature Map." CVPR (2016). 
  [[paper](http://www4.comp.polyu.edu.hk/~cslzhang/paper/cvpr16/DLSSVM.pdf)]
  [[code](http://www4.comp.polyu.edu.hk/~cslzhang/code/DLSSVM_CVPR.zip)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/DLSSVM/DLSSVM.htm)]

### NIPS2016
* **Learnet:** Luca Bertinetto, João F. Henriques, Jack Valmadre, Philip H. S. Torr, Andrea Vedaldi. 
  "Learning feed-forward one-shot learners." NIPS (2016). 
  [[paper](https://arxiv.org/pdf/1606.05233v1.pdf)]

### ICCV2015

* **FCNT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu. 
  "Visual Tracking with Fully Convolutional Networks." ICCV (2015). 
  [[paper](http://202.118.75.4/lu/Paper/ICCV2015/iccv15_lijun.pdf)]
  [[project](http://scott89.github.io/FCNT/)]
  [[github](https://github.com/scott89/FCNT)]

* **SRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Learning Spatially Regularized Correlation Filters for Visual Tracking." ICCV (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/SRDCF_ICCV15.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **CF2:** Chao Ma, Jia-Bin Huang, Xiaokang Yang and Ming-Hsuan Yang.
  "Hierarchical Convolutional Features for Visual Tracking." ICCV (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/iccv15_tracking.pdf)]
  [[project](https://sites.google.com/site/jbhuang0604/publications/cf2)]
  [[github](https://github.com/jbhuang0604/CF2)]

* Naiyan Wang, Jianping Shi, Dit-Yan Yeung and Jiaya Jia.
  "Understanding and Diagnosing Visual Tracking Systems." ICCV (2015). 
  [[paper](http://winsty.net/papers/diagnose.pdf)]
  [[project](http://winsty.net/tracker_diagnose.html)]
  [[code](http://winsty.net/diagnose/diagnose_code.zip)]\

* **DeepSRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Convolutional Features for Correlation Filter Based Visual Tracking." ICCV workshop (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/ConvDCF_ICCV15_VOTworkshop.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **RAJSSC:** Mengdan Zhang, Junliang Xing, Jin Gao, Xinchu Shi, Qiang Wang, Weiming Hu. 
  "Joint Scale-Spatial Correlation Tracking with Adaptive Rotation Estimation." ICCV workshop (2015). 
  [[paper](http://www.cv-foundation.org//openaccess/content_iccv_2015_workshops/w14/papers/Zhang_Joint_Scale-Spatial_Correlation_ICCV_2015_paper.pdf)]
  [[poster](http://www.votchallenge.net/vot2015/download/poster_Mengdan_Zhang.pdf)]

### CVPR2015

* **MUSTer:** Zhibin Hong, Zhe Chen, Chaohui Wang, Xue Mei, Danil Prokhorov, Dacheng Tao. 
  "MUlti-Store Tracker (MUSTer): A Cognitive Psychology Inspired Approach to Object Tracking." CVPR (2015). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Hong_MUlti-Store_Tracker_MUSTer_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/multistoretrackermuster/)]

* **LCT:** Chao Ma, Xiaokang Yang, Chongyang Zhang, Ming-Hsuan Yang.
  "Long-term Correlation Tracking." CVPR (2015).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Ma_Long-Term_Correlation_Tracking_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/chaoma99/cvpr15_tracking)]
  [[github](https://github.com/chaoma99/lct-tracker)]

* **DAT:** Horst Possegger, Thomas Mauthner, and Horst Bischof. 
  "In Defense of Color-based Model-free Tracking." CVPR (2015). 
  [[paper](https://lrs.icg.tugraz.at/pubs/possegger_cvpr15.pdf)]
  [[project](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/dat)]
  [[code](https://lrs.icg.tugraz.at/downloads/dat-v1.0.zip)]

* **RPT:** Yang Li, Jianke Zhu and Steven C.H. Hoi. 
  "Reliable Patch Trackers: Robust Visual Tracking by Exploiting Reliable Patches." CVPR (2015). 
  [[paper](https://github.com/ihpdep/ihpdep.github.io/raw/master/papers/cvpr15_rpt.pdf)]
  [[github](https://github.com/ihpdep/rpt)]

### ICML2015

* **CNN-SVM:** Seunghoon Hong, Tackgeun You, Suha Kwak and Bohyung Han.
  "Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network ." ICML (2015)
  [[paper](http://120.52.73.80/arxiv.org/pdf/1502.06796.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/CNN_SVM/)]

### BMVC2014

* **DSST:** Martin Danelljan, Gustav Häger, Fahad Shahbaz Khan and Michael Felsberg. 
  "Accurate Scale Estimation for Robust Visual Tracking." BMVC (2014).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/ScaleTracking_BMVC14.pdf)]
  [[PAMI](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html)]

### ECCV2014

* **MEEM:** Jianming Zhang, Shugao Ma, and Stan Sclaroff.
  "MEEM: Robust Tracking via Multiple Experts using Entropy Minimization." ECCV (2014).
  [[paper](http://cs-people.bu.edu/jmzhang/MEEM/MEEM-eccv-preprint.pdf)]
  [[project](http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html)]

* **TGPR:** Jin Gao, Haibin Ling, Weiming Hu, Junliang Xing.
  "Transfer Learning Based Visual Tracking with Gaussian Process Regression." ECCV (2014).
  [[paper](http://www.dabi.temple.edu/~hbling/publication/tgpr-eccv14.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/TGPR.htm)]

* **STC:** Kaihua Zhang, Lei Zhang, Ming-Hsuan Yang, David Zhang.
  "Fast Tracking via Spatio-Temporal Context Learning." ECCV (2014).
  [[paper](http://arxiv.org/pdf/1311.1939v1.pdf)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/STC/STC.htm)]

* **SAMF:** Yang Li, Jianke Zhu.
  "A Scale Adaptive Kernel Correlation Filter Tracker with Feature Integration." ECCV workshop (2014).
  [[paper](http://link.springer.com/content/pdf/10.1007%2F978-3-319-16181-5_18.pdf)]
  [[github](https://github.com/ihpdep/samf)]

### NIPS2013

* **DLT:** Naiyan Wang and Dit-Yan Yeung. 
  "Learning A Deep Compact Image Representation for Visual Tracking." NIPS (2013). 
  [[paper](http://winsty.net/papers/dlt.pdf)]
  [[project](http://winsty.net/dlt.html)]
  [[code](http://winsty.net/dlt/DLTcode.zip)]
 
 ### PAMI & IJCV & TIP

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
    " Learning Multi-task Correlation Particle Filters for Visual Tracking." TPAMI (2017).
      [[paper]( )]
      [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/lmcpf.html)]
      [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_mcpf/Source_Code/Source_Code.zip)] 

* **RSST:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
  " Robust Structural Sparse Tracking." TPAMI (2017).
  [[paper]( )
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/rsst.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_RSST/RSSTDeep/RSSTDeep_Code.zip)] 

* **fDSST:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg.
  "Discriminative Scale Space Tracking." TPAMI (2017).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/index.html)]
  [[code](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/fDSST_code.zip)] 

* **KCF:** João F. Henriques, Rui Caseiro, Pedro Martins, Jorge Batista. 
  "High-Speed Tracking with Kernelized Correlation Filters." TPAMI (2015).
  [[paper](http://www.robots.ox.ac.uk/~joao/publications/henriques_tpami2015.pdf)]
  [[project](http://www.robots.ox.ac.uk/~joao/circulant/)]

* **CLRST:** Tianzhu Zhang, Si Liu, Narendra Ahuja, Ming-Hsuan Yang, Bernard Ghanem.  
  "Robust Visual Tracking Via Consistent Low-Rank Sparse Learning." IJCV (2015). 
  [[paper](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/tianzhu%20zhang_files/Journal%20Articles/IJCV15_zhang_Low-Rank%20Sparse%20Learning.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/Robust%20Visual%20Tracking%20Via%20Consistent%20Low-Rank%20Sparse.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/material/LRT_Code.zip)]

* **DNT:** Zhizhen Chi, Hongyang Li, Huchuan Lu, Ming-Hsuan Yang. 
  "Dual Deep Network for Visual Tracking." TIP (2017). 
  [[paper](https://arxiv.org/pdf/1612.06053v1.pdf)]

* **DRT:** Junyu Gao, Tianzhu Zhang, Xiaoshan Yang, Changsheng Xu. 
  "Deep Relative Tracking." TIP (2017). 
  [[paper](http://ieeexplore.ieee.org/abstract/document/7828108/)]

* **BIT:** Bolun Cai, Xiangmin Xu, Xiaofen Xing, Kui Jia, Jie Miao, Dacheng Tao.
  "BIT: Biologically Inspired Tracker." TIP (2016). 
  [[paper](http://caibolun.github.io/papers/BIT_TIP.pdf)]
  [[project](http://caibolun.github.io/BIT/index.html)]
  [[github](https://github.com/caibolun/BIT)]

* **CNT:** Kaihua Zhang, Qingshan Liu, Yi Wu, Minghsuan Yang. 
  "Robust Visual Tracking via Convolutional Networks Without Training." TIP (2016). 
  [[paper](http://kaihuazhang.net/CNT.pdf)]
  [[code](http://kaihuazhang.net/CNT_matlab.rar)]
  
  ## ArXiv

* **DCFNet:** Qiang Wang, Jin Gao, Junliang Xing, Mengdan Zhang, Weiming Hu. 
  "DCFNet: Discriminant Correlation Filters Network for Visual Tracking." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1704.04057.pdf)]
  [[code](https://github.com/foolwood/DCFNet#dcfnet-discriminant-correlation-filters-network-for-visual-tracking)]

* **RDT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. 
  "Visual Tracking by Reinforced Decision Making." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1702.06291.pdf)]

* **MSDAT:** Xinyu Wang, Hanxi Li, Yi Li, Fumin Shen, Fatih Porikli .
  "Robust and Real-time Deep Tracking Via Multi-Scale Domain Adaptation." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1701.00561.pdf)]

* **RLT:** Da Zhang, Hamid Maei, Xin Wang, Yuan-Fang Wang.
  "Deep Reinforcement Learning for Visual Object Tracking in Videos." arXiv (2017). 
  [[paper](https://arxiv.org/pdf/1701.08936v1.pdf)]

* **SCF:** Wangmeng Zuo, Xiaohe Wu, Liang Lin, Lei Zhang, Ming-Hsuan Yang. 
  "Learning Support Correlation Filters for Visual Tracking." arXiv (2016).
  [[paper](https://arxiv.org/pdf/1601.06032.pdf)]
  [[project](http://faculty.ucmerced.edu/mhyang/project/scf/)]

* **CRT:** Kai Chen, Wenbing Tao. 
  "Convolutional Regression for Visual Tracking." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1611.04215.pdf)]

* **BMR:** Kaihua Zhang, Qingshan Liu, and Ming-Hsuan Yang. 
  "Visual Tracking via Boolean Map Representations." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1610.09652v1.pdf)]

* **YCNN:** Kai Chen, Wenbing Tao. 
  "Once for All: a Two-flow Convolutional Neural Network for Visual Tracking." arXiv (2016). 
  [[paper](https://arxiv.org/pdf/1604.07507v1.pdf)]

* **ROLO:** Guanghan Ning, Zhi Zhang, Chen Huang, Zhihai He, Xiaobo Ren, Haohong Wang. 
  "Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking." arXiv (2016). 
  [[paper](http://arxiv.org/pdf/1607.05781v1.pdf)]
  [[project](http://guanghan.info/projects/ROLO/)]
  [[github](https://github.com/Guanghan/ROLO/)]

* **SO-DLT:** Naiyan Wang, Siyi Li, Abhinav Gupta, Dit-Yan Yeung. 
  "Transferring Rich Feature Hierarchies for Robust Visual Tracking." arXiv (2015). 
  [[paper](https://arxiv.org/pdf/1501.04587v2.pdf)]
  [[code](http://www.votchallenge.net/vot2016/download/08_SO-DLT.zip)]

* **DMSRDCF:** Susanna Gladh, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg. 
  "Deep Motion Features for Visual Tracking." ICPR **Best Paper** (2016). 
  [[paper](https://arxiv.org/pdf/1612.06615v1.pdf)]

## Benchmark

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1803.09502.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[project](https://silviogiancola.github.io/publication/2018-03-trackingnet/details/)]
  [[paper](https://arxiv.org/pdf/1803.10794.pdf)] 

* **UAVDT:** Dawei Du, Yuankai Qi, Hongyang Yu, Yifang Yang, Kaiwen Duan, GuoRong Li, Weigang Zhang,  Weihai; Qingming Huang, Qi Tian.<br />
  "The Unmanned Aerial Vehicle Benchmark: Object Detection and Tracking." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1804.00518.pdf)]

* **Dataset-AMP:** Luka Čehovin Zajc; Alan Lukežič; Aleš Leonardis; Matej Kristan.
  "Beyond Standard Benchmarks: Parameterizing Performance Evaluation in Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zajc_Beyond_Standard_Benchmarks_ICCV_2017_paper.pdf)]

* **Dataset-NFS:** Hamed Kiani Galoogahi, Ashton Fagg, Chen Huang, Deva Ramanan and Simon Lucey.
  "Need for Speed: A Benchmark for Higher Frame Rate Object Tracking." ICCV (2017)
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Need_for_Speed_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Need_for_Speed_ICCV_2017_supplemental.pdf)]
  [[project](http://ci2cv.net/nfs/index.html)]

* **Dataset-DTB70:** Siyi Li, Dit-Yan Yeung.
  "Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models." AAAI (2017)
  [[paper](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14338/14292)]
  [[project](https://github.com/flyers/drone-tracking)]
  [[dataset](https://www.dropbox.com/s/s1fj99s2six4lrs/DTB70.tar.gz?dl=0)]

* **Dataset-UAV123:** Matthias Mueller, Neil Smith and Bernard Ghanem.
  "A Benchmark and Simulator for UAV Tracking." ECCV (2016)
  [[paper](https://ivul.kaust.edu.sa/Documents/Publications/2016/A%20Benchmark%20and%20Simulator%20for%20UAV%20Tracking.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-benchmark-simulator-uav.aspx)]
  [[dataset](https://ivul.kaust.edu.sa/Pages/Dataset-UAV123.aspx)]

* **Dataset-TColor-128:** Pengpeng Liang, Erik Blasch, Haibin Ling.
  "Encoding color information for visual tracking: Algorithms and benchmark." TIP (2015)
  [[paper](http://www.dabi.temple.edu/~hbling/publication/TColor-128.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/data/TColor-128/TColor-128.html)]
  [[dataset](http://www.dabi.temple.edu/~hbling/data/TColor-128/Temple-color-128.zip)]

* **Dataset-NUS-PRO:** Annan Li, Min Lin, Yi Wu, Ming-Hsuan Yang, and Shuicheng Yan.
  "NUS-PRO: A New Visual Tracking Challenge." PAMI (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/pami15_nus_pro.pdf)]
  [[project](https://sites.google.com/site/li00annan/nus-pro)]
  [[Data_360](https://d9fca6.lc.yunpan.cn/lk/cqKIc6DU3t2eJ)(code:bf28)]
  [[Data_baidu]](https://pan.baidu.com/s/1pJHvbSn#list/path=%2F)]
  [[View_360](https://6aa275.lc.yunpan.cn/lk/cqK479PfzDrPX)(code:515a)]
  [[View_baidu]](https://pan.baidu.com/s/1hqKXcuK)]

* **Dataset-PTB:** Shuran Song and Jianxiong Xiao.
  "Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines." ICCV (2013)
  [[paper](http://vision.princeton.edu/projects/2013/tracking/paper.pdf)]
  [[project](http://tracking.cs.princeton.edu/)]
  [[5 validation](http://tracking.cs.princeton.edu/ValidationSet.zip)]
  [[95 evaluation](http://tracking.cs.princeton.edu/EvaluationSet.tgz)]

* **Dataset-ALOV300+:** Arnold W. M. Smeulders, Dung M. Chu, Rita Cucchiara, Simone Calderara, Afshin Dehghan, Mubarak Shah.
  "Visual Tracking: An Experimental Survey." PAMI (2014)
  [[paper](http://crcv.ucf.edu/papers/Tracking_Survey.pdf)]
  [[project](http://imagelab.ing.unimore.it/dsm/)]
  [Mirror Link:ALOV300++ Dataset](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/Frames.zip)
  [Mirror Link:ALOV300++ Groundtruth](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/GT.zip)

* **OTB2013:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Online Object Tracking: A Benchmark." CVPR (2013).
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr13_benchmark.pdf)]

* **OTB2015:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Object Tracking Benchmark." TPAMI (2015).
  [[paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7001050&tag=1)]
  [[project](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)]

* **Dataset-VOT:**
  **[[project](http://www.votchallenge.net/)]**



## Distinguished Researchers & Teams
Distinguished visual tracking researchers who have published +3 papers which have a major impact on the field of visual tracking and are still active in the field of visual tracking.(Names listed in no particular order.)

* [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/)
* [Haibin Ling](http://www.dabi.temple.edu/~hbling/)
* [Huchuan Lu](http://ice.dlut.edu.cn/lu/)
* [Hongdong Li](http://users.cecs.anu.edu.au/~hongdong/)
* [Lei Zhang](http://www4.comp.polyu.edu.hk/~cslzhang/)
* [Matej Kristan](http://www.vicos.si/People/Matejk)
* [João F. Henriques](http://www.robots.ox.ac.uk/~joao/)
* [Martin Danelljan](http://users.isy.liu.se/cvl/marda26/)
* [Kaihua Zhang](http://kaihuazhang.net/)
* [Hamed Kiani](http://www.hamedkiani.com/)
* [Luca Bertinetto](http://www.robots.ox.ac.uk/~luca/index.html)
* [Tianzhu Zhang](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/index.html)
* [Chao Ma](https://www.chaoma.info/)
* [Yibing Song](https://ybsong00.github.io/)
* [Dong Wang](http://www.escience.cn/people/wangdongdut/index.html)
* [**Torr Vision Group**](http://www.robots.ox.ac.uk/~tvg/people.php)
* [**Computer Vision Laboratory, POSTECH**](http://cvlab.postech.ac.kr/lab/index.php)
